{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b110fe5",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 1: DATA EXPLORATION & ITEM DIAGNOSTICS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be3f78",
   "metadata": {},
   "source": [
    "## 1.1 Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdebe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Fix for potential OpenMP runtime conflicts\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer, calculate_kmo, calculate_bartlett_sphericity\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure output directories exist\n",
    "Path('plots').mkdir(exist_ok=True)\n",
    "Path('tables').mkdir(exist_ok=True)\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "RANDOM_SEED = 67\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "POPULATION = 'full'  # Using entire 511 sample for experimental analysis\n",
    "\n",
    "print(\"âœ“ Libraries loaded\")\n",
    "print(f\"âœ“ Random seed: {RANDOM_SEED}\")\n",
    "print(f\"âœ“ Population: {POPULATION.upper()} (N=511)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f09fd",
   "metadata": {},
   "source": [
    "## 1.2 Load Data and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FULL sample for experimental EFA (N=511)\n",
    "df_full = pd.read_csv('../data/AIRS_clean.csv')\n",
    "\n",
    "# Load item metadata\n",
    "with open('../data/airs_28item_complete.json', 'r', encoding='utf-8') as f:\n",
    "    item_metadata = json.load(f)\n",
    "\n",
    "# Extract structure - ALL items initially\n",
    "ALL_PREDICTOR_ITEMS = item_metadata['predictor_items']  # 24 items\n",
    "outcome_items = item_metadata['outcome_items']  # 4 BI items\n",
    "ALL_CONSTRUCTS = item_metadata['constructs']\n",
    "metadata = item_metadata['metadata']\n",
    "positive_items = item_metadata['positive_items']\n",
    "negative_items = item_metadata['negative_items']\n",
    "\n",
    "# Create construct mapping dictionary\n",
    "ALL_PREDICTOR_CONSTRUCTS = {\n",
    "    'PE': ['PE1', 'PE2'],\n",
    "    'EE': ['EE1', 'EE2'],\n",
    "    'SI': ['SI1', 'SI2'],\n",
    "    'FC': ['FC1', 'FC2'],\n",
    "    'HM': ['HM1', 'HM2'],\n",
    "    'PV': ['PV1', 'PV2'],\n",
    "    'HB': ['HB1', 'HB2'],\n",
    "    'VO': ['VO1', 'VO2'],\n",
    "    'TR': ['TR1', 'TR2'],\n",
    "    'EX': ['EX1', 'EX2'],\n",
    "    'ER': ['ER1', 'ER2'],\n",
    "    'AX': ['AX1', 'AX2'],\n",
    "}\n",
    "\n",
    "print(f\"Full sample: N = {len(df_full)}\")\n",
    "print(f\"Total predictor items: {len(ALL_PREDICTOR_ITEMS)}\")\n",
    "print(f\"Total constructs: {len(ALL_PREDICTOR_CONSTRUCTS)}\")\n",
    "print(f\"\\nConstructs: {list(ALL_PREDICTOR_CONSTRUCTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c80391",
   "metadata": {},
   "source": [
    "## 1.3 Descriptive Statistics - All Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for ALL items\n",
    "df_all_items = df_full[ALL_PREDICTOR_ITEMS].copy()\n",
    "\n",
    "desc_stats = df_all_items.describe().T\n",
    "desc_stats['skew'] = df_all_items.skew()\n",
    "desc_stats['kurtosis'] = df_all_items.kurtosis()\n",
    "desc_stats['construct'] = [metadata[item]['construct_abbr'] for item in desc_stats.index]\n",
    "\n",
    "# Add item text for reference\n",
    "desc_stats['item_text'] = [metadata[item]['question_text'][:50] + '...' for item in desc_stats.index]\n",
    "\n",
    "print(\"DESCRIPTIVE STATISTICS - ALL 24 PREDICTOR ITEMS\")\n",
    "print(\"=\" * 80)\n",
    "display(desc_stats[['construct', 'mean', 'std', 'min', 'max', 'skew', 'kurtosis']].round(3))\n",
    "\n",
    "# Flag potential issues\n",
    "skew_issues = desc_stats[abs(desc_stats['skew']) > 1.0]\n",
    "kurt_issues = desc_stats[abs(desc_stats['kurtosis']) > 3.0]\n",
    "\n",
    "if len(skew_issues) > 0:\n",
    "    print(f\"\\nâš ï¸ Items with |skewness| > 1.0: {list(skew_issues.index)}\")\n",
    "if len(kurt_issues) > 0:\n",
    "    print(f\"âš ï¸ Items with |kurtosis| > 3.0: {list(kurt_issues.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff287b97",
   "metadata": {},
   "source": [
    "## 1.4 Item Reference Guide\n",
    "\n",
    "Complete item text for informed selection decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ce3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full item reference\n",
    "print(\"=\" * 90)\n",
    "print(\"COMPLETE ITEM REFERENCE GUIDE\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for construct, items in ALL_PREDICTOR_CONSTRUCTS.items():\n",
    "    construct_name = metadata[items[0]]['construct']\n",
    "    print(f\"\\n{'â”€' * 90}\")\n",
    "    print(f\"ğŸ“‹ {construct}: {construct_name}\")\n",
    "    print(f\"{'â”€' * 90}\")\n",
    "    for item in items:\n",
    "        direction = metadata[item]['direction']\n",
    "        text = metadata[item]['question_text']\n",
    "        mean_val = df_all_items[item].mean()\n",
    "        std_val = df_all_items[item].std()\n",
    "        print(f\"  {item} [{direction:8}]: \\\"{text}\\\"\")\n",
    "        print(f\"           Mean={mean_val:.2f}, SD={std_val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b021",
   "metadata": {},
   "source": [
    "## 1.5 Within-Construct Reliability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-construct analysis functions\n",
    "def cronbach_alpha(data):\n",
    "    \"\"\"Calculate Cronbach's alpha for a set of items.\"\"\"\n",
    "    n_items = data.shape[1]\n",
    "    if n_items < 2:\n",
    "        return np.nan\n",
    "    item_vars = data.var(axis=0, ddof=1)\n",
    "    total_var = data.sum(axis=1).var(ddof=1)\n",
    "    return (n_items / (n_items - 1)) * (1 - item_vars.sum() / total_var)\n",
    "\n",
    "def item_total_correlation(df, items):\n",
    "    \"\"\"Calculate corrected item-total correlations.\"\"\"\n",
    "    results = {}\n",
    "    total = df[items].sum(axis=1)\n",
    "    for item in items:\n",
    "        # Corrected: exclude item from total\n",
    "        corrected_total = total - df[item]\n",
    "        results[item] = df[item].corr(corrected_total)\n",
    "    return results\n",
    "\n",
    "# Analyze each construct\n",
    "construct_diagnostics = []\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"WITHIN-CONSTRUCT RELIABILITY ANALYSIS - ALL CONSTRUCTS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for construct, items in ALL_PREDICTOR_CONSTRUCTS.items():\n",
    "    construct_name = metadata[items[0]]['construct']\n",
    "    construct_df = df_all_items[items]\n",
    "    \n",
    "    # Inter-item correlation\n",
    "    r = construct_df.corr().iloc[0, 1]\n",
    "    \n",
    "    # Cronbach's alpha\n",
    "    alpha = cronbach_alpha(construct_df)\n",
    "    \n",
    "    # Item-total correlations\n",
    "    itc = item_total_correlation(df_all_items, items)\n",
    "    \n",
    "    # Status assessment\n",
    "    if alpha >= 0.70:\n",
    "        status = \"âœ“ Good\"\n",
    "    elif alpha >= 0.60:\n",
    "        status = \"~ Marginal\"\n",
    "    else:\n",
    "        status = \"âœ— Poor\"\n",
    "    \n",
    "    construct_diagnostics.append({\n",
    "        'Construct': construct,\n",
    "        'Name': construct_name,\n",
    "        'Items': ', '.join(items),\n",
    "        'r_inter': r,\n",
    "        'Alpha': alpha,\n",
    "        'ITC_1': itc[items[0]],\n",
    "        'ITC_2': itc[items[1]],\n",
    "        'Status': status\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{construct} ({construct_name}):\")\n",
    "    print(f\"  Inter-item r = {r:.3f}\")\n",
    "    print(f\"  Cronbach's Î± = {alpha:.3f} {status}\")\n",
    "    print(f\"  {items[0]} ITC = {itc[items[0]]:.3f}\")\n",
    "    print(f\"  {items[1]} ITC = {itc[items[1]]:.3f}\")\n",
    "\n",
    "diagnostics_df = pd.DataFrame(construct_diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcadbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"CONSTRUCT RELIABILITY SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "display(diagnostics_df[['Construct', 'Name', 'r_inter', 'Alpha', 'ITC_1', 'ITC_2', 'Status']].round(3))\n",
    "\n",
    "# Classification counts\n",
    "good = len(diagnostics_df[diagnostics_df['Alpha'] >= 0.70])\n",
    "marginal = len(diagnostics_df[(diagnostics_df['Alpha'] >= 0.60) & (diagnostics_df['Alpha'] < 0.70)])\n",
    "poor = len(diagnostics_df[diagnostics_df['Alpha'] < 0.60])\n",
    "\n",
    "print(f\"\\nâœ“ Good reliability (Î± â‰¥ .70): {good}/12 constructs\")\n",
    "print(f\"~ Marginal reliability (.60 â‰¤ Î± < .70): {marginal}/12 constructs\")\n",
    "print(f\"âœ— Poor reliability (Î± < .60): {poor}/12 constructs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbabe05",
   "metadata": {},
   "source": [
    "## 1.6 Within-Construct Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd83503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualization\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (construct, items) in enumerate(ALL_PREDICTOR_CONSTRUCTS.items()):\n",
    "    ax = axes[idx]\n",
    "    construct_df = df_all_items[items]\n",
    "    corr = construct_df.corr()\n",
    "    \n",
    "    alpha_val = diagnostics_df[diagnostics_df['Construct'] == construct]['Alpha'].values[0]\n",
    "    status = diagnostics_df[diagnostics_df['Construct'] == construct]['Status'].values[0]\n",
    "    \n",
    "    color = 'darkgreen' if 'Good' in status else ('goldenrod' if 'Marginal' in status else 'darkred')\n",
    "    \n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdYlGn', center=0.5,\n",
    "               vmin=0, vmax=1, ax=ax, cbar=False,\n",
    "               xticklabels=items, yticklabels=items)\n",
    "    ax.set_title(f\"{construct} (Î±={alpha_val:.2f})\", fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Within-Construct Inter-Item Correlations\\n(Green title = Good Î±, Yellow = Marginal, Red = Poor)', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/phase1_within_construct_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523aa9c",
   "metadata": {},
   "source": [
    "## 1.7 Item-Level Diagnostics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive item diagnostics\n",
    "item_diagnostics = []\n",
    "\n",
    "for item in ALL_PREDICTOR_ITEMS:\n",
    "    construct = metadata[item]['construct_abbr']\n",
    "    direction = metadata[item]['direction']\n",
    "    \n",
    "    # Find ITC from construct analysis\n",
    "    construct_items = ALL_PREDICTOR_CONSTRUCTS[construct]\n",
    "    itc_dict = item_total_correlation(df_all_items, construct_items)\n",
    "    \n",
    "    # Item stats\n",
    "    mean_val = df_all_items[item].mean()\n",
    "    std_val = df_all_items[item].std()\n",
    "    skew_val = df_all_items[item].skew()\n",
    "    kurt_val = df_all_items[item].kurtosis()\n",
    "    \n",
    "    # Flags\n",
    "    issues = []\n",
    "    if abs(skew_val) > 1.0:\n",
    "        issues.append('SKEW')\n",
    "    if abs(kurt_val) > 3.0:\n",
    "        issues.append('KURT')\n",
    "    if itc_dict[item] < 0.30:\n",
    "        issues.append('LOW_ITC')\n",
    "    \n",
    "    item_diagnostics.append({\n",
    "        'Item': item,\n",
    "        'Construct': construct,\n",
    "        'Direction': direction,\n",
    "        'Mean': mean_val,\n",
    "        'SD': std_val,\n",
    "        'Skew': skew_val,\n",
    "        'Kurt': kurt_val,\n",
    "        'ITC': itc_dict[item],\n",
    "        'Issues': ', '.join(issues) if issues else 'âœ“'\n",
    "    })\n",
    "\n",
    "item_diag_df = pd.DataFrame(item_diagnostics)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"ITEM-LEVEL DIAGNOSTICS SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "display(item_diag_df.round(3))\n",
    "\n",
    "# Flag problem items\n",
    "problem_items = item_diag_df[item_diag_df['Issues'] != 'âœ“']\n",
    "if len(problem_items) > 0:\n",
    "    print(f\"\\nâš ï¸ ITEMS WITH POTENTIAL ISSUES ({len(problem_items)}):\")\n",
    "    for _, row in problem_items.iterrows():\n",
    "        print(f\"   {row['Item']} ({row['Construct']}): {row['Issues']}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All items pass basic diagnostics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606e602",
   "metadata": {},
   "source": [
    "## 1.8 KMO and Bartlett's Test (All Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMO and Bartlett's on ALL items\n",
    "kmo_all, kmo_model = calculate_kmo(df_all_items)\n",
    "chi_square, p_value = calculate_bartlett_sphericity(df_all_items)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"FACTORABILITY ASSESSMENT - ALL 24 ITEMS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\\nKMO Measure of Sampling Adequacy: {kmo_model:.3f}\")\n",
    "if kmo_model >= 0.90:\n",
    "    kmo_interpretation = \"Marvelous\"\n",
    "elif kmo_model >= 0.80:\n",
    "    kmo_interpretation = \"Meritorious\"\n",
    "elif kmo_model >= 0.70:\n",
    "    kmo_interpretation = \"Middling\"\n",
    "elif kmo_model >= 0.60:\n",
    "    kmo_interpretation = \"Mediocre\"\n",
    "elif kmo_model >= 0.50:\n",
    "    kmo_interpretation = \"Miserable\"\n",
    "else:\n",
    "    kmo_interpretation = \"Unacceptable\"\n",
    "print(f\"  Interpretation: {kmo_interpretation} (Kaiser, 1974)\")\n",
    "\n",
    "print(f\"\\nBartlett's Test of Sphericity:\")\n",
    "print(f\"  Chi-square: {chi_square:.2f}\")\n",
    "print(f\"  p-value: {p_value:.2e}\")\n",
    "print(f\"  Result: {'âœ“ Significant' if p_value < 0.001 else 'âœ— Not significant'}\")\n",
    "\n",
    "# Item-level KMO\n",
    "print(f\"\\nItem-level KMO (flagged if < 0.50):\")\n",
    "low_kmo_items = [(ALL_PREDICTOR_ITEMS[i], kmo_all[i]) for i in range(len(ALL_PREDICTOR_ITEMS)) if kmo_all[i] < 0.50]\n",
    "if low_kmo_items:\n",
    "    for item, kmo in low_kmo_items:\n",
    "        print(f\"  âš ï¸ {item}: {kmo:.3f}\")\n",
    "else:\n",
    "    print(\"  âœ“ All items have KMO â‰¥ 0.50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58199c7",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ DECISION POINT 1: SELECT CONSTRUCTS AND ITEMS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Based on the diagnostics above, decide which items to include in the EFA.\n",
    "\n",
    "**Considerations:**\n",
    "- Constructs with poor reliability (Î± < .60) may not hold together\n",
    "- Items with low ITC (< .30) may not contribute to their construct\n",
    "- Items with extreme skewness or kurtosis may cause issues\n",
    "- Theoretical relevance to your population\n",
    "\n",
    "**Edit the `SELECTED_ITEMS` dictionary below to customize your selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ¯ DECISION POINT 1: EDIT THIS DICTIONARY TO SELECT ITEMS                   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ITEM REFERENCE (for cherry-picking decisions)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PE - Performance Expectancy (POSITIVE)\n",
    "#   PE1: \"AI tools help me accomplish tasks more quickly.\"\n",
    "#   PE2: \"Using AI improves the quality of my work or studies.\"\n",
    "#\n",
    "# EE - Effort Expectancy (POSITIVE)\n",
    "#   EE1: \"Learning to use AI tools is easy for me.\"\n",
    "#   EE2: \"Interacting with AI tools is clear and understandable.\"\n",
    "#\n",
    "# SI - Social Influence (POSITIVE)\n",
    "#   SI1: \"People whose opinions I value encourage me to use AI tools.\"\n",
    "#   SI2: \"Leaders in my organization or school support the use of AI tools.\"\n",
    "#\n",
    "# FC - Facilitating Conditions (POSITIVE)\n",
    "#   FC1: \"I have access to training or tutorials for the AI tools I use.\"\n",
    "#   FC2: \"The AI tools I use are compatible with other tools or systems I use.\"\n",
    "#\n",
    "# HM - Hedonic Motivation (POSITIVE)\n",
    "#   HM1: \"Using AI tools is stimulating and engaging.\"\n",
    "#   HM2: \"AI tools make my work or studies more interesting.\"\n",
    "#\n",
    "# PV - Price Value (POSITIVE)\n",
    "#   PV1: \"I get more value from AI tools than the effort they require.\"\n",
    "#   PV2: \"Using AI tools is worth the learning curve.\"\n",
    "#\n",
    "# HB - Habit (POSITIVE)\n",
    "#   HB1: \"Using AI tools has become a habit for me.\"\n",
    "#   HB2: \"I tend to rely on AI tools by default when I need help with tasks.\"\n",
    "#\n",
    "# VO - Voluntariness (POSITIVE)\n",
    "#   VO1: \"I choose to use AI tools in my work because I find them helpful, not because I am required to.\"\n",
    "#   VO2: \"I could choose not to use AI tools in my work or studies if I preferred.\"\n",
    "#\n",
    "# TR - Trust in AI (POSITIVE)\n",
    "#   TR1: \"I trust AI tools to provide reliable information.\"\n",
    "#   TR2: \"I trust the AI tools that are available to me.\"\n",
    "#\n",
    "# EX - Explainability (POSITIVE)\n",
    "#   EX1: \"I understand how the AI tools I use generate their outputs.\"\n",
    "#   EX2: \"I prefer AI tools that explain their recommendations.\"\n",
    "#\n",
    "# ER - Perceived Ethical Risk (NEGATIVE)\n",
    "#   ER1: \"I worry that AI tools could replace jobs in my field.\"\n",
    "#   ER2: \"I am concerned about privacy risks when using AI tools.\"\n",
    "#\n",
    "# AX - AI Anxiety (MIXED)\n",
    "#   AX1: \"I feel uneasy about the increasing use of AI.\" (NEGATIVE)\n",
    "#   AX2: \"I worry that I may be left behind if I do not keep up with AI.\" (POSITIVE - FOMO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "SELECTED_ITEMS = {\n",
    "    'PE': ['PE1', 'PE2'],  # Performance Expectancy\n",
    "    'EE': ['EE1', 'EE2'],  # Effort Expectancy\n",
    "    'SI': ['SI1', 'SI2'],  # Social Influence\n",
    "    'FC': ['FC1', 'FC2'],  # Facilitating Conditions\n",
    "    'HM': ['HM1', 'HM2'],  # Hedonic Motivation\n",
    "    'PV': ['PV1', 'PV2'],  # Price Value\n",
    "    'HB': ['HB1', 'HB2'],  # Habit\n",
    "    'VO': ['VO1', 'VO2'],  # Voluntariness\n",
    "    'TR': ['TR1', 'TR2'],  # Trust in AI\n",
    "    'EX': ['EX1', 'EX2'],  # Explainability\n",
    "    'ER': ['ER1', 'ER2'],  # Perceived Ethical Risk (NEGATIVE)\n",
    "    'AX': ['AX1', 'AX2'],  # AI Anxiety (MIXED direction)\n",
    "}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Apply selection and update working variables\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "selected_predictor_items = [item for items in SELECTED_ITEMS.values() for item in items]\n",
    "selected_predictor_constructs = {k: v for k, v in SELECTED_ITEMS.items() if v}\n",
    "\n",
    "# Create EFA dataframe with selected items\n",
    "df_efa = df_full[selected_predictor_items].copy()\n",
    "\n",
    "# Update global references\n",
    "predictor_items = selected_predictor_items\n",
    "predictor_constructs = selected_predictor_constructs\n",
    "\n",
    "# Summary\n",
    "total_selected = len(predictor_items)\n",
    "constructs_active = len([k for k, v in SELECTED_ITEMS.items() if v])\n",
    "constructs_full = len([k for k, v in SELECTED_ITEMS.items() if len(v) == 2])\n",
    "constructs_partial = len([k for k, v in SELECTED_ITEMS.items() if len(v) == 1])\n",
    "constructs_dropped = len([k for k, v in SELECTED_ITEMS.items() if len(v) == 0])\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"ğŸ¯ DECISION POINT 1 - ITEM SELECTION APPLIED\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nğŸ“Š Selection Summary:\")\n",
    "print(f\"   Total items selected: {total_selected}/24\")\n",
    "print(f\"   Active constructs: {constructs_active}/12\")\n",
    "print(f\"     - Full (2 items): {constructs_full}\")\n",
    "print(f\"     - Partial (1 item): {constructs_partial}\")\n",
    "print(f\"     - Dropped (0 items): {constructs_dropped}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Selected Items by Construct:\")\n",
    "for construct, items in SELECTED_ITEMS.items():\n",
    "    if items:\n",
    "        print(f\"   {construct}: {', '.join(items)}\")\n",
    "    else:\n",
    "        print(f\"   {construct}: [DROPPED]\")\n",
    "\n",
    "print(f\"\\nâœ“ df_efa ready: {df_efa.shape[0]} observations Ã— {df_efa.shape[1]} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47bfae",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 2: FACTOR EXPLORATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a118591",
   "metadata": {},
   "source": [
    "## 2.1 Parallel Analysis & Kaiser Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6020ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue analysis\n",
    "fa_eigen = FactorAnalyzer(rotation=None, n_factors=len(predictor_items))\n",
    "fa_eigen.fit(df_efa)\n",
    "ev, v = fa_eigen.get_eigenvalues()\n",
    "\n",
    "# Parallel analysis\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "def parallel_analysis(data, n_iterations=100, percentile=95):\n",
    "    \"\"\"Perform parallel analysis to determine number of factors.\"\"\"\n",
    "    n_obs, n_vars = data.shape\n",
    "    random_eigenvalues = np.zeros((n_iterations, n_vars))\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        random_data = np.random.normal(size=(n_obs, n_vars))\n",
    "        random_corr = np.corrcoef(random_data, rowvar=False)\n",
    "        random_eigenvalues[i] = np.linalg.eigvalsh(random_corr)[::-1]\n",
    "    \n",
    "    return np.percentile(random_eigenvalues, percentile, axis=0)\n",
    "\n",
    "random_ev = parallel_analysis(df_efa.values)\n",
    "\n",
    "# Determine factors by different criteria\n",
    "n_factors_kaiser = sum(ev > 1)\n",
    "n_factors_pa = sum(ev > random_ev)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"FACTOR EXTRACTION CRITERIA\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\\n{'Factor':<8} {'Eigenvalue':<12} {'Random EV':<12} {'Kaiser':<10} {'PA':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(min(12, len(ev))):\n",
    "    kaiser = \"âœ“\" if ev[i] > 1 else \"\"\n",
    "    pa = \"âœ“\" if ev[i] > random_ev[i] else \"\"\n",
    "    print(f\"F{i+1:<7} {ev[i]:<12.3f} {random_ev[i]:<12.3f} {kaiser:<10} {pa:<10}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Recommendations:\")\n",
    "print(f\"   Kaiser criterion (Î» > 1): {n_factors_kaiser} factors\")\n",
    "print(f\"   Parallel analysis: {n_factors_pa} factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot with parallel analysis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = range(1, len(ev) + 1)\n",
    "ax.plot(x, ev, 'bo-', linewidth=2, markersize=8, label='Actual Eigenvalues')\n",
    "ax.plot(x, random_ev, 'r--', linewidth=2, label='Parallel Analysis (95th percentile)')\n",
    "ax.axhline(y=1, color='gray', linestyle=':', label='Kaiser Criterion (Î»=1)')\n",
    "\n",
    "ax.set_xlabel('Factor Number', fontsize=12)\n",
    "ax.set_ylabel('Eigenvalue', fontsize=12)\n",
    "ax.set_title('Scree Plot with Parallel Analysis', fontsize=14)\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, len(ev) + 1))\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/phase2_scree_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Scree plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a14900",
   "metadata": {},
   "source": [
    "## 2.2 Full Factor Solution (All Possible Factors)\n",
    "\n",
    "Exploring ALL factors to identify which have meaningful loadings, regardless of eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit maximum factors (up to 12 or number of items)\n",
    "n_factors_max = min(12, len(predictor_items))\n",
    "\n",
    "print(f\"Fitting EFA with {n_factors_max} factors (maximum exploration)\")\n",
    "print(f\"  Estimator: MINRES\")\n",
    "print(f\"  Rotation: Promax (oblique)\")\n",
    "\n",
    "efa_full = FactorAnalyzer(n_factors=n_factors_max, rotation='promax', method='minres')\n",
    "efa_full.fit(df_efa)\n",
    "\n",
    "# Get variance explained\n",
    "var_full = efa_full.get_factor_variance()\n",
    "eigenvalues_full = var_full[0]\n",
    "prop_var_full = var_full[1]\n",
    "cum_var_full = var_full[2]\n",
    "\n",
    "print(f\"\\n{'Factor':<8} {'SS Loading':<12} {'% Variance':<12} {'Cumulative %':<12} {'Strength':<15}\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(n_factors_max):\n",
    "    if eigenvalues_full[i] >= 1.0:\n",
    "        strength = \"â˜…â˜…â˜… Strong\"\n",
    "    elif eigenvalues_full[i] >= 0.5:\n",
    "        strength = \"â˜…â˜… Moderate\"\n",
    "    elif eigenvalues_full[i] >= 0.3:\n",
    "        strength = \"â˜… Weak\"\n",
    "    else:\n",
    "        strength = \"âœ— Minimal\"\n",
    "    print(f\"F{i+1:<7} {eigenvalues_full[i]:<12.3f} {prop_var_full[i]*100:<12.1f} {cum_var_full[i]*100:<12.1f} {strength}\")\n",
    "\n",
    "print(f\"\\nTotal variance explained: {cum_var_full[-1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc1106",
   "metadata": {},
   "source": [
    "## 2.3 Full Pattern Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern matrix\n",
    "loadings_full = pd.DataFrame(\n",
    "    efa_full.loadings_,\n",
    "    index=predictor_items,\n",
    "    columns=[f'F{i+1}' for i in range(n_factors_max)]\n",
    ")\n",
    "\n",
    "# Add construct labels\n",
    "loadings_full['Construct'] = [metadata[item]['construct_abbr'] for item in loadings_full.index]\n",
    "\n",
    "# Highlighting function\n",
    "def highlight_loadings(val):\n",
    "    if abs(val) >= 0.50:\n",
    "        return 'background-color: darkgreen; color: white; font-weight: bold'\n",
    "    elif abs(val) >= 0.32:\n",
    "        return 'background-color: goldenrod; color: white'\n",
    "    return ''\n",
    "\n",
    "print(\"FULL PATTERN MATRIX\")\n",
    "print(\"Green â‰¥ 0.50 (strong), Yellow â‰¥ 0.32 (moderate)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "factor_cols = [f'F{i+1}' for i in range(n_factors_max)]\n",
    "styled = loadings_full[factor_cols + ['Construct']].style.applymap(\n",
    "    highlight_loadings, subset=factor_cols\n",
    ").format('{:.3f}', subset=factor_cols)\n",
    "display(styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11f882",
   "metadata": {},
   "source": [
    "## 2.4 Factor Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each factor's quality\n",
    "print(\"=\" * 90)\n",
    "print(\"FACTOR QUALITY ANALYSIS (by loading strength)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "factor_quality = []\n",
    "\n",
    "for i in range(n_factors_max):\n",
    "    factor_name = f'F{i+1}'\n",
    "    factor_loadings = loadings_full[factor_name]\n",
    "    abs_loadings = factor_loadings.abs()\n",
    "    \n",
    "    # Count items by loading strength\n",
    "    strong_items = loadings_full[abs_loadings >= 0.50].index.tolist()\n",
    "    moderate_items = loadings_full[(abs_loadings >= 0.32) & (abs_loadings < 0.50)].index.tolist()\n",
    "    \n",
    "    # Check cross-loading issues\n",
    "    cross_loading_issues = []\n",
    "    for item in strong_items:\n",
    "        other_factors = [f'F{j+1}' for j in range(n_factors_max) if j != i]\n",
    "        other_loadings = loadings_full.loc[item, other_factors].abs()\n",
    "        if other_loadings.max() >= 0.32:\n",
    "            cross_factor = other_loadings.idxmax()\n",
    "            cross_loading_issues.append(f\"{item}â†’{cross_factor}\")\n",
    "    \n",
    "    # Get constructs loading on this factor\n",
    "    constructs = [metadata[item]['construct_abbr'] for item in strong_items]\n",
    "    unique_constructs = list(set(constructs))\n",
    "    \n",
    "    # Quality rating\n",
    "    if len(strong_items) >= 2 and len(cross_loading_issues) == 0:\n",
    "        quality = \"â˜…â˜…â˜… RETAIN (clean, multi-item)\"\n",
    "    elif len(strong_items) >= 2:\n",
    "        quality = \"â˜…â˜… RETAIN (minor cross-loading)\"\n",
    "    elif len(strong_items) == 1 and len(cross_loading_issues) == 0:\n",
    "        quality = \"â˜… CONSIDER (single-item, clean)\"\n",
    "    else:\n",
    "        quality = \"âœ— SKIP\"\n",
    "    \n",
    "    factor_quality.append({\n",
    "        'Factor': factor_name,\n",
    "        'Eigenvalue': eigenvalues_full[i],\n",
    "        'Strong_Items': len(strong_items),\n",
    "        'Cross_Loadings': len(cross_loading_issues),\n",
    "        'Constructs': unique_constructs,\n",
    "        'Quality': quality\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{factor_name} (Î»={eigenvalues_full[i]:.2f}): {quality}\")\n",
    "    if strong_items:\n",
    "        print(f\"   Strong items: {', '.join(strong_items)}\")\n",
    "        print(f\"   Constructs: {', '.join(unique_constructs)}\")\n",
    "    if cross_loading_issues:\n",
    "        print(f\"   âš ï¸ Cross-loadings: {', '.join(cross_loading_issues)}\")\n",
    "\n",
    "quality_df = pd.DataFrame(factor_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor quality summary table\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FACTOR QUALITY SUMMARY TABLE\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "display(quality_df)\n",
    "\n",
    "# Recommendations\n",
    "retain_factors = quality_df[quality_df['Quality'].str.contains('RETAIN')]\n",
    "consider_factors = quality_df[quality_df['Quality'].str.contains('CONSIDER')]\n",
    "\n",
    "print(f\"\\nğŸ“Š Factor Recommendations:\")\n",
    "print(f\"   â˜…â˜…â˜…/â˜…â˜… RETAIN: {len(retain_factors)} factors - {list(retain_factors['Factor'])}\")\n",
    "print(f\"   â˜… CONSIDER: {len(consider_factors)} factors - {list(consider_factors['Factor'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180f5e9",
   "metadata": {},
   "source": [
    "## 2.5 Construct-to-Factor Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274eb582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which factors each construct's items load on\n",
    "print(\"=\" * 90)\n",
    "print(\"CONSTRUCT-TO-FACTOR MAPPING\")\n",
    "print(\"=\" * 90)\n",
    "print(\"Where do items from each theoretical construct load?\")\n",
    "\n",
    "for construct in loadings_full['Construct'].unique():\n",
    "    construct_items = loadings_full[loadings_full['Construct'] == construct]\n",
    "    print(f\"\\n{construct}:\")\n",
    "    for item in construct_items.index:\n",
    "        item_loadings = loadings_full.loc[item, factor_cols]\n",
    "        max_factor = item_loadings.abs().idxmax()\n",
    "        max_loading = item_loadings[max_factor]\n",
    "        \n",
    "        # Find any cross-loadings\n",
    "        sorted_loadings = item_loadings.abs().sort_values(ascending=False)\n",
    "        secondary = sorted_loadings.index[1] if len(sorted_loadings) > 1 else None\n",
    "        secondary_loading = item_loadings[secondary] if secondary else 0\n",
    "        \n",
    "        cross = f\" (also {secondary}: {secondary_loading:+.2f})\" if abs(secondary_loading) >= 0.32 else \"\"\n",
    "        print(f\"   {item} â†’ {max_factor} ({max_loading:+.3f}){cross}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321b247",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ DECISION POINT 2: SELECT FACTORS TO RETAIN\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Based on the factor exploration above, decide which factors to retain.\n",
    "\n",
    "**Considerations:**\n",
    "- Factors with strong loadings (â‰¥ 0.50) on multiple items are preferred\n",
    "- Clean factors (no cross-loadings â‰¥ 0.32) are easier to interpret\n",
    "- Single-item factors are acceptable if theoretically meaningful\n",
    "- Consider theoretical interpretability (do the items make sense together?)\n",
    "\n",
    "**Edit the `SELECTED_FACTORS` list below to customize your selection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ¯ DECISION POINT 2: EDIT THIS LIST TO SELECT FACTORS                       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Based on the factor quality analysis above, select which factors to retain\n",
    "# Example: SELECTED_FACTORS = ['F1', 'F2', 'F3', 'F6']\n",
    "\n",
    "SELECTED_FACTORS = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6']  # <-- EDIT THIS LIST\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"ğŸ¯ DECISION POINT 2 - FACTOR SELECTION\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nSelected factors: {SELECTED_FACTORS}\")\n",
    "print(f\"Number of factors: {len(SELECTED_FACTORS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd8542",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PHASE 3: FINAL MODEL & VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2330fe",
   "metadata": {},
   "source": [
    "## 3.1 Build Cherry-Picked Factor Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build selected factor solution\n",
    "selected_loadings = loadings_full[SELECTED_FACTORS + ['Construct']].copy()\n",
    "\n",
    "# Assign items to factors\n",
    "item_assignments = []\n",
    "for item in selected_loadings.index:\n",
    "    item_loadings = selected_loadings.loc[item, SELECTED_FACTORS]\n",
    "    primary_factor = item_loadings.abs().idxmax()\n",
    "    primary_loading = item_loadings[primary_factor]\n",
    "    \n",
    "    max_abs_loading = item_loadings.abs().max()\n",
    "    if max_abs_loading >= 0.40:\n",
    "        status = \"âœ“ Assigned\"\n",
    "    elif max_abs_loading >= 0.32:\n",
    "        status = \"~ Marginal\"\n",
    "    else:\n",
    "        status = \"âœ— Unassigned\"\n",
    "    \n",
    "    item_assignments.append({\n",
    "        'Item': item,\n",
    "        'Construct': metadata[item]['construct_abbr'],\n",
    "        'Primary_Factor': primary_factor,\n",
    "        'Loading': primary_loading,\n",
    "        'Status': status\n",
    "    })\n",
    "\n",
    "assignment_df = pd.DataFrame(item_assignments)\n",
    "\n",
    "# Display by factor\n",
    "print(\"=\" * 90)\n",
    "print(f\"CHERRY-PICKED {len(SELECTED_FACTORS)}-FACTOR SOLUTION\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for factor in SELECTED_FACTORS:\n",
    "    factor_items = assignment_df[\n",
    "        (assignment_df['Primary_Factor'] == factor) & \n",
    "        (assignment_df['Status'].isin(['âœ“ Assigned', '~ Marginal']))\n",
    "    ]\n",
    "    print(f\"\\n{factor}:\")\n",
    "    for _, row in factor_items.iterrows():\n",
    "        print(f\"   {row['Item']} ({row['Construct']}): {row['Loading']:+.3f} {row['Status']}\")\n",
    "\n",
    "# Unassigned items\n",
    "unassigned = assignment_df[assignment_df['Status'] == 'âœ— Unassigned']\n",
    "if len(unassigned) > 0:\n",
    "    print(f\"\\nâš ï¸ UNASSIGNED ITEMS ({len(unassigned)}):\")\n",
    "    for _, row in unassigned.iterrows():\n",
    "        print(f\"   {row['Item']} ({row['Construct']}): max loading = {row['Loading']:+.3f}\")\n",
    "\n",
    "# Statistics\n",
    "assigned_count = len(assignment_df[assignment_df['Status'] == 'âœ“ Assigned'])\n",
    "marginal_count = len(assignment_df[assignment_df['Status'] == '~ Marginal'])\n",
    "unassigned_count = len(unassigned)\n",
    "\n",
    "print(f\"\\nğŸ“Š Assignment Statistics:\")\n",
    "print(f\"   Items assigned (â‰¥.40): {assigned_count}/{len(predictor_items)}\")\n",
    "print(f\"   Items marginal (.32-.40): {marginal_count}\")\n",
    "print(f\"   Items unassigned (<.32): {unassigned_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2f10a",
   "metadata": {},
   "source": [
    "## 3.2 Factor Reliability Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reliability for each factor\n",
    "print(\"=\" * 90)\n",
    "print(\"FACTOR RELIABILITY ASSESSMENT\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "def calculate_cronbach_alpha(data):\n",
    "    \"\"\"Calculate Cronbach's alpha.\"\"\"\n",
    "    n_items = data.shape[1]\n",
    "    if n_items < 2:\n",
    "        return np.nan\n",
    "    item_vars = data.var(axis=0, ddof=1)\n",
    "    total_var = data.sum(axis=1).var(ddof=1)\n",
    "    return (n_items / (n_items - 1)) * (1 - item_vars.sum() / total_var)\n",
    "\n",
    "factor_reliability = []\n",
    "\n",
    "for factor in SELECTED_FACTORS:\n",
    "    factor_items = assignment_df[\n",
    "        (assignment_df['Primary_Factor'] == factor) & \n",
    "        (assignment_df['Loading'].abs() >= 0.40)\n",
    "    ]['Item'].tolist()\n",
    "    \n",
    "    if len(factor_items) >= 2:\n",
    "        alpha = calculate_cronbach_alpha(df_efa[factor_items])\n",
    "        constructs = [metadata[item]['construct_abbr'] for item in factor_items]\n",
    "        primary_construct = pd.Series(constructs).mode()[0]\n",
    "        status = 'âœ“ Good' if alpha >= 0.70 else ('~ Marginal' if alpha >= 0.60 else 'âœ— Poor')\n",
    "        \n",
    "        factor_reliability.append({\n",
    "            'Factor': factor,\n",
    "            'N_Items': len(factor_items),\n",
    "            'Items': ', '.join(factor_items),\n",
    "            'Primary_Construct': primary_construct,\n",
    "            'Alpha': alpha,\n",
    "            'Status': status\n",
    "        })\n",
    "        print(f\"\\n{factor} ({primary_construct}): Î± = {alpha:.3f} {status}\")\n",
    "        print(f\"   Items: {', '.join(factor_items)}\")\n",
    "    elif len(factor_items) == 1:\n",
    "        factor_reliability.append({\n",
    "            'Factor': factor,\n",
    "            'N_Items': 1,\n",
    "            'Items': factor_items[0],\n",
    "            'Primary_Construct': metadata[factor_items[0]]['construct_abbr'],\n",
    "            'Alpha': np.nan,\n",
    "            'Status': 'â€” Single item'\n",
    "        })\n",
    "        print(f\"\\n{factor}: Single-item ({factor_items[0]})\")\n",
    "    else:\n",
    "        print(f\"\\n{factor}: No items assigned\")\n",
    "\n",
    "reliability_df = pd.DataFrame(factor_reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reliability summary table\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"RELIABILITY SUMMARY TABLE\")\n",
    "print(\"=\" * 90)\n",
    "display(reliability_df)\n",
    "\n",
    "# Count good reliability\n",
    "multi_item = reliability_df[reliability_df['N_Items'] >= 2]\n",
    "good_alpha = len(multi_item[multi_item['Alpha'] >= 0.70])\n",
    "total_multi = len(multi_item)\n",
    "\n",
    "print(f\"\\nğŸ“Š Reliability Summary:\")\n",
    "print(f\"   Multi-item factors: {total_multi}/{len(SELECTED_FACTORS)}\")\n",
    "print(f\"   Good reliability (Î± â‰¥ .70): {good_alpha}/{total_multi}\")\n",
    "print(f\"   Single-item factors: {len(reliability_df[reliability_df['N_Items'] == 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de11949",
   "metadata": {},
   "source": [
    "## 3.3 Pattern Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of selected factor loadings\n",
    "plt.figure(figsize=(12, max(8, len(predictor_items) * 0.4)))\n",
    "\n",
    "heatmap_data = selected_loadings[SELECTED_FACTORS].copy()\n",
    "\n",
    "# Add construct grouping\n",
    "heatmap_data['Construct'] = selected_loadings['Construct']\n",
    "heatmap_data = heatmap_data.sort_values('Construct')\n",
    "\n",
    "sns.heatmap(heatmap_data[SELECTED_FACTORS], \n",
    "            annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            yticklabels=[f\"{idx} ({heatmap_data.loc[idx, 'Construct']})\" for idx in heatmap_data.index])\n",
    "\n",
    "plt.title(f'Cherry-Picked {len(SELECTED_FACTORS)}-Factor Pattern Matrix\\n(Items grouped by construct)', fontsize=14)\n",
    "plt.xlabel('Factor')\n",
    "plt.ylabel('Item (Construct)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/phase3_pattern_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Pattern matrix saved to plots/phase3_pattern_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b0747",
   "metadata": {},
   "source": [
    "## 3.4 Factor Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75623d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor correlations (from full solution, subset to selected)\n",
    "if hasattr(efa_full, 'phi_'):\n",
    "    factor_corr_full = pd.DataFrame(\n",
    "        efa_full.phi_,\n",
    "        index=[f'F{i+1}' for i in range(n_factors_max)],\n",
    "        columns=[f'F{i+1}' for i in range(n_factors_max)]\n",
    "    )\n",
    "    factor_corr = factor_corr_full.loc[SELECTED_FACTORS, SELECTED_FACTORS]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    mask = np.triu(np.ones_like(factor_corr, dtype=bool), k=1)\n",
    "    sns.heatmap(factor_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "               vmin=-1, vmax=1, mask=mask)\n",
    "    plt.title('Factor Intercorrelations (Promax rotation)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/phase3_factor_correlations.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Factor correlation matrix saved\")\n",
    "else:\n",
    "    print(\"Factor correlations not available (orthogonal rotation used)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d34915",
   "metadata": {},
   "source": [
    "## 3.5 Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a045bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results\n",
    "print(\"=\" * 90)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# 1. Pattern matrix\n",
    "loadings_export = selected_loadings.copy()\n",
    "loadings_export.to_csv('tables/pattern_matrix.csv')\n",
    "print(\"âœ“ tables/pattern_matrix.csv\")\n",
    "\n",
    "# 2. Item assignments\n",
    "assignment_df.to_csv('tables/item_assignments.csv', index=False)\n",
    "print(\"âœ“ tables/item_assignments.csv\")\n",
    "\n",
    "# 3. Factor reliability\n",
    "reliability_df.to_csv('tables/factor_reliability.csv', index=False)\n",
    "print(\"âœ“ tables/factor_reliability.csv\")\n",
    "\n",
    "# 4. Item diagnostics\n",
    "item_diag_df.to_csv('tables/item_diagnostics.csv', index=False)\n",
    "print(\"âœ“ tables/item_diagnostics.csv\")\n",
    "\n",
    "# 5. Full loadings for reference\n",
    "loadings_full.to_csv('tables/full_pattern_matrix.csv')\n",
    "print(\"âœ“ tables/full_pattern_matrix.csv\")\n",
    "\n",
    "# 6. JSON summary\n",
    "summary = {\n",
    "    'population': POPULATION,\n",
    "    'n_observations': len(df_full),\n",
    "    'n_items_selected': len(predictor_items),\n",
    "    'n_factors_selected': len(SELECTED_FACTORS),\n",
    "    'selected_items': SELECTED_ITEMS,\n",
    "    'selected_factors': SELECTED_FACTORS,\n",
    "    'kmo': float(kmo_model),\n",
    "    'bartlett_chi2': float(chi_square),\n",
    "    'variance_explained': float(cum_var_full[len(SELECTED_FACTORS)-1]) if len(SELECTED_FACTORS) <= len(cum_var_full) else None\n",
    "}\n",
    "\n",
    "with open('tables/efa_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"âœ“ tables/efa_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29b364",
   "metadata": {},
   "source": [
    "## 3.6 APA Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate APA-formatted summary\n",
    "n_obs = len(df_full)\n",
    "n_items = len(predictor_items)\n",
    "n_factors_final = len(SELECTED_FACTORS)\n",
    "\n",
    "# Calculate total variance for selected factors\n",
    "total_var_selected = sum([eigenvalues_full[int(f[1:])-1] for f in SELECTED_FACTORS])\n",
    "total_var_all = sum(eigenvalues_full)\n",
    "var_pct = (total_var_selected / total_var_all) * 100 if total_var_all > 0 else 0\n",
    "\n",
    "apa_summary = f\"\"\"\n",
    "## APA-Formatted Method Summary\n",
    "\n",
    "### Exploratory Factor Analysis - {POPULATION.title()} Sample\n",
    "\n",
    "An exploratory factor analysis (EFA) was conducted on {n_items} predictor items using the \n",
    "full sample (*N* = {n_obs}). Prior to analysis, the suitability of the data for factor \n",
    "analysis was assessed. The Kaiser-Meyer-Olkin measure of sampling adequacy was {kmo_model:.2f}, \n",
    "indicating {kmo_interpretation.lower()} factorability (Kaiser, 1974). Bartlett's test of sphericity \n",
    "was significant, Ï‡Â²({n_items * (n_items - 1) // 2}) = {chi_square:.2f}, *p* < .001, indicating that \n",
    "correlations between items were sufficiently large for factor analysis.\n",
    "\n",
    "Factor extraction was performed using the MINRES method with oblique rotation (Promax). \n",
    "Initial parallel analysis suggested {n_factors_pa} factors, while the Kaiser criterion \n",
    "suggested {n_factors_kaiser} factors. After examining the full {n_factors_max}-factor solution, \n",
    "a {n_factors_final}-factor solution was selected based on loading quality, theoretical \n",
    "interpretability, and construct coherence.\n",
    "\n",
    "The {n_factors_final}-factor solution explained approximately {var_pct:.1f}% of the extracted \n",
    "variance. Items were retained if they demonstrated a primary loading â‰¥ .40 on their assigned \n",
    "factor. Of the {n_items} items analyzed, {assigned_count} were assigned to factors with \n",
    "acceptable loadings.\n",
    "\n",
    "### Factor Reliability\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add reliability info\n",
    "for _, row in reliability_df.iterrows():\n",
    "    if row['N_Items'] >= 2:\n",
    "        apa_summary += f\"- **{row['Factor']}** ({row['Primary_Construct']}): Î± = {row['Alpha']:.2f}, {row['N_Items']} items\\n\"\n",
    "    else:\n",
    "        apa_summary += f\"- **{row['Factor']}** ({row['Primary_Construct']}): Single-item factor\\n\"\n",
    "\n",
    "display(Markdown(apa_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad386588",
   "metadata": {},
   "source": [
    "## 3.7 Final Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faeb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final synthesis\n",
    "conclusions = f\"\"\"\n",
    "## Final Conclusions\n",
    "\n",
    "### Model Summary\n",
    "- **Sample**: {POPULATION.title()} (N = {n_obs})\n",
    "- **Items Analyzed**: {n_items} (from {constructs_active} constructs)\n",
    "- **Factors Retained**: {n_factors_final}\n",
    "- **Items Assigned**: {assigned_count}/{n_items} ({assigned_count/n_items*100:.0f}%)\n",
    "\n",
    "### Decision Point 1 Summary (Item Selection)\n",
    "- Started with {len(ALL_PREDICTOR_ITEMS)} items across 12 constructs\n",
    "- Selected {n_items} items from {constructs_active} constructs\n",
    "- Constructs with full representation (2 items): {constructs_full}\n",
    "- Constructs with partial representation (1 item): {constructs_partial}\n",
    "- Constructs dropped: {constructs_dropped}\n",
    "\n",
    "### Decision Point 2 Summary (Factor Selection)\n",
    "- Maximum factors explored: {n_factors_max}\n",
    "- Parallel analysis suggested: {n_factors_pa} factors\n",
    "- Kaiser criterion suggested: {n_factors_kaiser} factors\n",
    "- **Final selection**: {n_factors_final} factors ({', '.join(SELECTED_FACTORS)})\n",
    "\n",
    "### Reliability Assessment\n",
    "\"\"\"\n",
    "\n",
    "good_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] >= 0.70)])\n",
    "marginal_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] >= 0.60) & (reliability_df['Alpha'] < 0.70)])\n",
    "poor_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] < 0.60)])\n",
    "single_item = len(reliability_df[reliability_df['N_Items'] == 1])\n",
    "\n",
    "conclusions += f\"\"\"\n",
    "- Good reliability (Î± â‰¥ .70): {good_rel} factors\n",
    "- Marginal reliability (.60 â‰¤ Î± < .70): {marginal_rel} factors\n",
    "- Poor reliability (Î± < .60): {poor_rel} factors\n",
    "- Single-item factors: {single_item}\n",
    "\n",
    "### Recommendations\n",
    "\"\"\"\n",
    "\n",
    "if unassigned_count > 0:\n",
    "    conclusions += f\"- âš ï¸ {unassigned_count} items did not load adequately on selected factors\\n\"\n",
    "if poor_rel > 0:\n",
    "    conclusions += f\"- âš ï¸ {poor_rel} factors have poor internal consistency\\n\"\n",
    "if single_item > n_factors_final // 2:\n",
    "    conclusions += f\"- âš ï¸ Many single-item factors - consider combining or re-evaluating\\n\"\n",
    "\n",
    "conclusions += \"\"\"\n",
    "### Next Steps\n",
    "1. Validate this structure with CFA on an independent sample\n",
    "2. Consider theoretical justification for factor interpretations\n",
    "3. Document any items that behave unexpectedly\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(conclusions))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"âœ“ ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final synthesis\n",
    "conclusions = f\"\"\"\n",
    "## Final Conclusions\n",
    "\n",
    "### Model Summary\n",
    "- **Sample**: {POPULATION.title()} (N = {n_obs})\n",
    "- **Items Analyzed**: {n_items} (from {constructs_active} constructs)\n",
    "- **Factors Retained**: {n_factors_final}\n",
    "- **Items Assigned**: {assigned_count}/{n_items} ({assigned_count/n_items*100:.0f}%)\n",
    "\n",
    "### Decision Point 1 Summary (Item Selection)\n",
    "- Started with {len(ALL_PREDICTOR_ITEMS)} items across 12 constructs\n",
    "- Selected {n_items} items from {constructs_active} constructs\n",
    "- Constructs with full representation (2 items): {constructs_full}\n",
    "- Constructs with partial representation (1 item): {constructs_partial}\n",
    "- Constructs dropped: {constructs_dropped}\n",
    "\n",
    "### Decision Point 2 Summary (Factor Selection)\n",
    "- Maximum factors explored: {n_factors_max}\n",
    "- Parallel analysis suggested: {n_factors_pa} factors\n",
    "- Kaiser criterion suggested: {n_factors_kaiser} factors\n",
    "- **Final selection**: {n_factors_final} factors ({', '.join(SELECTED_FACTORS)})\n",
    "\n",
    "### Reliability Assessment\n",
    "\"\"\"\n",
    "\n",
    "good_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] >= 0.70)])\n",
    "marginal_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] >= 0.60) & (reliability_df['Alpha'] < 0.70)])\n",
    "poor_rel = len(reliability_df[(reliability_df['N_Items'] >= 2) & (reliability_df['Alpha'] < 0.60)])\n",
    "single_item = len(reliability_df[reliability_df['N_Items'] == 1])\n",
    "\n",
    "conclusions += f\"\"\"\n",
    "- Good reliability (Î± â‰¥ .70): {good_rel} factors\n",
    "- Marginal reliability (.60 â‰¤ Î± < .70): {marginal_rel} factors\n",
    "- Poor reliability (Î± < .60): {poor_rel} factors\n",
    "- Single-item factors: {single_item}\n",
    "\n",
    "### Recommendations\n",
    "\"\"\"\n",
    "\n",
    "if unassigned_count > 0:\n",
    "    conclusions += f\"- âš ï¸ {unassigned_count} items did not load adequately on selected factors\\n\"\n",
    "if poor_rel > 0:\n",
    "    conclusions += f\"- âš ï¸ {poor_rel} factors have poor internal consistency\\n\"\n",
    "if single_item > n_factors_final // 2:\n",
    "    conclusions += f\"- âš ï¸ Many single-item factors - consider combining or re-evaluating\\n\"\n",
    "\n",
    "conclusions += \"\"\"\n",
    "### Next Steps\n",
    "1. Validate this structure with CFA on an independent sample\n",
    "2. Consider theoretical justification for factor interpretations\n",
    "3. Document any items that behave unexpectedly\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(conclusions))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"âœ“ ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 90)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
