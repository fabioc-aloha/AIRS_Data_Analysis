{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4921d66",
   "metadata": {},
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ’ DECISION POINT: SELECT AUDIENCE(S) TO INCLUDE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Configure which role(s) to include in the experiment below.\n",
    "\n",
    "**Available Role Categories (Granular):**\n",
    "| Code | Role | Typical N |\n",
    "|------|------|----------|\n",
    "| `FT_Student` | Full-time Student | ~150 |\n",
    "| `PT_Student` | Part-time Student | ~46 |\n",
    "| `IC` | Individual Contributor | ~100 |\n",
    "| `Manager` | Manager | ~90 |\n",
    "| `Executive` | Executive/Leader | ~40 |\n",
    "| `Freelancer` | Freelancer/Self-Employed | ~40 |\n",
    "| `Unemployed` | Not Currently Employed | ~21 |\n",
    "\n",
    "**Pre-defined Population Groups:**\n",
    "| Group | Includes |\n",
    "|-------|----------|\n",
    "| `Academic` | FT_Student + PT_Student |\n",
    "| `Professional` | IC + Freelancer + Unemployed |\n",
    "| `Leader` | Manager + Executive |\n",
    "| `ALL` | All roles above (~487 total) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b1cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’ Selected roles: ['ALL']\n"
     ]
    }
   ],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ¯ DECISION POINT: EDIT THIS TO SELECT ROLE(S)                              â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 1: Process ALL roles (default - maximum power for cherry-picking)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "SELECTED_ROLES = ['ALL']\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 2: Population Groups (coarse)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SELECTED_ROLES = ['Academic']                    # FT_Student + PT_Student (~196)\n",
    "# SELECTED_ROLES = ['Professional']                # IC + Freelancer + Unemployed (~161)\n",
    "# SELECTED_ROLES = ['Leader']                      # Manager + Executive (~130)\n",
    "# SELECTED_ROLES = ['Academic', 'Professional']    # Exclude leaders\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 3: Granular Role Selection\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SELECTED_ROLES = ['FT_Student']                  # Full-time students only\n",
    "# SELECTED_ROLES = ['PT_Student']                  # Part-time students only\n",
    "# SELECTED_ROLES = ['IC']                          # Individual contributors only\n",
    "# SELECTED_ROLES = ['Manager']                     # Managers only\n",
    "# SELECTED_ROLES = ['Executive']                   # Executives only\n",
    "# SELECTED_ROLES = ['Freelancer']                  # Freelancers/Self-employed only\n",
    "# SELECTED_ROLES = ['Unemployed']                  # Not currently employed only\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 4: Custom Combinations\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SELECTED_ROLES = ['FT_Student', 'IC']            # Students + ICs only\n",
    "# SELECTED_ROLES = ['Manager', 'Executive']        # Leaders only (same as 'Leader')\n",
    "# SELECTED_ROLES = ['FT_Student', 'Manager']       # Compare students vs managers\n",
    "# SELECTED_ROLES = ['IC', 'Freelancer']            # Non-manager professionals\n",
    "# SELECTED_ROLES = ['Academic', 'Manager']         # Students + Managers\n",
    "\n",
    "print(f\"ğŸ’ Selected roles: {SELECTED_ROLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef9a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ’ AIRS EXPERIMENT DATA PREPARATION\n",
      "======================================================================\n",
      "Random seed: 67\n",
      "Output: Full sample (no dev/holdout split)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 0: IMPORTS AND CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Prevent OpenMP conflicts\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 67\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create output directories\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "Path('plots').mkdir(exist_ok=True)\n",
    "Path('tables').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ’ AIRS EXPERIMENT DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Random seed: {RANDOM_SEED}\")\n",
    "print(f\"Output: Full sample (no dev/holdout split)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512bb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’ AUDIENCE CONFIGURATION\n",
      "======================================================================\n",
      "Selected: ['ALL']\n",
      "Granular roles to include: ['FT_Student', 'PT_Student', 'IC', 'Manager', 'Executive', 'Freelancer', 'Unemployed']\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Role Group Definitions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ROLE_GROUPS = {\n",
    "    'ALL': ['FT_Student', 'PT_Student', 'IC', 'Manager', 'Executive', 'Freelancer', 'Unemployed'],\n",
    "    'Academic': ['FT_Student', 'PT_Student'],\n",
    "    'Professional': ['IC', 'Freelancer', 'Unemployed'],\n",
    "    'Leader': ['Manager', 'Executive'],\n",
    "}\n",
    "\n",
    "VALID_GRANULAR_ROLES = ['FT_Student', 'PT_Student', 'IC', 'Manager', 'Executive', 'Freelancer', 'Unemployed']\n",
    "VALID_GROUPS = list(ROLE_GROUPS.keys())\n",
    "\n",
    "# Expand selection to granular roles\n",
    "ROLES_TO_INCLUDE = []\n",
    "for role in SELECTED_ROLES:\n",
    "    if role in ROLE_GROUPS:\n",
    "        ROLES_TO_INCLUDE.extend(ROLE_GROUPS[role])\n",
    "    elif role in VALID_GRANULAR_ROLES:\n",
    "        ROLES_TO_INCLUDE.append(role)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid role: {role}. Valid options: {VALID_GROUPS + VALID_GRANULAR_ROLES}\")\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "ROLES_TO_INCLUDE = list(dict.fromkeys(ROLES_TO_INCLUDE))\n",
    "\n",
    "print(\"ğŸ’ AUDIENCE CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Selected: {SELECTED_ROLES}\")\n",
    "print(f\"Granular roles to include: {ROLES_TO_INCLUDE}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78564a14",
   "metadata": {},
   "source": [
    "## 1. Load Clean Data from Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29abe49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA LOADED\n",
      "======================================================================\n",
      "Total rows: 511\n",
      "Columns: 45\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1: LOAD CLEAN DATA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Load from main data folder (processed by 00_Create_Split_Samples.ipynb)\n",
    "df_full = pd.read_csv('../data/AIRS_clean.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA LOADED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total rows: {len(df_full)}\")\n",
    "print(f\"Columns: {len(df_full.columns)}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5072bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ’ AUDIENCE FILTERING\n",
      "======================================================================\n",
      "Total responses: 511\n",
      "Valid populations (excl. 'Other'): 487\n",
      "After role filter: 487\n",
      "Excluded: 0\n",
      "======================================================================\n",
      "\n",
      "ğŸ’ Role breakdown in experiment sample:\n",
      "   âœ“ FT_Student: N=180\n",
      "   âœ“ IC: N=113\n",
      "   âœ“ Manager: N=74\n",
      "   âœ“ Executive: N=56\n",
      "   âœ“ Freelancer: N=31\n",
      "   âœ“ Unemployed: N=17\n",
      "   âœ“ PT_Student: N=16\n",
      "\n",
      "ğŸ“Š Population breakdown:\n",
      "   Academic: N=196 (40.2%)\n",
      "   Professional: N=161 (33.1%)\n",
      "   Leader: N=130 (26.7%)\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2: APPLY ROLE FILTER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Filter to valid populations (exclude 'Other')\n",
    "df_valid = df_full[df_full['Population'].notna()].copy()\n",
    "\n",
    "# Apply granular role filter\n",
    "df = df_valid[df_valid['Role_Category'].isin(ROLES_TO_INCLUDE)].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ’ AUDIENCE FILTERING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total responses: {len(df_full)}\")\n",
    "print(f\"Valid populations (excl. 'Other'): {len(df_valid)}\")\n",
    "print(f\"After role filter: {len(df)}\")\n",
    "print(f\"Excluded: {len(df_valid) - len(df)}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show role breakdown\n",
    "print(\"\\nğŸ’ Role breakdown in experiment sample:\")\n",
    "role_counts = df['Role_Category'].value_counts()\n",
    "for role, n in role_counts.items():\n",
    "    marker = \"âœ“\" if role in ROLES_TO_INCLUDE else \"âœ—\"\n",
    "    print(f\"   {marker} {role}: N={n}\")\n",
    "\n",
    "# Show population breakdown\n",
    "print(\"\\nğŸ“Š Population breakdown:\")\n",
    "pop_counts = df['Population'].value_counts()\n",
    "for pop, n in pop_counts.items():\n",
    "    print(f\"   {pop}: N={n} ({n/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143baba",
   "metadata": {},
   "source": [
    "## 2. Sample Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3240dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ’ EXPERIMENT SAMPLE CHARACTERISTICS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Sample Size: N = 487\n",
      "   Cases per item: 20.3 âœ“ Excellent\n",
      "\n",
      "ğŸ“Š AI Adoption:\n",
      "   Adopters: 438 (89.9%)\n",
      "   Non-Adopters: 49 (10.1%)\n",
      "\n",
      "ğŸ“Š Usage Intensity:\n",
      "   Medium: 161 (33.1%)\n",
      "   Low: 148 (30.4%)\n",
      "   High: 129 (26.5%)\n",
      "   Non-User: 49 (10.1%)\n",
      "\n",
      "ğŸ“Š Disability Status:\n",
      "   No: N=411 (84.4%)\n",
      "   Yes: N=66 (13.6%)\n",
      "   Prefer not to answer: N=10 (2.1%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3: SAMPLE OVERVIEW\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ’ EXPERIMENT SAMPLE CHARACTERISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“Š Sample Size: N = {len(df)}\")\n",
    "\n",
    "# Cases per item for EFA adequacy\n",
    "n_items = 24\n",
    "cases_per_item = len(df) / n_items\n",
    "efa_status = \"âœ“ Excellent\" if cases_per_item >= 10 else \"âœ“ Good\" if cases_per_item >= 5 else \"âš ï¸ Marginal\"\n",
    "print(f\"   Cases per item: {cases_per_item:.1f} {efa_status}\")\n",
    "\n",
    "print(\"\\nğŸ“Š AI Adoption:\")\n",
    "print(f\"   Adopters: {df['AI_Adoption'].sum()} ({df['AI_Adoption'].mean()*100:.1f}%)\")\n",
    "print(f\"   Non-Adopters: {(~df['AI_Adoption'].astype(bool)).sum()} ({(1-df['AI_Adoption'].mean())*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“Š Usage Intensity:\")\n",
    "usage_dist = df['Usage_Intensity'].value_counts()\n",
    "for intensity, n in usage_dist.items():\n",
    "    print(f\"   {intensity}: {n} ({n/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nğŸ“Š Disability Status:\")\n",
    "dis_dist = df['Disability'].value_counts()\n",
    "for status, n in dis_dist.items():\n",
    "    print(f\"   {status}: N={n} ({n/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d12505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ITEM DESCRIPTIVES\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Predictor Items (24):\n",
      "     mean   std  min  max\n",
      "PE1  3.64  1.12  1.0  5.0\n",
      "PE2  3.31  1.18  1.0  5.0\n",
      "EE1  3.73  1.02  1.0  5.0\n",
      "EE2  3.58  1.04  1.0  5.0\n",
      "SI1  3.08  1.18  1.0  5.0\n",
      "SI2  3.30  1.12  1.0  5.0\n",
      "FC1  3.25  1.17  1.0  5.0\n",
      "FC2  3.47  1.03  1.0  5.0\n",
      "HM1  3.28  1.18  1.0  5.0\n",
      "HM2  3.33  1.20  1.0  5.0\n",
      "PV1  3.43  1.19  1.0  5.0\n",
      "PV2  3.43  1.16  1.0  5.0\n",
      "HB1  3.08  1.32  1.0  5.0\n",
      "HB2  2.97  1.32  1.0  5.0\n",
      "VO1  3.46  1.27  1.0  5.0\n",
      "VO2  3.86  1.09  1.0  5.0\n",
      "TR1  3.15  1.20  1.0  5.0\n",
      "TR2  3.29  1.17  1.0  5.0\n",
      "EX1  3.33  1.14  1.0  5.0\n",
      "EX2  3.83  0.93  1.0  5.0\n",
      "ER1  3.22  1.29  1.0  5.0\n",
      "ER2  3.87  1.03  1.0  5.0\n",
      "AX1  3.65  1.14  1.0  5.0\n",
      "AX2  3.20  1.21  1.0  5.0\n",
      "\n",
      "ğŸ“Š Outcome Items (BI1-BI4):\n",
      "     mean   std  min  max\n",
      "BI1  3.22  1.19  1.0  5.0\n",
      "BI2  3.21  1.22  1.0  5.0\n",
      "BI3  3.26  1.24  1.0  5.0\n",
      "BI4  3.06  1.24  1.0  5.0\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4: ITEM DESCRIPTIVES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Define item groups\n",
    "predictor_items = ['PE1', 'PE2', 'EE1', 'EE2', 'SI1', 'SI2', 'FC1', 'FC2',\n",
    "                   'HM1', 'HM2', 'PV1', 'PV2', 'HB1', 'HB2', 'VO1', 'VO2',\n",
    "                   'TR1', 'TR2', 'EX1', 'EX2', 'ER1', 'ER2', 'AX1', 'AX2']\n",
    "\n",
    "outcome_items = ['BI1', 'BI2', 'BI3', 'BI4']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ITEM DESCRIPTIVES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“Š Predictor Items (24):\")\n",
    "desc = df[predictor_items].describe().T[['mean', 'std', 'min', 'max']]\n",
    "print(desc.round(2).to_string())\n",
    "\n",
    "print(\"\\nğŸ“Š Outcome Items (BI1-BI4):\")\n",
    "desc_bi = df[outcome_items].describe().T[['mean', 'std', 'min', 'max']]\n",
    "print(desc_bi.round(2).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83efcf",
   "metadata": {},
   "source": [
    "## 3. Save Experiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cda053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ’ EXPERIMENT DATA SAVED\n",
      "======================================================================\n",
      "âœ“ data/AIRS_experiment.csv\n",
      "  Rows: 487\n",
      "  Columns: 45\n",
      "âœ“ data/experiment_config.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5: SAVE EXPERIMENT DATA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Save to experiment data folder\n",
    "output_path = 'data/AIRS_experiment.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Also save experiment config for reproducibility\n",
    "config = {\n",
    "    'selected_roles': SELECTED_ROLES,\n",
    "    'roles_included': ROLES_TO_INCLUDE,\n",
    "    'n_observations': len(df),\n",
    "    'n_predictor_items': len(predictor_items),\n",
    "    'n_outcome_items': len(outcome_items),\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'source': '../data/AIRS_clean.csv',\n",
    "    'population_breakdown': df['Population'].value_counts().to_dict(),\n",
    "    'role_breakdown': df['Role_Category'].value_counts().to_dict(),\n",
    "}\n",
    "\n",
    "with open('data/experiment_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ’ EXPERIMENT DATA SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ“ {output_path}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"âœ“ data/experiment_config.json\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86abdf7",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87049304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ğŸ’ Experiment Data Summary\n",
       "\n",
       "| Attribute | Value |\n",
       "|-----------|-------|\n",
       "| **Sample Size** | N = 487 |\n",
       "| **Roles Included** | FT_Student, PT_Student, IC, Manager, Executive, Freelancer, Unemployed |\n",
       "| **Population Breakdown** | Academic: 196, Professional: 161, Leader: 130 |\n",
       "| **Cases per Item** | 20.3 (âœ“ Excellent) |\n",
       "| **AI Adopters** | 438 (89.9%) |\n",
       "\n",
       "### Output Files\n",
       "- `data/AIRS_experiment.csv` - Clean experiment dataset\n",
       "- `data/experiment_config.json` - Configuration for reproducibility\n",
       "\n",
       "### Next Steps\n",
       "1. Run `01_EFA_Experiment.ipynb` for exploratory factor analysis\n",
       "2. Run `02_CFA_Experiment.ipynb` for confirmatory factor analysis (cherry-picking)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âœ“ EXPERIMENT DATA PREPARATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6: SUMMARY\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "roles_str = ', '.join(ROLES_TO_INCLUDE)\n",
    "pop_str = ', '.join([f\"{k}: {v}\" for k, v in df['Population'].value_counts().items()])\n",
    "\n",
    "summary = f\"\"\"\n",
    "## ğŸ’ Experiment Data Summary\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| **Sample Size** | N = {len(df)} |\n",
    "| **Roles Included** | {roles_str} |\n",
    "| **Population Breakdown** | {pop_str} |\n",
    "| **Cases per Item** | {cases_per_item:.1f} ({efa_status}) |\n",
    "| **AI Adopters** | {df['AI_Adoption'].sum()} ({df['AI_Adoption'].mean()*100:.1f}%) |\n",
    "\n",
    "### Output Files\n",
    "- `data/AIRS_experiment.csv` - Clean experiment dataset\n",
    "- `data/experiment_config.json` - Configuration for reproducibility\n",
    "\n",
    "### Next Steps\n",
    "1. Run `01_EFA_Experiment.ipynb` for exploratory factor analysis\n",
    "2. Run `02_CFA_Experiment.ipynb` for confirmatory factor analysis (cherry-picking)\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ EXPERIMENT DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
