{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0928077d",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries and Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acee23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Linear regression for structural models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(67)  # Reproducibility (consistent with Phases 4-5)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"[OK] Libraries imported successfully\")\n",
    "print(f\"   - numpy version: {np.__version__}\")\n",
    "print(f\"   - pandas version: {pd.__version__}\")\n",
    "print(f\"   - Random seed: 67 (consistent with Phases 4-5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfe4f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Full Sample and Prepare Data\n",
    "\n",
    "Using **complete dataset (N=362)** for maximum power per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16306bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "df_full = pd.read_csv('../data/AIRS_clean.csv')\n",
    "\n",
    "print(f\"[DATA] Full Sample Loaded\")\n",
    "print(f\"   - N = {len(df_full)}\")\n",
    "print(f\"   - Columns: {len(df_full.columns)}\")\n",
    "\n",
    "# Load 12-item selection from Phase 1\n",
    "with open('../data/airs_12item_selection.json', 'r') as f:\n",
    "    item_selection = json.load(f)\n",
    "\n",
    "# Extract selected items\n",
    "selected_items = [info['selected_item'] for construct, info in item_selection.items()]\n",
    "print(f\"\\n[SCALE] 12-Item AIRS Scale:\")\n",
    "print(f\"   {', '.join(selected_items)}\")\n",
    "\n",
    "# Behavioral intention items (outcome variable)\n",
    "bi_items = ['BI1', 'BI2', 'BI3', 'BI4']\n",
    "print(f\"\\n[TARGET] Outcome Variable (BI):\")\n",
    "print(f\"   {', '.join(bi_items)}\")\n",
    "\n",
    "# Demographic variables for moderation\n",
    "demo_vars = ['Role', 'AI_usage_frequency', 'AI_adopter']\n",
    "print(f\"\\n[MODERATORS] Contextual Variables:\")\n",
    "print(f\"   {', '.join(demo_vars)}\")\n",
    "\n",
    "# Create dataset with all needed variables\n",
    "analysis_items = selected_items + bi_items + demo_vars\n",
    "df_analysis = df_full[analysis_items].copy()\n",
    "\n",
    "# Check for missing data\n",
    "missing_counts = df_analysis.isnull().sum()\n",
    "if missing_counts.sum() > 0:\n",
    "    print(f\"\\n[WARNING] Missing Data Detected:\")\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "    print(f\"\\n   Using listwise deletion (complete cases only)\")\n",
    "    df_analysis = df_analysis.dropna()\n",
    "    print(f\"   Final N = {len(df_analysis)}\")\n",
    "else:\n",
    "    print(f\"\\n[OK] No missing data - all cases complete (N = {len(df_analysis)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016b00e",
   "metadata": {},
   "source": [
    "## 3. Create Composite Scores and Verify Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61451693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create composite scores for all constructs\n",
    "print(\"Creating composite scores...\\n\")\n",
    "\n",
    "# UTAUT2 constructs (predictors)\n",
    "df_analysis['PE'] = df_analysis[['PE2']].mean(axis=1)  # Performance Expectancy\n",
    "df_analysis['EE'] = df_analysis[['EE1']].mean(axis=1)  # Effort Expectancy\n",
    "df_analysis['SI'] = df_analysis[['SI1']].mean(axis=1)  # Social Influence\n",
    "df_analysis['FC'] = df_analysis[['FC1']].mean(axis=1)  # Facilitating Conditions\n",
    "df_analysis['HM'] = df_analysis[['HM2']].mean(axis=1)  # Hedonic Motivation\n",
    "df_analysis['PV'] = df_analysis[['PV2']].mean(axis=1)  # Price Value\n",
    "df_analysis['HB'] = df_analysis[['HB2']].mean(axis=1)  # Habit\n",
    "df_analysis['VO'] = df_analysis[['VO1']].mean(axis=1)  # Voluntariness of Use\n",
    "\n",
    "# AIRS constructs (predictors)\n",
    "df_analysis['TR'] = df_analysis[['TR2']].mean(axis=1)  # Trust\n",
    "df_analysis['EX'] = df_analysis[['EX1']].mean(axis=1)  # Explainability\n",
    "df_analysis['ER'] = df_analysis[['ER2']].mean(axis=1)  # Ethical Risk\n",
    "df_analysis['AX'] = df_analysis[['AX2']].mean(axis=1)  # AI Anxiety\n",
    "\n",
    "# Behavioral intention (outcome)\n",
    "df_analysis['BI'] = df_analysis[bi_items].mean(axis=1)\n",
    "\n",
    "print(\"[OK] Composite scores created\")\n",
    "print(f\"   - 8 UTAUT2 constructs: PE, EE, SI, FC, HM, PV, HB, VO\")\n",
    "print(f\"   - 4 AIRS constructs: TR, EX, ER, AX\")\n",
    "print(f\"   - 1 outcome: BI\")\n",
    "\n",
    "# Verify demographic distributions\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DEMOGRAPHIC DISTRIBUTIONS (N={len(df_analysis)})\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Role distribution\n",
    "role_counts = df_analysis['Role'].value_counts().sort_index()\n",
    "print(\"Role Distribution:\")\n",
    "for role, count in role_counts.items():\n",
    "    pct = 100 * count / len(df_analysis)\n",
    "    print(f\"   {role}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# AI usage frequency distribution\n",
    "usage_counts = df_analysis['AI_usage_frequency'].value_counts().sort_index()\n",
    "print(\"\\nAI Usage Frequency Distribution:\")\n",
    "for usage, count in usage_counts.items():\n",
    "    pct = 100 * count / len(df_analysis)\n",
    "    print(f\"   {usage}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# AI adopter distribution\n",
    "adopter_counts = df_analysis['AI_adopter'].value_counts().sort_index()\n",
    "print(\"\\nAI Adoption Status Distribution:\")\n",
    "for adopter, count in adopter_counts.items():\n",
    "    pct = 100 * count / len(df_analysis)\n",
    "    status = \"Adopter\" if adopter == 1 else \"Non-Adopter\"\n",
    "    print(f\"   {status}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06cab09",
   "metadata": {},
   "source": [
    "## 4. Define Structural Model Function\n",
    "\n",
    "This function estimates the full structural model for a given subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_structural_model(data, group_name=\"Full Sample\"):\n",
    "    \"\"\"\n",
    "    Estimate full structural model: All UTAUT2 + AIRS constructs → BI\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Subset of data for this group\n",
    "    group_name : str\n",
    "        Name of the group for display\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results dictionary with coefficients, t-stats, p-values, R²\n",
    "    \"\"\"\n",
    "    # Define predictors (12 total: 8 UTAUT2 + 4 AIRS)\n",
    "    predictors = ['PE', 'EE', 'SI', 'FC', 'HM', 'PV', 'HB', 'VO',  # UTAUT2\n",
    "                  'TR', 'EX', 'ER', 'AX']  # AIRS\n",
    "    \n",
    "    # Extract X and y\n",
    "    X = data[predictors].values\n",
    "    y = data['BI'].values\n",
    "    n = len(data)\n",
    "    \n",
    "    # Fit OLS regression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get predictions and residuals\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    # Calculate R²\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    # Calculate standard errors and t-statistics\n",
    "    k = len(predictors)\n",
    "    dof = n - k - 1\n",
    "    mse = ss_res / dof\n",
    "    \n",
    "    # Calculate variance-covariance matrix\n",
    "    X_centered = X - X.mean(axis=0)\n",
    "    var_covar = mse * np.linalg.inv(X_centered.T @ X_centered)\n",
    "    std_errors = np.sqrt(np.diag(var_covar))\n",
    "    \n",
    "    # Calculate t-statistics and p-values\n",
    "    t_stats = model.coef_ / std_errors\n",
    "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), dof))\n",
    "    \n",
    "    # Create results dictionary\n",
    "    results = {\n",
    "        'group': group_name,\n",
    "        'n': n,\n",
    "        'r_squared': r_squared,\n",
    "        'coefficients': {},\n",
    "        'intercept': model.intercept_\n",
    "    }\n",
    "    \n",
    "    # Store results for each predictor\n",
    "    for i, pred in enumerate(predictors):\n",
    "        results['coefficients'][pred] = {\n",
    "            'beta': model.coef_[i],\n",
    "            'se': std_errors[i],\n",
    "            't': t_stats[i],\n",
    "            'p': p_values[i]\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"[OK] Structural model function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55c596",
   "metadata": {},
   "source": [
    "## 5. Bootstrap Confidence Intervals Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_path_ci(data, predictor, n_iterations=5000, ci=95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap confidence interval for a specific path coefficient.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Data for this group\n",
    "    predictor : str\n",
    "        Name of predictor variable\n",
    "    n_iterations : int\n",
    "        Number of bootstrap samples\n",
    "    ci : float\n",
    "        Confidence level (e.g., 95)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (lower_ci, upper_ci)\n",
    "    \"\"\"\n",
    "    predictors = ['PE', 'EE', 'SI', 'FC', 'HM', 'PV', 'HB', 'VO',\n",
    "                  'TR', 'EX', 'ER', 'AX']\n",
    "    \n",
    "    bootstrap_coefs = []\n",
    "    n = len(data)\n",
    "    pred_idx = predictors.index(predictor)\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        # Resample with replacement\n",
    "        indices = np.random.choice(n, size=n, replace=True)\n",
    "        sample = data.iloc[indices]\n",
    "        \n",
    "        # Fit model\n",
    "        X = sample[predictors].values\n",
    "        y = sample['BI'].values\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        bootstrap_coefs.append(model.coef_[pred_idx])\n",
    "    \n",
    "    # Calculate percentile-based confidence interval\n",
    "    alpha = (100 - ci) / 2\n",
    "    lower_ci = np.percentile(bootstrap_coefs, alpha)\n",
    "    upper_ci = np.percentile(bootstrap_coefs, 100 - alpha)\n",
    "    \n",
    "    return lower_ci, upper_ci\n",
    "\n",
    "print(\"[OK] Bootstrap CI function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82176440",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. H4a & H4b: Role Moderation Analysis\n",
    "\n",
    "**H4a**: Trust (TR) and Explainability (EX) effects stronger for professionals (discretionary context)  \n",
    "**H4b**: Social Influence (SI) effects stronger for students (normative pressure)\n",
    "\n",
    "**Approach**: Estimate separate structural models for each role, compare key path coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODERATION ANALYSIS 1: ROLE (H4a, H4b)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEstimating separate structural models by role...\\n\")\n",
    "\n",
    "# Get unique roles\n",
    "roles = df_analysis['Role'].unique()\n",
    "role_results = {}\n",
    "\n",
    "# Estimate model for each role\n",
    "for role in sorted(roles):\n",
    "    role_data = df_analysis[df_analysis['Role'] == role]\n",
    "    results = estimate_structural_model(role_data, group_name=role)\n",
    "    role_results[role] = results\n",
    "    \n",
    "    print(f\"\\n{role} (N={results['n']}):\")\n",
    "    print(f\"   R² = {results['r_squared']:.4f}\")\n",
    "    print(f\"   Key paths:\")\n",
    "    for construct in ['TR', 'EX', 'SI', 'AX']:\n",
    "        coef_info = results['coefficients'][construct]\n",
    "        sig = '***' if coef_info['p'] < 0.001 else '**' if coef_info['p'] < 0.01 else '*' if coef_info['p'] < 0.05 else 'ns'\n",
    "        print(f\"      {construct} → BI: β={coef_info['beta']:.4f}{sig}, t={coef_info['t']:.3f}, p={coef_info['p']:.4f}\")\n",
    "\n",
    "print(\"\\n[OK] Role moderation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c531ba2",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Intervals for Key Paths (Role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b41dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating bootstrap 95% CIs for key paths (5000 iterations)...\\n\")\n",
    "\n",
    "# Calculate CIs for key constructs across roles\n",
    "key_constructs_role = ['TR', 'EX', 'SI']\n",
    "role_ci_results = {}\n",
    "\n",
    "for role in sorted(roles):\n",
    "    role_data = df_analysis[df_analysis['Role'] == role]\n",
    "    role_ci_results[role] = {}\n",
    "    \n",
    "    print(f\"{role}:\")\n",
    "    for construct in key_constructs_role:\n",
    "        lower_ci, upper_ci = bootstrap_path_ci(role_data, construct)\n",
    "        role_ci_results[role][construct] = (lower_ci, upper_ci)\n",
    "        \n",
    "        point_est = role_results[role]['coefficients'][construct]['beta']\n",
    "        sig = \"[SIG]\" if (lower_ci > 0 and upper_ci > 0) or (lower_ci < 0 and upper_ci < 0) else \"[ns]\"\n",
    "        print(f\"   {construct} → BI: β={point_est:.4f}, 95% CI [{lower_ci:.4f}, {upper_ci:.4f}] {sig}\")\n",
    "    print()\n",
    "\n",
    "print(\"[OK] Bootstrap CIs calculated for role moderation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207b8607",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. H4c & H4d: Usage Frequency Moderation Analysis\n",
    "\n",
    "**H4c**: Habit (HB) effect stronger for high-frequency users  \n",
    "**H4d**: Anxiety (AX) effect weaker for high-frequency users (exposure effect)\n",
    "\n",
    "**Note**: We'll dichotomize usage frequency into Low vs. High for clearer comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dichotomize usage frequency: Daily/Weekly = High, Monthly/Rarely/Never = Low\n",
    "df_analysis['usage_binary'] = df_analysis['AI_usage_frequency'].apply(\n",
    "    lambda x: 'High' if x in ['Daily', 'Weekly'] else 'Low'\n",
    ")\n",
    "\n",
    "print(\"Usage Frequency Dichotomization:\")\n",
    "print(df_analysis['usage_binary'].value_counts().sort_index())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODERATION ANALYSIS 2: USAGE FREQUENCY (H4c, H4d)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEstimating separate structural models by usage frequency...\\n\")\n",
    "\n",
    "# Get unique usage levels\n",
    "usage_levels = df_analysis['usage_binary'].unique()\n",
    "usage_results = {}\n",
    "\n",
    "# Estimate model for each usage level\n",
    "for usage in sorted(usage_levels):\n",
    "    usage_data = df_analysis[df_analysis['usage_binary'] == usage]\n",
    "    results = estimate_structural_model(usage_data, group_name=f\"{usage} Usage\")\n",
    "    usage_results[usage] = results\n",
    "    \n",
    "    print(f\"\\n{usage} Usage (N={results['n']}):\")\n",
    "    print(f\"   R² = {results['r_squared']:.4f}\")\n",
    "    print(f\"   Key paths:\")\n",
    "    for construct in ['HB', 'AX', 'TR', 'EX']:\n",
    "        coef_info = results['coefficients'][construct]\n",
    "        sig = '***' if coef_info['p'] < 0.001 else '**' if coef_info['p'] < 0.01 else '*' if coef_info['p'] < 0.05 else 'ns'\n",
    "        print(f\"      {construct} → BI: β={coef_info['beta']:.4f}{sig}, t={coef_info['t']:.3f}, p={coef_info['p']:.4f}\")\n",
    "\n",
    "print(\"\\n[OK] Usage frequency moderation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba7f98",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Intervals for Key Paths (Usage Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb540269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating bootstrap 95% CIs for key paths (5000 iterations)...\\n\")\n",
    "\n",
    "# Calculate CIs for key constructs across usage levels\n",
    "key_constructs_usage = ['HB', 'AX']\n",
    "usage_ci_results = {}\n",
    "\n",
    "for usage in sorted(usage_levels):\n",
    "    usage_data = df_analysis[df_analysis['usage_binary'] == usage]\n",
    "    usage_ci_results[usage] = {}\n",
    "    \n",
    "    print(f\"{usage} Usage:\")\n",
    "    for construct in key_constructs_usage:\n",
    "        lower_ci, upper_ci = bootstrap_path_ci(usage_data, construct)\n",
    "        usage_ci_results[usage][construct] = (lower_ci, upper_ci)\n",
    "        \n",
    "        point_est = usage_results[usage]['coefficients'][construct]['beta']\n",
    "        sig = \"[SIG]\" if (lower_ci > 0 and upper_ci > 0) or (lower_ci < 0 and upper_ci < 0) else \"[ns]\"\n",
    "        print(f\"   {construct} → BI: β={point_est:.4f}, 95% CI [{lower_ci:.4f}, {upper_ci:.4f}] {sig}\")\n",
    "    print()\n",
    "\n",
    "print(\"[OK] Bootstrap CIs calculated for usage frequency moderation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85677068",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. H4e: Adoption Status Moderation Analysis\n",
    "\n",
    "**H4e**: Facilitators (Factor 1: PE, EE, SI, FC, HM, PV, HB, VO, TR, EX) more salient for adopters;  \n",
    "       Barriers (Factor 2: ER, AX) more salient for non-adopters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODERATION ANALYSIS 3: ADOPTION STATUS (H4e)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEstimating separate structural models by adoption status...\\n\")\n",
    "\n",
    "# Get unique adoption statuses\n",
    "adoption_statuses = df_analysis['AI_adopter'].unique()\n",
    "adoption_results = {}\n",
    "\n",
    "# Estimate model for each adoption status\n",
    "for adopter in sorted(adoption_statuses):\n",
    "    adopter_data = df_analysis[df_analysis['AI_adopter'] == adopter]\n",
    "    status_label = \"Adopter\" if adopter == 1 else \"Non-Adopter\"\n",
    "    results = estimate_structural_model(adopter_data, group_name=status_label)\n",
    "    adoption_results[status_label] = results\n",
    "    \n",
    "    print(f\"\\n{status_label} (N={results['n']}):\")\n",
    "    print(f\"   R² = {results['r_squared']:.4f}\")\n",
    "    print(f\"   Facilitators (Factor 1):\")\n",
    "    for construct in ['PE', 'EE', 'SI', 'FC', 'HM', 'PV', 'HB', 'VO', 'TR', 'EX']:\n",
    "        coef_info = results['coefficients'][construct]\n",
    "        sig = '***' if coef_info['p'] < 0.001 else '**' if coef_info['p'] < 0.01 else '*' if coef_info['p'] < 0.05 else 'ns'\n",
    "        print(f\"      {construct} → BI: β={coef_info['beta']:.4f}{sig}\")\n",
    "    print(f\"   Barriers (Factor 2):\")\n",
    "    for construct in ['ER', 'AX']:\n",
    "        coef_info = results['coefficients'][construct]\n",
    "        sig = '***' if coef_info['p'] < 0.001 else '**' if coef_info['p'] < 0.01 else '*' if coef_info['p'] < 0.05 else 'ns'\n",
    "        print(f\"      {construct} → BI: β={coef_info['beta']:.4f}{sig}\")\n",
    "\n",
    "print(\"\\n[OK] Adoption status moderation analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6df7a3",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Intervals for Key Paths (Adoption Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating bootstrap 95% CIs for barriers (5000 iterations)...\\n\")\n",
    "\n",
    "# Calculate CIs for barriers (Factor 2) across adoption statuses\n",
    "key_constructs_adoption = ['ER', 'AX']\n",
    "adoption_ci_results = {}\n",
    "\n",
    "for adopter in sorted(adoption_statuses):\n",
    "    adopter_data = df_analysis[df_analysis['AI_adopter'] == adopter]\n",
    "    status_label = \"Adopter\" if adopter == 1 else \"Non-Adopter\"\n",
    "    adoption_ci_results[status_label] = {}\n",
    "    \n",
    "    print(f\"{status_label}:\")\n",
    "    for construct in key_constructs_adoption:\n",
    "        lower_ci, upper_ci = bootstrap_path_ci(adopter_data, construct)\n",
    "        adoption_ci_results[status_label][construct] = (lower_ci, upper_ci)\n",
    "        \n",
    "        point_est = adoption_results[status_label]['coefficients'][construct]['beta']\n",
    "        sig = \"[SIG]\" if (lower_ci > 0 and upper_ci > 0) or (lower_ci < 0 and upper_ci < 0) else \"[ns]\"\n",
    "        print(f\"   {construct} → BI: β={point_est:.4f}, 95% CI [{lower_ci:.4f}, {upper_ci:.4f}] {sig}\")\n",
    "    print()\n",
    "\n",
    "print(\"[OK] Bootstrap CIs calculated for adoption status moderation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6ec12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary Tables: Export Results\n",
    "\n",
    "Create publication-ready summary tables for all moderation analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "Path('../results/tables').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Creating summary tables...\\n\")\n",
    "\n",
    "# Table 1: Role Moderation Summary\n",
    "role_summary = []\n",
    "for role in sorted(roles):\n",
    "    for construct in ['TR', 'EX', 'SI', 'AX']:\n",
    "        coef_info = role_results[role]['coefficients'][construct]\n",
    "        ci = role_ci_results[role].get(construct, (None, None))\n",
    "        \n",
    "        role_summary.append({\n",
    "            'role': role,\n",
    "            'predictor': construct,\n",
    "            'n': role_results[role]['n'],\n",
    "            'r_squared': role_results[role]['r_squared'],\n",
    "            'beta': coef_info['beta'],\n",
    "            'se': coef_info['se'],\n",
    "            't_value': coef_info['t'],\n",
    "            'p_value': coef_info['p'],\n",
    "            'ci_lower': ci[0],\n",
    "            'ci_upper': ci[1],\n",
    "            'significant': coef_info['p'] < 0.05\n",
    "        })\n",
    "\n",
    "df_role = pd.DataFrame(role_summary)\n",
    "df_role.to_csv('../results/tables/moderation_role_summary.csv', index=False)\n",
    "print(f\"[SAVED] Role moderation summary: ../results/tables/moderation_role_summary.csv\")\n",
    "\n",
    "# Table 2: Usage Frequency Moderation Summary\n",
    "usage_summary = []\n",
    "for usage in sorted(usage_levels):\n",
    "    for construct in ['HB', 'AX', 'TR', 'EX']:\n",
    "        coef_info = usage_results[usage]['coefficients'][construct]\n",
    "        ci = usage_ci_results[usage].get(construct, (None, None))\n",
    "        \n",
    "        usage_summary.append({\n",
    "            'usage_level': usage,\n",
    "            'predictor': construct,\n",
    "            'n': usage_results[usage]['n'],\n",
    "            'r_squared': usage_results[usage]['r_squared'],\n",
    "            'beta': coef_info['beta'],\n",
    "            'se': coef_info['se'],\n",
    "            't_value': coef_info['t'],\n",
    "            'p_value': coef_info['p'],\n",
    "            'ci_lower': ci[0],\n",
    "            'ci_upper': ci[1],\n",
    "            'significant': coef_info['p'] < 0.05\n",
    "        })\n",
    "\n",
    "df_usage = pd.DataFrame(usage_summary)\n",
    "df_usage.to_csv('../results/tables/moderation_usage_summary.csv', index=False)\n",
    "print(f\"[SAVED] Usage frequency moderation summary: ../results/tables/moderation_usage_summary.csv\")\n",
    "\n",
    "# Table 3: Adoption Status Moderation Summary\n",
    "adoption_summary = []\n",
    "for status_label in ['Non-Adopter', 'Adopter']:\n",
    "    for construct in ['PE', 'EE', 'SI', 'FC', 'HM', 'PV', 'HB', 'VO', 'TR', 'EX', 'ER', 'AX']:\n",
    "        coef_info = adoption_results[status_label]['coefficients'][construct]\n",
    "        ci = adoption_ci_results[status_label].get(construct, (None, None))\n",
    "        \n",
    "        adoption_summary.append({\n",
    "            'adoption_status': status_label,\n",
    "            'predictor': construct,\n",
    "            'n': adoption_results[status_label]['n'],\n",
    "            'r_squared': adoption_results[status_label]['r_squared'],\n",
    "            'beta': coef_info['beta'],\n",
    "            'se': coef_info['se'],\n",
    "            't_value': coef_info['t'],\n",
    "            'p_value': coef_info['p'],\n",
    "            'ci_lower': ci[0],\n",
    "            'ci_upper': ci[1],\n",
    "            'significant': coef_info['p'] < 0.05\n",
    "        })\n",
    "\n",
    "df_adoption = pd.DataFrame(adoption_summary)\n",
    "df_adoption.to_csv('../results/tables/moderation_adoption_summary.csv', index=False)\n",
    "print(f\"[SAVED] Adoption status moderation summary: ../results/tables/moderation_adoption_summary.csv\")\n",
    "\n",
    "print(\"\\n[OK] All summary tables exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2acd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Hypothesis Decision Summary\n",
    "\n",
    "Synthesize findings across all moderation hypotheses (H4a-e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e632f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"HYPOTHESIS DECISION SUMMARY (H4a-e)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# H4a: Trust and Explainability stronger for professionals\n",
    "print(\"H4a: Trust (TR) and Explainability (EX) effects stronger for professionals\")\n",
    "print(\"     (discretionary context hypothesis)\")\n",
    "print()\n",
    "for role in sorted(roles):\n",
    "    tr_beta = role_results[role]['coefficients']['TR']['beta']\n",
    "    tr_p = role_results[role]['coefficients']['TR']['p']\n",
    "    ex_beta = role_results[role]['coefficients']['EX']['beta']\n",
    "    ex_p = role_results[role]['coefficients']['EX']['p']\n",
    "    print(f\"   {role}: TR β={tr_beta:.4f} (p={tr_p:.4f}), EX β={ex_beta:.4f} (p={ex_p:.4f})\")\n",
    "print()\n",
    "\n",
    "# H4b: Social Influence stronger for students\n",
    "print(\"H4b: Social Influence (SI) effects stronger for students\")\n",
    "print(\"     (normative pressure hypothesis)\")\n",
    "print()\n",
    "for role in sorted(roles):\n",
    "    si_beta = role_results[role]['coefficients']['SI']['beta']\n",
    "    si_p = role_results[role]['coefficients']['SI']['p']\n",
    "    print(f\"   {role}: SI β={si_beta:.4f} (p={si_p:.4f})\")\n",
    "print()\n",
    "\n",
    "# H4c: Habit stronger for high-frequency users\n",
    "print(\"H4c: Habit (HB) effect stronger for high-frequency users\")\n",
    "print()\n",
    "for usage in sorted(usage_levels):\n",
    "    hb_beta = usage_results[usage]['coefficients']['HB']['beta']\n",
    "    hb_p = usage_results[usage]['coefficients']['HB']['p']\n",
    "    print(f\"   {usage} Usage: HB β={hb_beta:.4f} (p={hb_p:.4f})\")\n",
    "print()\n",
    "\n",
    "# H4d: Anxiety weaker for high-frequency users\n",
    "print(\"H4d: Anxiety (AX) effect weaker for high-frequency users\")\n",
    "print(\"     (exposure effect hypothesis)\")\n",
    "print()\n",
    "for usage in sorted(usage_levels):\n",
    "    ax_beta = usage_results[usage]['coefficients']['AX']['beta']\n",
    "    ax_p = usage_results[usage]['coefficients']['AX']['p']\n",
    "    print(f\"   {usage} Usage: AX β={ax_beta:.4f} (p={ax_p:.4f})\")\n",
    "print()\n",
    "\n",
    "# H4e: Facilitators for adopters, Barriers for non-adopters\n",
    "print(\"H4e: Facilitators (F1) more salient for adopters; Barriers (F2) for non-adopters\")\n",
    "print()\n",
    "for status_label in ['Non-Adopter', 'Adopter']:\n",
    "    er_beta = adoption_results[status_label]['coefficients']['ER']['beta']\n",
    "    er_p = adoption_results[status_label]['coefficients']['ER']['p']\n",
    "    ax_beta = adoption_results[status_label]['coefficients']['AX']['beta']\n",
    "    ax_p = adoption_results[status_label]['coefficients']['AX']['p']\n",
    "    r2 = adoption_results[status_label]['r_squared']\n",
    "    print(f\"   {status_label}: R²={r2:.4f}\")\n",
    "    print(f\"      Barriers: ER β={er_beta:.4f} (p={er_p:.4f}), AX β={ax_beta:.4f} (p={ax_p:.4f})\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 6 MODERATION ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786afd8d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Visualization: Path Coefficient Comparison Across Groups\n",
    "\n",
    "Create forest plots comparing key path coefficients across moderator groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb00fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "Path('../results/plots').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Creating moderation visualization plots...\\n\")\n",
    "\n",
    "# This cell creates placeholder for visualization\n",
    "# We'll add specific forest plots for each moderation analysis\n",
    "\n",
    "print(\"[OK] Visualization setup complete\")\n",
    "print(\"    Next: Implement specific forest plots for role, usage, adoption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef4cbf3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Run this notebook** to generate all moderation results\n",
    "2. **Review hypothesis decisions** for H4a-e\n",
    "3. **Create visualizations** comparing path coefficients across groups\n",
    "4. **Update documentation** with Phase 6 findings\n",
    "5. **Proceed to Phase 7** (Integration & Chapter 4 writing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
