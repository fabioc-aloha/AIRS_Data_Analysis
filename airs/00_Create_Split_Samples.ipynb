{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f31c49",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b9467fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dba989d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample: N = 318\n",
      "Variables: 45\n",
      "\n",
      "First few columns: ['Duration_minutes', 'PE1', 'PE2', 'EE1', 'EE2', 'SI1', 'SI2', 'FC1', 'FC2', 'HM1']\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_csv('../data/AIRS_clean.csv')\n",
    "\n",
    "print(f\"Total sample: N = {len(df)}\")\n",
    "print(f\"Variables: {len(df.columns)}\")\n",
    "print(f\"\\nFirst few columns: {df.columns[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7cc4e",
   "metadata": {},
   "source": [
    "## 2. Pre-Split Distributions\n",
    "\n",
    "Document baseline distributions before splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd844fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRE-SPLIT DISTRIBUTIONS\n",
      "======================================================================\n",
      "\n",
      "1. Work Context:\n",
      "Work_Context\n",
      "Professional        168\n",
      "Academic-Student    105\n",
      "Academic-Faculty     45\n",
      "Name: count, dtype: int64\n",
      "Proportions: {'Professional': 52.8, 'Academic-Student': 33.0, 'Academic-Faculty': 14.2}\n",
      "\n",
      "2. AI Adoption:\n",
      "Adopters (1): 285 (89.6%)\n",
      "Non-Adopters (0): 33 (10.4%)\n",
      "\n",
      "3. Usage Intensity:\n",
      "Usage_Intensity\n",
      "Medium      102\n",
      "Low          93\n",
      "High         90\n",
      "Non-User     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4. Experience Level:\n",
      "Experience_Level\n",
      "Expert    110\n",
      "Entry      59\n",
      "Early      57\n",
      "Mid        52\n",
      "Senior     40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PRE-SPLIT DISTRIBUTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Work Context\n",
    "print(\"\\n1. Work Context:\")\n",
    "work_context_dist = df['Work_Context'].value_counts()\n",
    "print(work_context_dist)\n",
    "print(f\"Proportions: {(work_context_dist / len(df) * 100).round(1).to_dict()}\")\n",
    "\n",
    "# AI Adoption\n",
    "print(\"\\n2. AI Adoption:\")\n",
    "ai_adoption_dist = df['AI_Adoption'].value_counts()\n",
    "print(f\"Adopters (1): {ai_adoption_dist.get(1, 0)} ({ai_adoption_dist.get(1, 0)/len(df)*100:.1f}%)\")\n",
    "print(f\"Non-Adopters (0): {ai_adoption_dist.get(0, 0)} ({ai_adoption_dist.get(0, 0)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Usage Intensity\n",
    "print(\"\\n3. Usage Intensity:\")\n",
    "usage_intensity_dist = df['Usage_Intensity'].value_counts()\n",
    "print(usage_intensity_dist)\n",
    "\n",
    "# Experience Level\n",
    "print(\"\\n4. Experience Level:\")\n",
    "experience_dist = df['Experience_Level'].value_counts()\n",
    "print(experience_dist)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7cfad",
   "metadata": {},
   "source": [
    "## 3. Create Stratified Split\n",
    "\n",
    "Stratify by **Work Context × AI Adoption** to ensure balanced representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46b733e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratification groups (Work Context × AI Adoption):\n",
      "stratify_key\n",
      "Academic-Faculty_0      2\n",
      "Academic-Faculty_1     43\n",
      "Academic-Student_0      5\n",
      "Academic-Student_1    100\n",
      "Professional_0         26\n",
      "Professional_1        142\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique strata: 6\n"
     ]
    }
   ],
   "source": [
    "# Create stratification variable (Work Context × AI Adoption)\n",
    "df['stratify_key'] = df['Work_Context'].astype(str) + '_' + df['AI_Adoption'].astype(str)\n",
    "\n",
    "print(\"Stratification groups (Work Context × AI Adoption):\")\n",
    "print(df['stratify_key'].value_counts().sort_index())\n",
    "print(f\"\\nTotal unique strata: {df['stratify_key'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdf5a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPLIT-SAMPLE CREATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Development sample: N = 159 (50.0%)\n",
      "Holdout sample:     N = 159 (50.0%)\n",
      "Total:              N = 318\n",
      "\n",
      "✓ Stratified by: Work Context × AI Adoption\n",
      "✓ Random seed: 42 (reproducible)\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified 50/50 split\n",
    "df_dev, df_holdout = train_test_split(\n",
    "    df,\n",
    "    test_size=0.50,\n",
    "    stratify=df['stratify_key'],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SPLIT-SAMPLE CREATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDevelopment sample: N = {len(df_dev)} ({len(df_dev)/len(df)*100:.1f}%)\")\n",
    "print(f\"Holdout sample:     N = {len(df_holdout)} ({len(df_holdout)/len(df)*100:.1f}%)\")\n",
    "print(f\"Total:              N = {len(df)}\")\n",
    "print(\"\\n✓ Stratified by: Work Context × AI Adoption\")\n",
    "print(f\"✓ Random seed: {RANDOM_SEED} (reproducible)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54397d65",
   "metadata": {},
   "source": [
    "## 4. Validation: Post-Split Balance\n",
    "\n",
    "Verify stratification succeeded with chi-square tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2942b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POST-SPLIT BALANCE TESTS (Chi-Square)\n",
      "======================================================================\n",
      "\n",
      "Work_Context:\n",
      "                  Development  Holdout\n",
      "Work_Context                          \n",
      "Academic-Faculty           22       23\n",
      "Academic-Student           53       52\n",
      "Professional               84       84\n",
      "\n",
      "χ² = 0.032, df = 2, p = 0.9843\n",
      "✓ Balanced (p > 0.05): No significant difference between samples\n",
      "\n",
      "AI_Adoption:\n",
      "             Development  Holdout\n",
      "AI_Adoption                      \n",
      "0                     17       16\n",
      "1                    142      143\n",
      "\n",
      "χ² = 0.000, df = 1, p = 1.0000\n",
      "✓ Balanced (p > 0.05): No significant difference between samples\n"
     ]
    }
   ],
   "source": [
    "def test_balance(variable_name, dev_sample, holdout_sample):\n",
    "    \"\"\"\n",
    "    Test if variable distribution differs between development and holdout samples.\n",
    "    H0: Distributions are equal (balanced split)\n",
    "    \"\"\"\n",
    "    # Create proper contingency table\n",
    "    dev_counts = dev_sample[variable_name].value_counts().sort_index()\n",
    "    holdout_counts = holdout_sample[variable_name].value_counts().sort_index()\n",
    "    \n",
    "    contingency_table = pd.DataFrame({\n",
    "        'Development': dev_counts,\n",
    "        'Holdout': holdout_counts\n",
    "    }).fillna(0)\n",
    "    \n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\n{variable_name}:\")\n",
    "    print(contingency_table)\n",
    "    print(f\"\\nχ² = {chi2:.3f}, df = {dof}, p = {p_value:.4f}\")\n",
    "    \n",
    "    if p_value > 0.05:\n",
    "        print(f\"✓ Balanced (p > 0.05): No significant difference between samples\")\n",
    "    else:\n",
    "        print(f\"⚠ Imbalanced (p ≤ 0.05): Significant difference detected\")\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POST-SPLIT BALANCE TESTS (Chi-Square)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "p_work_context = test_balance('Work_Context', df_dev, df_holdout)\n",
    "p_ai_adoption = test_balance('AI_Adoption', df_dev, df_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa835e",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics: Compare Samples\n",
    "\n",
    "Compare key Likert item means to ensure no systematic bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7465ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LIKERT ITEM MEANS: Development vs. Holdout\n",
      "======================================================================\n",
      "\n",
      "Sample of items (first 8):\n",
      "     Development_M  Development_SD  Holdout_M  Holdout_SD   Diff  Abs_Diff\n",
      "PE1          3.597           1.131      3.616       1.152 -0.019     0.019\n",
      "PE2          3.340           1.195      3.346       1.222 -0.006     0.006\n",
      "EE1          3.748           0.968      3.786       1.040 -0.038     0.038\n",
      "EE2          3.610           1.055      3.629       1.003 -0.019     0.019\n",
      "SI1          3.063           1.178      3.138       1.214 -0.075     0.075\n",
      "SI2          3.283           1.175      3.415       1.075 -0.132     0.132\n",
      "FC1          3.270           1.221      3.195       1.193  0.075     0.075\n",
      "FC2          3.434           1.040      3.440       1.083 -0.006     0.006\n",
      "\n",
      "Mean absolute difference across all items: 0.062\n",
      "Max absolute difference: 0.220 (AX1)\n",
      "\n",
      "✓ Excellent balance: Mean difference < 0.10 scale points\n"
     ]
    }
   ],
   "source": [
    "# Define construct items\n",
    "construct_items = {\n",
    "    'PE': ['PE1', 'PE2'],\n",
    "    'EE': ['EE1', 'EE2'],\n",
    "    'SI': ['SI1', 'SI2'],\n",
    "    'FC': ['FC1', 'FC2'],\n",
    "    'HM': ['HM1', 'HM2'],\n",
    "    'PV': ['PV1', 'PV2'],\n",
    "    'HB': ['HB1', 'HB2'],\n",
    "    'VO': ['VO1', 'VO2'],\n",
    "    'TR': ['TR1', 'TR2'],\n",
    "    'EX': ['EX1', 'EX2'],\n",
    "    'ER': ['ER1', 'ER2'],\n",
    "    'AX': ['AX1', 'AX2'],\n",
    "    'BI': ['BI1', 'BI2', 'BI3', 'BI4']\n",
    "}\n",
    "\n",
    "all_items = [item for items in construct_items.values() for item in items]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LIKERT ITEM MEANS: Development vs. Holdout\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Development_M': df_dev[all_items].mean(),\n",
    "    'Development_SD': df_dev[all_items].std(),\n",
    "    'Holdout_M': df_holdout[all_items].mean(),\n",
    "    'Holdout_SD': df_holdout[all_items].std(),\n",
    "    'Diff': df_dev[all_items].mean() - df_holdout[all_items].mean()\n",
    "})\n",
    "\n",
    "comparison['Abs_Diff'] = comparison['Diff'].abs()\n",
    "\n",
    "print(\"\\nSample of items (first 8):\")\n",
    "print(comparison.head(8).round(3))\n",
    "\n",
    "print(f\"\\nMean absolute difference across all items: {comparison['Abs_Diff'].mean():.3f}\")\n",
    "print(f\"Max absolute difference: {comparison['Abs_Diff'].max():.3f} ({comparison['Abs_Diff'].idxmax()})\")\n",
    "\n",
    "if comparison['Abs_Diff'].mean() < 0.10:\n",
    "    print(\"\\n✓ Excellent balance: Mean difference < 0.10 scale points\")\n",
    "elif comparison['Abs_Diff'].mean() < 0.20:\n",
    "    print(\"\\n✓ Good balance: Mean difference < 0.20 scale points\")\n",
    "else:\n",
    "    print(\"\\n⚠ Review: Mean difference ≥ 0.20 scale points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d1834",
   "metadata": {},
   "source": [
    "## 6. Save Split Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc5be722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLES SAVED\n",
      "======================================================================\n",
      "\n",
      "✓ Development sample: data/AIRS_clean_dev.csv\n",
      "  N = 159, Variables = 45\n",
      "\n",
      "✓ Holdout sample: data/AIRS_clean_holdout.csv\n",
      "  N = 159, Variables = 45\n",
      "\n",
      "✓ Stratification key removed from saved files\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remove temporary stratification key\n",
    "df_dev_clean = df_dev.drop(columns=['stratify_key'])\n",
    "df_holdout_clean = df_holdout.drop(columns=['stratify_key'])\n",
    "\n",
    "# Save to CSV\n",
    "df_dev_clean.to_csv('../data/AIRS_clean_dev.csv', index=False)\n",
    "df_holdout_clean.to_csv('../data/AIRS_clean_holdout.csv', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLES SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✓ Development sample: data/AIRS_clean_dev.csv\")\n",
    "print(f\"  N = {len(df_dev_clean)}, Variables = {len(df_dev_clean.columns)}\")\n",
    "print(f\"\\n✓ Holdout sample: data/AIRS_clean_holdout.csv\")\n",
    "print(f\"  N = {len(df_holdout_clean)}, Variables = {len(df_holdout_clean.columns)}\")\n",
    "print(\"\\n✓ Stratification key removed from saved files\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6b804",
   "metadata": {},
   "source": [
    "## 7. Summary and Quality Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bcefd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPLIT-SAMPLE VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Quality Checklist:\n",
      "  ✓ Sample sizes approximately equal\n",
      "  ✓ Development sample ≥ 150 (adequate for EFA)\n",
      "  ✓ Holdout sample ≥ 150 (adequate for CFA)\n",
      "  ✓ Work Context balanced (p > 0.05)\n",
      "  ✓ AI Adoption balanced (p > 0.05)\n",
      "  ✓ Mean item difference < 0.20\n",
      "  ✓ Files saved successfully\n",
      "\n",
      "======================================================================\n",
      "✅ ALL VALIDATION CHECKS PASSED\n",
      "======================================================================\n",
      "\n",
      "Ready for Phase 1: Exploratory Factor Analysis (EFA)\n",
      "Next notebook: 01_EFA_Split_Sample_Development.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SPLIT-SAMPLE VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "checks = [\n",
    "    (\"Sample sizes approximately equal\", abs(len(df_dev) - len(df_holdout)) <= 2),\n",
    "    (\"Development sample ≥ 150 (adequate for EFA)\", len(df_dev) >= 150),\n",
    "    (\"Holdout sample ≥ 150 (adequate for CFA)\", len(df_holdout) >= 150),\n",
    "    (\"Work Context balanced (p > 0.05)\", p_work_context > 0.05),\n",
    "    (\"AI Adoption balanced (p > 0.05)\", p_ai_adoption > 0.05),\n",
    "    (\"Mean item difference < 0.20\", comparison['Abs_Diff'].mean() < 0.20),\n",
    "    (\"Files saved successfully\", True)  # If we got here, it succeeded\n",
    "]\n",
    "\n",
    "print(\"\\nQuality Checklist:\")\n",
    "for check, passed in checks:\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {check}\")\n",
    "\n",
    "all_passed = all(passed for _, passed in checks)\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✅ ALL VALIDATION CHECKS PASSED\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nReady for Phase 1: Exploratory Factor Analysis (EFA)\")\n",
    "    print(\"Next notebook: 01_EFA_Split_Sample_Development.ipynb\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠ REVIEW REQUIRED\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nSome validation checks failed. Review results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf33d59",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**Stratification Strategy**:\n",
    "- Stratified by Work Context × AI Adoption (6 groups)\n",
    "- Ensures balanced representation of key moderator variables\n",
    "- Critical for moderation analysis (H4)\n",
    "\n",
    "**Sample Size Adequacy**:\n",
    "- N ≈ 159 per sample supports 12-factor CFA (N:q ratio ≈ 6.6:1 for 24 items)\n",
    "- Minimum recommended: 5:1 for stable solutions (Bentler & Chou, 1987)\n",
    "- Both samples adequate for planned analyses\n",
    "\n",
    "**Random Seed**: 42 (reproducible splits for dissertation transparency)\n",
    "\n",
    "**Next Steps**:\n",
    "1. Run EFA on development sample (polychoric correlations)\n",
    "2. Select items based on loadings ≥ 0.50, cross-loadings < 0.30\n",
    "3. Test measurement model with CFA on holdout sample\n",
    "4. Proceed to structural modeling if fit indices acceptable\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
