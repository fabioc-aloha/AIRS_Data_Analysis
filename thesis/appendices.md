<!-- markdownlint-disable MD029 MD041 -->
# Appendices

## Appendix A: AI Readiness Scale (AIRS) Final 16-Item Instrument

The final validated 16-item AIRS instrument consists of eight constructs measured using a 5-point Likert scale (1 = Strongly Disagree to 5 = Strongly Agree).

### Performance Expectancy (PE)

1. **PE1**: AI tools help me accomplish tasks more quickly.
2. **PE2**: Using AI improves the quality of my work or studies.

### Effort Expectancy (EE)

3. **EE1**: Learning to use AI tools is easy for me.
4. **EE2**: Interacting with AI tools is clear and understandable.

### Social Influence (SI)

5. **SI1**: People whose opinions I value encourage me to use AI tools.
6. **SI2**: Leaders in my organization or school support the use of AI tools.

### Facilitating Conditions (FC)

7. **FC1**: I have access to training or tutorials for the AI tools I use.
8. **FC2**: The AI tools I use are compatible with other tools or systems I use.

### Hedonic Motivation (HM)

9. **HM1**: Using AI tools is stimulating and engaging.
10. **HM2**: AI tools make my work or studies more interesting.

### Price Value (PV)

11. **PV1**: I get more value from AI tools than the effort they require.
12. **PV2**: Using AI tools is worth the learning curve.

### Habit (HB)

13. **HB1**: Using AI tools has become a habit for me.
14. **HB2**: I tend to rely on AI tools by default when I need help with tasks.

### Trust in AI (TR)

15. **TR1**: I trust AI tools to provide reliable information.
16. **TR2**: I trust the AI tools that are available to me.

\newpage

## Appendix B: Survey Materials

### B.1 Participant Information Sheet

The online survey was administered via Qualtrics following institutional ethics approval. Participants received information about the study purpose, voluntary participation, data confidentiality, and right to withdraw at any time without penalty. The study was described as research investigating individuals' perceptions and use of artificial intelligence tools in academic and professional contexts.

### B.2 Informed Consent Form

Electronic informed consent was obtained prior to survey administration. Participants confirmed they were 18 years or older, understood the study purpose, and agreed to participate voluntarily. Consent was recorded through affirmative response before access to survey items.

### B.3 Demographic Questions

Demographic items collected included:

- **Role**: Current employment/student status (Full-time student, Part-time student, Employed - individual contributor, Employed - manager, Employed - executive, Freelancer/self-employed, Not currently employed, Other)
- **Education**: Highest level completed (High school or less, Some college/vocational, Associate's degree, Bachelor's degree, Master's degree, Doctoral/professional degree)
- **Industry**: Primary field of work or study (Technology/IT, Healthcare, Education, Finance/Banking, Manufacturing, Government/Public sector, Retail/Hospitality, Nonprofit, Other)
- **Experience**: Years of experience in field (Less than 1 year, 1-3 years, 4-6 years, 7-10 years, 11 or more years)
- **Disability Status**: Self-disclosed (Yes, No, Prefer not to say)
- **AI Tool Usage**: Frequency of use for Microsoft Copilot, ChatGPT, Google Gemini, and other AI tools (Never, Rarely, Sometimes, Often, Very Often)

\newpage

## Appendix C: Supplementary Statistical Tables

### C.1 Construct Reliability Summary

| Construct | Abbreviation | Cronbach's α | CR | AVE | Items |
|-----------|--------------|--------------|-----|-----|-------|
| Performance Expectancy | PE | .803 | .804 | .673 | PE1, PE2 |
| Effort Expectancy | EE | .859 | .861 | .756 | EE1, EE2 |
| Social Influence | SI | .752 | .763 | .621 | SI1, SI2 |
| Facilitating Conditions | FC | .743 | .750 | .601 | FC1, FC2 |
| Hedonic Motivation | HM | .864 | .865 | .763 | HM1, HM2 |
| Price Value | PV | .883 | .883 | .790 | PV1, PV2 |
| Habit | HB | .909 | .909 | .833 | HB1, HB2 |
| Trust in AI | TR | .891 | .891 | .804 | TR1, TR2 |

*Note*. α = Cronbach's alpha; CR = Composite Reliability; AVE = Average Variance Extracted. All retained constructs exceed minimum thresholds (α ≥ .70, CR ≥ .70, AVE ≥ .50). Behavioral Intention (BI) serves as the outcome variable and is modeled separately in the structural model.

### C.2 Model Fit Indices Summary

| Model | χ² | df | p | CFI | TLI | RMSEA | 90% CI |
|-------|-----|-----|----|----|-----|--------|--------|
| CFA (8-factor) | 191.25 | 98 | <.001 | .975 | .960 | .065 | [.051, .079] |
| Structural Model | 354.32 | 169 | <.001 | .967 | .953 | .070 | [.059, .081] |

*Note*. CFI = Comparative Fit Index; TLI = Tucker-Lewis Index; RMSEA = Root Mean Square Error of Approximation.

### C.3 Constructs Removed During Validation

| Construct | Abbreviation | Cronbach's α | Reason for Removal |
|-----------|--------------|--------------|-------------------|
| Voluntariness | VO | .406 | Unacceptable reliability |
| Explainability | EX | .582 | Poor reliability |
| Perceived Ethical Risk | ER | .546 | Poor reliability |
| AI Anxiety | AX | .301 | Unacceptable reliability |

*Note*. Constructs were removed during EFA due to α < .70 threshold.

\newpage

## Appendix D: Supplementary Figures

This appendix presents additional visualizations from the empirical analysis that support the findings reported in Chapters 4 and 5.

### D.1 Sample Preparation

![Figure D.1: Sample Preparation Overview](figures/fig_sample_overview.png){width=90%}

*Figure D.1. Overview of sample preparation process, including data cleaning, split-sample design, and final sample composition across student and professional populations.*

### D.2 AI Tool Usage Patterns

![Figure D.2: AI Tool Usage Distribution](figures/fig_usage_distribution.png){width=85%}

*Figure D.2. Distribution of AI tool usage frequency across the sample. ChatGPT demonstrates the highest adoption rates, followed by Microsoft Copilot and Google Gemini.*

### D.3 Disability and AI Anxiety

![Figure D.3: Disability Status and AI Anxiety](figures/fig_disability_anxiety.png){width=80%}

*Figure D.3. Comparison of AI anxiety levels between participants with and without disclosed disabilities. Effect size d = .36 indicates moderate elevation of anxiety for participants with disabilities.*

\newpage

## Appendix E: AIRS Research Roadmap and Future Applications

This appendix outlines the research program envisioned to extend the validated AIRS instrument into practical organizational applications. The roadmap represents a multi-phase research agenda that builds systematically on the foundation established in this dissertation.

### E.1 Research Program Overview

The AI Readiness Scale (AIRS) validated in this dissertation represents Phase 0 of a comprehensive research program aimed at bridging the gap between AI adoption measurement and organizational AI maturity. The roadmap below outlines subsequent research phases, each requiring independent empirical validation.

| Phase | Focus | Key Deliverables |
|-------|-------|------------------|
| **Phase 0** | Scale Validation | ✅ This Dissertation: 8-factor, 16-item AIRS, structural model, user typology |
| **Phase 1** | Scoring System | AIRS Score algorithm, normative benchmarks, readiness classifications |
| **Phase 2** | Organizational Diagnostics | Team/org-level assessment, gap analysis, benchmarking protocols |
| **Phase 3** | Intervention Research | Segment-specific interventions, randomized trials, effectiveness validation |
| **Phase 4** | AI Readiness Ecosystem | Longitudinal tracking, industry adaptations, practitioner certification |

### E.2 Phase 1: AIRS Score Development

**Research Objective**: Develop a scoring methodology that transforms raw AIRS responses into interpretable individual readiness scores with established normative benchmarks.

**Key Research Questions**:

- How should construct scores be weighted to optimize predictive validity?
- What normative distributions exist across student, professional, and leadership populations?
- What classification system best communicates readiness levels to practitioners?

### E.3 Phase 2: Organizational Diagnostics

**Research Objective**: Develop validated protocols for assessing AI readiness at team and organizational levels.

**Key Research Questions**:

- What aggregation methods preserve construct validity at organizational levels?
- Do organizational readiness profiles predict AI implementation success?
- What reporting formats maximize practitioner utility?

### E.4 Phase 3: Intervention Research

**Research Objective**: Design and empirically test segment-specific interventions based on the user typology framework.

The four-segment typology identified in this dissertation (AI Enthusiasts, Cautious Adopters, Moderate Users, Anxious Avoiders) suggests that different user populations may respond to different intervention approaches. Future research should employ randomized controlled trials to test whether segment-matched interventions outperform generic approaches.

**Key Research Questions**:

- Do segment-specific interventions outperform one-size-fits-all approaches?
- What intervention components drive segment-specific effectiveness?
- Do intervention effects persist over 6-12 month follow-up periods?

### E.5 Phase 4: Comprehensive AI Readiness Ecosystem

**Research Objective**: Develop an integrated system combining validated assessment, diagnostics, and intervention protocols.

**Long-Term Vision**:

- **Longitudinal Tracking**: Systems for monitoring organizational AI readiness progression
- **Industry Adaptations**: Validated modifications for healthcare, finance, education, and manufacturing contexts
- **Cross-Cultural Validation**: Replication across collectivist cultures, developing economies, and varying policy environments
- **Practitioner Resources**: Administration guides, interpretation frameworks, and training pathways

### E.6 Contribution to the Field

This research program addresses a critical gap in the technology adoption literature: while validated measurement instruments exist, the translation of assessment into organizational action remains underdeveloped. By systematically building from validated measurement through scoring, diagnostics, intervention, and ecosystem development, this roadmap offers a research-to-practice pipeline that can ultimately deliver the evidence-based tools organizations need to close the AI adoption-value gap.

### E.7 Collaboration and Licensing

The AIRS instrument validated in this dissertation is made available for academic research purposes. Organizations interested in applying the AIRS framework for organizational assessment should contact the author to discuss appropriate use, validation requirements, and potential research collaboration opportunities.

**Contact**: Dr. Fabio Correa | [Institution] | [Email]

\newpage

## Appendix F: Institutional Review Board Documentation

### F.1 IRB Approval

This study was reviewed and approved by the Touro University Worldwide Institutional Review Board (IRB) prior to data collection. The study was classified as exempt under 45 CFR 46.104(d)(2) as research involving survey procedures where responses are recorded anonymously.

**IRB Protocol Number**: T00571337

**Application Date**: October 29, 2025

**Principal Investigator**: Fabio Correa, DBA Candidate

**Faculty Advisor (Chair of Committee)**: Dr. Karina Kasztelnik

**Institution**: Touro University Worldwide, School of Business

The signed IRB approval letter follows on the next page.

\includepdf[pages=-]{Fabio_Correa__IRB_Approval_Letter.pdf}

### F.2 Research Purpose and Methodology

As stated in the IRB application, the purpose of this research was to examine the psychological, motivational, and contextual factors that influence enterprise employees' readiness to adopt artificial intelligence (AI) tools. The study extended the UTAUT2 framework by adding four AI-specific constructs—trust in AI, explainability, perceived ethical risk, and AI-related anxiety—to develop and validate the Artificial Intelligence Readiness Scale (AIRS).

**Research Questions**:

1. What psychological, motivational, and contextual factors influence individual readiness to adopt AI technologies within large enterprises?
2. To what extent do UTAUT2 constructs predict AI adoption readiness?

**Participant Recruitment**: Participants were recruited externally through Centiment, a professional survey research platform maintaining verified panels of adult participants across diverse industries, roles, and geographic regions. Target sample size was n ≈ 500 respondents.

**Risk Classification**: Exempt (minimal risk limited to potential discomfort reflecting on AI-related attitudes or privacy concerns).

### F.3 Informed Consent Statement

The following informed consent statement was presented to all participants prior to survey administration via the Centiment platform:

---

**Participation in a Research Study**

**Institutional Review Board – Touro University Worldwide**

**Enterprise AI Readiness Research**

You are invited to participate in a research study conducted by Fabio Correa, a doctoral candidate in the Doctor of Business Administration program at Touro University Worldwide. The purpose of this study is to understand how individual, psychological, and contextual factors influence employee readiness to adopt artificial intelligence (AI) tools in the enterprise workplace. This study explores constructs from the Unified Theory of Acceptance and Use of Technology (UTAUT2) and AI-specific enablers and inhibitors, including trust in AI, explainability, perceived ethical risk, and AI-related anxiety.

Your participation will involve completing an online survey that takes approximately 10–15 minutes. The survey includes questions about your experiences and perceptions of AI tools, such as Microsoft 365 Copilot, ChatGPT, and other AI applications. Participation is voluntary, and you may withdraw at any time without penalty or consequence.

**Risks and Discomforts**: The risks involved in this study are minimal. Some participants may experience minor discomfort when reflecting on their attitudes or experiences with AI, or concerns related to privacy or job impact. You may skip any question that makes you uncomfortable.

**Potential Benefits**: While there are no direct benefits to you, your participation will contribute to advancing understanding of how employees and organizations can prepare for AI adoption responsibly and effectively.

**Protection of Confidentiality**: All survey responses will be kept confidential. Data collection will occur through a secure online platform (Centiment) with no personally identifiable information collected. Results will be reported in aggregate form, and no individual responses will be identifiable.

**Voluntary Participation**: Your participation in this study is entirely voluntary. You may choose not to participate or may withdraw at any time without penalty or loss of benefits.

**Contact Information**: If you have questions about this study, contact Fabio Correa, Doctoral Candidate, Touro University Worldwide. If you have questions about your rights as a research participant, contact the Touro University Worldwide IRB at (818) 874-4115.

**Consent**: By clicking "Yes, I agree" below and completing the online survey, you confirm that you have read this consent form, are at least 18 years of age, and voluntarily agree to participate in this research study.

☐ Yes, I agree to participate
☐ No, I do not wish to participate

---

### F.4 Data Management and Privacy

**Data Collection Platform**: Centiment online survey panel

**Data Storage**: Survey responses were collected and stored on Centiment's secure servers, then exported to the researcher's encrypted institutional storage for analysis.

**Anonymity**: No personally identifiable information (names, email addresses, IP addresses) was collected or retained. Responses cannot be linked to individual participants.

**Data Retention**: De-identified data will be retained until January 2028 in accordance with federal regulations requiring researchers to keep data for a minimum of three years (45 CFR 46).

### F.5 Ethical Principles Certification

The researcher certified compliance with the Touro University Worldwide Ethical Principles & Guidelines for Research Involving Human Subjects, adapted from The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research (April 18, 1979), including:

1. **Informed Consent**: Subjects were given the opportunity to choose what shall or shall not happen to them
2. **Comprehension**: Information was conveyed clearly with adequate time for consideration
3. **Voluntariness**: Participation was free of coercion and undue influence
4. **Assessment of Risks and Benefits**: Systematic review confirmed minimal risk classification
5. **Justice**: Fair selection of subjects without favoritism or bias
6. **Social Justice**: Appropriate consideration of participant burden and class selection

\newpage

## Appendix G: Complete Survey Instrument as Administered

This appendix reproduces the complete AI Readiness Scale (AIRS) survey instrument exactly as administered to participants via the Centiment online panel in November 2024.

---

### Survey Introduction

**Welcome to the AI Readiness Survey**

Thank you for participating in this research study. This survey explores your experiences and perceptions regarding artificial intelligence (AI) tools in work and educational settings.

The survey takes approximately 10-15 minutes to complete. Please answer all questions honestly based on your current experiences. There are no right or wrong answers.

---

### Section 1: UTAUT2 Core Constructs

*Please indicate your level of agreement with each statement based on your current work or study experience.*

**Scale**: 1 = Strongly disagree | 2 = Disagree | 3 = Neutral | 4 = Agree | 5 = Strongly agree

#### Performance Expectancy

1. AI tools help me accomplish tasks more quickly.
2. Using AI improves the quality of my work or studies.

#### Effort Expectancy

3. Learning to use AI tools is easy for me.
4. Interacting with AI tools is clear and understandable.

#### Social Influence

5. People whose opinions I value encourage me to use AI tools.
6. Leaders in my organization or school support the use of AI tools.

#### Facilitating Conditions

7. I have access to training or tutorials for the AI tools I use.
8. The AI tools I use are compatible with other tools or systems I use.

#### Hedonic Motivation

9. Using AI tools is stimulating and engaging.
10. AI tools make my work or studies more interesting.

#### Price Value

11. I get more value from AI tools than the effort they require.
12. Using AI tools is worth the learning curve.

#### Habit

13. Using AI tools has become a habit for me.
14. I tend to rely on AI tools by default when I need help with tasks.

#### Voluntariness

15. I choose to use AI tools in my work because I find them helpful, not because I am required to.
16. I could choose not to use AI tools in my work or studies if I preferred.

---

### Section 2: AI-Specific Constructs

#### Trust in AI

17. I trust AI tools to provide reliable information.
18. I trust the AI tools that are available to me.

#### Explainability

19. I understand how the AI tools I use generate their outputs.
20. I prefer AI tools that explain their recommendations.

#### Perceived Ethical Risk

21. I worry that AI tools could replace jobs in my field.
22. I am concerned about privacy risks when using AI tools.

#### AI Anxiety

23. I feel uneasy about the increasing use of AI.
24. I worry that I may be left behind if I do not keep up with AI.

---

### Section 3: AI Adoption Readiness (Behavioral Intention)

25. I am ready to use more AI tools in my work or studies.
26. I would recommend AI tools to others.
27. I see AI as an important part of my future.
28. I plan to increase my use of AI tools in the next six months.

---

### Section 4: AI Tool Usage Frequency

*How often do you use each of the following AI tools?*

**Scale**: 1 = Never | 2 = Rarely | 3 = Sometimes | 4 = Often | 5 = Very often (Daily)

29. Microsoft 365 Copilot or Microsoft Copilot
30. ChatGPT
31. Google Gemini
32. Other AI tools (for example, Claude, Perplexity, Jasper)

---

### Section 5: Demographics

33. **What is your highest level of education completed?**
    - High school or less
    - Some college or vocational training
    - Bachelor's degree
    - Master's degree
    - Doctoral or professional degree

34. **What is your current status?**
    - Full-time student
    - Part-time student
    - Employed — individual contributor
    - Employed — manager
    - Employed — executive or leader
    - Freelancer or self-employed
    - Not currently employed
    - Other

35. **Which industry or field best describes your primary area of work or study?**
    - Technology or IT
    - Education
    - Healthcare
    - Finance or Banking
    - Manufacturing
    - Retail or Hospitality
    - Government or Public sector
    - Nonprofit
    - Other

36. **How many years of work or study experience do you have in your field?**
    - Less than 1 year
    - 1 to 3 years
    - 4 to 6 years
    - 7 to 10 years
    - 11 or more years

37. **Do you identify as a person with a disability (for example, vision, mobility, neurodivergence)?**
    - Yes
    - No
    - Prefer not to answer

---

### Section 6: Open Feedback (Optional)

38. **Do you have any other feedback about your experiences with AI tools?**

[Open text response field]

---

### Survey Completion

Thank you for completing this survey. Your responses will contribute to research on AI adoption in academic and professional settings.

If you have questions about this study, please contact the research team.

---

*Note: Items 15-16 (Voluntariness), 19-20 (Explainability), 21-22 (Perceived Ethical Risk), and 23-24 (AI Anxiety) were administered but subsequently removed from the final validated instrument due to insufficient reliability (α < .70) as documented in Chapter 4.*
