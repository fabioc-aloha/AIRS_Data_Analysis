<!-- markdownlint-disable MD029 MD041 -->
# Appendices

## Appendix A: AI Readiness Scale (AIRS) Final 16-Item Diagnostic Instrument

The final validated 16-item AIRS diagnostic instrument consists of eight constructs measured using a 5-point Likert scale (1 = Strongly Disagree to 5 = Strongly Agree). The 8-factor structure enables both research applications and organizational diagnostic use: practitioners can identify specific adoption barriers (e.g., trust deficits, inadequate perceived value, low social influence) and design targeted interventions.

### Performance Expectancy (PE)

1. **PE1**: AI tools help me accomplish tasks more quickly.
2. **PE2**: Using AI improves the quality of my work or studies.

### Effort Expectancy (EE)

3. **EE1**: Learning to use AI tools is easy for me.
4. **EE2**: Interacting with AI tools is clear and understandable.

### Social Influence (SI)

5. **SI1**: People whose opinions I value encourage me to use AI tools.
6. **SI2**: Leaders in my organization or school support the use of AI tools.

### Facilitating Conditions (FC)

7. **FC1**: I have access to training or tutorials for the AI tools I use.
8. **FC2**: The AI tools I use are compatible with other tools or systems I use.

### Hedonic Motivation (HM)

9. **HM1**: Using AI tools is stimulating and engaging.
10. **HM2**: AI tools make my work or studies more interesting.

### Price Value (PV)

11. **PV1**: I get more value from AI tools than the effort they require.
12. **PV2**: Using AI tools is worth the learning curve.

### Habit (HB)

13. **HB1**: Using AI tools has become a habit for me.
14. **HB2**: I tend to rely on AI tools by default when I need help with tasks.

### Trust in AI (TR)

15. **TR1**: I trust AI tools to provide reliable information.
16. **TR2**: I trust the AI tools that are available to me.

\newpage

## Appendix B: Survey Materials

### B.1 Participant Information Sheet

The online survey was administered via Centiment following institutional ethics approval. Self-selection bias was mitigated through Centiment's platform-level recruitment design: survey invitations to panel members display only the estimated completion time and reward amount, with the survey topic deliberately concealed \"in order to avoid selection bias\" (Centiment, 2024). After accessing the survey link, participants received full disclosure about the AI focus through the informed consent form, which described the study purpose, voluntary participation, data confidentiality, and right to withdraw at any time without penalty. This two-stage approach (blinded recruitment followed by informed consent) ensured ethical transparency while reducing systematic bias in participant self-selection.

### B.2 Informed Consent Form

Electronic informed consent was obtained prior to survey administration. Participants confirmed they were 18 years or older, understood the study purpose, and agreed to participate voluntarily. Consent was recorded through affirmative response before access to survey items.

### B.3 Demographic Questions

Demographic items collected included:

- **Role**: Current employment/student status (Full-time student, Part-time student, Employed - individual contributor, Employed - manager, Employed - executive, Freelancer/self-employed, Not currently employed, Other)
- **Education**: Highest level completed (High school or less, Some college/vocational, Associate's degree, Bachelor's degree, Master's degree, Doctoral/professional degree)
- **Industry**: Primary field of work or study (Technology/IT, Healthcare, Education, Finance/Banking, Manufacturing, Government/Public sector, Retail/Hospitality, Nonprofit, Other)
- **Experience**: Years of experience in field (Less than 1 year, 1-3 years, 4-6 years, 7-10 years, 11 or more years)
- **Disability Status**: Self-disclosed (Yes, No, Prefer not to say)
- **AI Tool Usage**: Frequency of use for Microsoft Copilot, ChatGPT, Google Gemini, and other AI tools (Never, Rarely, Sometimes, Often, Very Often)

\newpage

## Appendix C: Supplementary Statistical Tables

### C.1 Construct Reliability Summary

| Construct | Abbreviation | Cronbach's α | CR | AVE | Items |
|-----------|--------------|--------------|-----|-----|-------|
| Performance Expectancy | PE | .803 | .804 | .673 | PE1, PE2 |
| Effort Expectancy | EE | .859 | .861 | .756 | EE1, EE2 |
| Social Influence | SI | .752 | .763 | .621 | SI1, SI2 |
| Facilitating Conditions | FC | .743 | .750 | .601 | FC1, FC2 |
| Hedonic Motivation | HM | .864 | .865 | .763 | HM1, HM2 |
| Price Value | PV | .883 | .883 | .790 | PV1, PV2 |
| Habit | HB | .909 | .909 | .833 | HB1, HB2 |
| Trust in AI | TR | .891 | .891 | .804 | TR1, TR2 |

*Note*. α = Cronbach's alpha; CR = Composite Reliability; AVE = Average Variance Extracted. All retained constructs exceed minimum thresholds (α ≥ .70, CR ≥ .70, AVE ≥ .50). Behavioral Intention (BI) serves as the outcome variable and is modeled separately in the structural model. Source: Compiled by Author

### C.2 Model Fit Indices Summary

| Model | χ² | df | p | CFI | TLI | RMSEA | 90% CI |
|-------|-----|-----|----|----|-----|--------|--------|
| CFA (8-factor) | 191.25 | 98 | <.001 | .975 | .960 | .065 | [.051, .079] |
| Structural Model | 354.32 | 169 | <.001 | .967 | .953 | .070 | [.059, .081] |

*Note*. CFI = Comparative Fit Index; TLI = Tucker-Lewis Index; RMSEA = Root Mean Square Error of Approximation. Source: Compiled by Author

### C.3 Constructs Removed During Validation

| Construct | Abbreviation | Cronbach's α | Reason for Removal |
|-----------|--------------|--------------|-------------------|
| Voluntariness | VO | .406 | Unacceptable reliability |
| Explainability | EX | .582 | Poor reliability |
| Perceived Ethical Risk | ER | .546 | Poor reliability |
| AI Anxiety | AX | .301 | Unacceptable reliability |

*Note*. Constructs were removed during EFA due to α < .70 threshold. Source: Compiled by Author

\newpage

## Appendix D: Supplementary Figures

This appendix presents additional visualizations from the empirical analysis that support the findings reported in Chapters 4 and 5.

### D.1 Sample Preparation

![](figures/fig_sample_overview.png){width=90%}

*Figure D.1. Overview of sample preparation process, including data cleaning, split-sample design, and final sample composition across student and professional populations. Source: Compiled by Author*

### D.2 AI Tool Usage Patterns

![](figures/fig_usage_distribution.png){width=85%}

*Figure D.2. Distribution of AI tool usage frequency across the sample. ChatGPT demonstrates the highest adoption rates, followed by Microsoft Copilot and Google Gemini. Source: Compiled by Author*

### D.3 Disability and AI Anxiety

![](figures/fig_disability_anxiety.png){width=80%}

*Figure D.3. Comparison of AI anxiety levels between participants with and without disclosed disabilities. Effect size d = .36 indicates moderate elevation of anxiety for participants with disabilities. Source: Compiled by Author*

\newpage

## Appendix E: AIRS Research Roadmap and Future Applications

This appendix outlines the research program envisioned to extend the validated AIRS diagnostic instrument into practical organizational applications. The 8-factor structure already enables identification of specific adoption barriers; this roadmap represents a multi-phase research agenda to develop formalized protocols that build systematically on the foundation established in this dissertation.

### E.1 Research Program Overview

The AI Readiness Scale (AIRS) validated in this dissertation represents Phase 0 of a comprehensive research program aimed at bridging the gap between AI adoption measurement and organizational AI maturity. The 8-factor diagnostic structure was selected over a more parsimonious 7-factor model because AI Trust provides essential diagnostic capability: organizations can identify trust deficits and design targeted interventions. The roadmap below outlines subsequent research phases, each requiring independent empirical validation.

| Phase | Focus | Key Deliverables |
|-------|-------|------------------|
| **Phase 0** | Scale Validation | [OK] This Dissertation: 8-factor, 16-item AIRS diagnostic instrument, structural model, user typology |
| **Phase 1** | Scoring System | AIRS Score algorithm, normative benchmarks, readiness classifications |
| **Phase 2** | Organizational Diagnostics | Team/org-level assessment, gap analysis, benchmarking protocols |
| **Phase 3** | Intervention Research | Segment-specific interventions, randomized trials, effectiveness validation |
| **Phase 4** | AI Readiness Ecosystem | Longitudinal tracking, industry adaptations, practitioner certification |

*Source: Compiled by Author*

### E.2 Phase 1: AIRS Score Development

**Research Objective**: Develop a scoring methodology that transforms raw AIRS responses into interpretable individual readiness scores with established normative benchmarks.

**Key Research Questions**:

- How should construct scores be weighted to optimize predictive validity?
- What normative distributions exist across student, professional, and leadership populations?
- What classification system best communicates readiness levels to practitioners?

### E.3 Phase 2: Organizational Diagnostics

**Research Objective**: Develop validated protocols for assessing AI readiness at team and organizational levels.

**Key Research Questions**:

- What aggregation methods preserve construct validity at organizational levels?
- Do organizational readiness profiles predict AI implementation success?
- What reporting formats maximize practitioner utility?

### E.4 Phase 3: Intervention Research

**Research Objective**: Design and empirically test segment-specific interventions based on the user typology framework.

The four-segment typology identified in this dissertation (AI Enthusiasts, Cautious Adopters, Moderate Users, Anxious Avoiders) suggests that different user populations may respond to different intervention approaches. Future research should employ randomized controlled trials to test whether segment-matched interventions outperform generic approaches.

**Key Research Questions**:

- Do segment-specific interventions outperform one-size-fits-all approaches?
- What intervention components drive segment-specific effectiveness?
- Do intervention effects persist over 6-12 month follow-up periods?

### E.5 Phase 4: Comprehensive AI Readiness Ecosystem

**Research Objective**: Develop an integrated system combining validated assessment, diagnostics, and intervention protocols.

**Long-Term Vision**:

- **Longitudinal Tracking**: Systems for monitoring organizational AI readiness progression
- **Industry Adaptations**: Validated modifications for healthcare, finance, education, and manufacturing contexts
- **Cross-Cultural Validation**: Replication across collectivist cultures, developing economies, and varying policy environments
- **Practitioner Resources**: Administration guides, interpretation frameworks, and training pathways

### E.6 Contribution to the Field

This research program addresses a critical gap in the technology adoption literature: while validated measurement instruments exist, the translation of assessment into organizational action remains underdeveloped. The AIRS diagnostic structure provides the foundation for this translation by enabling identification of specific adoption barriers. By systematically building from validated diagnostic measurement through scoring, formalized protocols, intervention research, and ecosystem development, this roadmap offers a research-to-practice pipeline that can ultimately deliver the evidence-based tools organizations need to close the AI adoption-value gap.

### E.7 Collaboration and Licensing

The AIRS diagnostic instrument validated in this dissertation is made available for academic research purposes. Organizations interested in applying the AIRS framework for organizational diagnostic assessment should contact the author to discuss appropriate use, validation requirements, and potential research collaboration opportunities.

**Contact**: Fabio Correa, Doctoral Candidate | Touro University Worldwide

\newpage

## Appendix F: Institutional Review Board Documentation

### F.1 IRB Approval

This study was reviewed and approved by the Touro University Worldwide Institutional Review Board (IRB) prior to data collection. The study was classified as exempt under 45 CFR 46.104(d)(2) as research involving survey procedures where responses are recorded anonymously.

**IRB Protocol Number**: T00571337

**Application Date**: October 29, 2025

**Principal Investigator**: Fabio Correa, DBA Candidate

**Faculty Advisor (Chair of Committee)**: Dr. Karina Kasztelnik

**Institution**: Touro University Worldwide, School of Business

The signed IRB approval letter follows on the next page.

\includepdf[pages=-]{Fabio_Correa__IRB_Approval_Letter.pdf}

### F.2 Research Purpose and Methodology

As stated in the IRB application, the purpose of this research was to examine the psychological, motivational, and contextual factors that influence enterprise employees' readiness to adopt artificial intelligence (AI) tools. The study extended the UTAUT2 framework by adding four AI-specific constructs (trust in AI, explainability, perceived ethical risk, and AI-related anxiety) to develop and validate the Artificial Intelligence Readiness Scale (AIRS).

**Research Questions**:

1. What psychological, motivational, and contextual factors influence individual readiness to adopt AI technologies within large enterprises?
2. To what extent do UTAUT2 constructs predict AI adoption readiness?

**Participant Recruitment**: Participants were recruited externally through Centiment, a professional survey research platform maintaining verified panels of adult participants across diverse industries, roles, and geographic regions. Centiment recruits panelists through social media platforms (Facebook, LinkedIn) and other outlets to achieve broad demographic representation. Critically, Centiment's recruitment methodology includes built-in self-selection bias mitigation: survey notifications to panel members display only the estimated completion time and reward amount, deliberately concealing the survey topic and subject matter "in order to avoid selection bias" (Centiment, 2024). This platform-level blinding ensured participants could not self-select based on AI interest. Target sample size was n ≈ 500 respondents.

**Risk Classification**: Exempt (minimal risk limited to potential discomfort reflecting on AI-related attitudes or privacy concerns).

### F.3 Informed Consent Statement

The following informed consent statement was presented to all participants prior to survey administration via the Centiment platform:

---

**Participation in a Research Study**

**Institutional Review Board – Touro University Worldwide**

**Enterprise AI Readiness Research**

You are invited to participate in a research study conducted by Fabio Correa, a doctoral candidate in the Doctor of Business Administration program at Touro University Worldwide. The purpose of this study is to understand how individual, psychological, and contextual factors influence employee readiness to adopt artificial intelligence (AI) tools in the enterprise workplace. This study explores constructs from the Unified Theory of Acceptance and Use of Technology (UTAUT2) and AI-specific enablers and inhibitors, including trust in AI, explainability, perceived ethical risk, and AI-related anxiety.

Your participation will involve completing an online survey that takes approximately 10–15 minutes. The survey includes questions about your experiences and perceptions of AI tools, such as Microsoft 365 Copilot, ChatGPT, and other AI applications. Participation is voluntary, and you may withdraw at any time without penalty or consequence.

**Risks and Discomforts**: The risks involved in this study are minimal. Some participants may experience minor discomfort when reflecting on their attitudes or experiences with AI, or concerns related to privacy or job impact. You may skip any question that makes you uncomfortable.

**Potential Benefits**: While there are no direct benefits to you, your participation will contribute to advancing understanding of how employees and organizations can prepare for AI adoption responsibly and effectively.

**Protection of Confidentiality**: All survey responses will be kept confidential. Data collection will occur through a secure online platform (Centiment) with no personally identifiable information collected. Results will be reported in aggregate form, and no individual responses will be identifiable.

**Voluntary Participation**: Your participation in this study is entirely voluntary. You may choose not to participate or may withdraw at any time without penalty or loss of benefits.

**Contact Information**: If you have questions about this study, contact Fabio Correa, Doctoral Candidate, Touro University Worldwide. If you have questions about your rights as a research participant, contact the Touro University Worldwide IRB at (818) 874-4115.

**Consent**: By clicking "Yes, I agree" below and completing the online survey, you confirm that you have read this consent form, are at least 18 years of age, and voluntarily agree to participate in this research study.

[ ] Yes, I agree to participate
[ ] No, I do not wish to participate

---

### F.4 Data Management and Privacy

**Data Collection Platform**: Centiment online survey panel

**Data Storage**: Survey responses were collected and stored on Centiment's secure servers, then exported to the researcher's encrypted institutional storage for analysis.

**Anonymity**: No personally identifiable information (names, email addresses, IP addresses) was collected or retained. Responses cannot be linked to individual participants.

**Data Retention**: De-identified data will be retained until January 2028 in accordance with federal regulations requiring researchers to keep data for a minimum of three years (45 CFR 46).

### F.5 Ethical Principles Certification

The researcher certified compliance with the Touro University Worldwide Ethical Principles & Guidelines for Research Involving Human Subjects, adapted from The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research (April 18, 1979), including:

1. **Informed Consent**: Subjects were given the opportunity to choose what shall or shall not happen to them
2. **Comprehension**: Information was conveyed clearly with adequate time for consideration
3. **Voluntariness**: Participation was free of coercion and undue influence
4. **Assessment of Risks and Benefits**: Systematic review confirmed minimal risk classification
5. **Justice**: Fair selection of subjects without favoritism or bias
6. **Social Justice**: Appropriate consideration of participant burden and class selection

\newpage

## Appendix G: Complete Survey Instrument as Administered

This appendix reproduces the complete AI Readiness Scale (AIRS) survey instrument exactly as administered to participants via the Centiment online panel in November 2024.

---

### Survey Introduction

**Welcome to the AI Readiness Survey**

Thank you for participating in this research study. This survey explores your experiences and perceptions regarding artificial intelligence (AI) tools in work and educational settings.

The survey takes approximately 10-15 minutes to complete. Please answer all questions honestly based on your current experiences. There are no right or wrong answers.

---

### Section 1: UTAUT2 Core Constructs

*Please indicate your level of agreement with each statement based on your current work or study experience.*

**Scale**: 1 = Strongly disagree | 2 = Disagree | 3 = Neutral | 4 = Agree | 5 = Strongly agree

#### Performance Expectancy

1. AI tools help me accomplish tasks more quickly.
2. Using AI improves the quality of my work or studies.

#### Effort Expectancy

3. Learning to use AI tools is easy for me.
4. Interacting with AI tools is clear and understandable.

#### Social Influence

5. People whose opinions I value encourage me to use AI tools.
6. Leaders in my organization or school support the use of AI tools.

#### Facilitating Conditions

7. I have access to training or tutorials for the AI tools I use.
8. The AI tools I use are compatible with other tools or systems I use.

#### Hedonic Motivation

9. Using AI tools is stimulating and engaging.
10. AI tools make my work or studies more interesting.

#### Price Value

11. I get more value from AI tools than the effort they require.
12. Using AI tools is worth the learning curve.

#### Habit

13. Using AI tools has become a habit for me.
14. I tend to rely on AI tools by default when I need help with tasks.

#### Voluntariness

15. I choose to use AI tools in my work because I find them helpful, not because I am required to.
16. I could choose not to use AI tools in my work or studies if I preferred.

---

### Section 2: AI-Specific Constructs

#### Trust in AI

17. I trust AI tools to provide reliable information.
18. I trust the AI tools that are available to me.

#### Explainability

19. I understand how the AI tools I use generate their outputs.
20. I prefer AI tools that explain their recommendations.

#### Perceived Ethical Risk

21. I worry that AI tools could replace jobs in my field.
22. I am concerned about privacy risks when using AI tools.

#### AI Anxiety

23. I feel uneasy about the increasing use of AI.
24. I worry that I may be left behind if I do not keep up with AI.

---

### Section 3: AI Adoption Readiness (Behavioral Intention)

25. I am ready to use more AI tools in my work or studies.
26. I would recommend AI tools to others.
27. I see AI as an important part of my future.
28. I plan to increase my use of AI tools in the next six months.

---

### Section 4: AI Tool Usage Frequency

*How often do you use each of the following AI tools?*

**Scale**: 1 = Never | 2 = Rarely | 3 = Sometimes | 4 = Often | 5 = Very often (Daily)

29. Microsoft 365 Copilot or Microsoft Copilot
30. ChatGPT
31. Google Gemini
32. Other AI tools (for example, Claude, Perplexity, Jasper)

---

### Section 5: Demographics

33. **What is your highest level of education completed?**
    - High school or less
    - Some college or vocational training
    - Bachelor's degree
    - Master's degree
    - Doctoral or professional degree

34. **What is your current status?**
    - Full-time student
    - Part-time student
    - Employed - individual contributor
    - Employed - manager
    - Employed - executive or leader
    - Freelancer or self-employed
    - Not currently employed
    - Other

35. **Which industry or field best describes your primary area of work or study?**
    - Technology or IT
    - Education
    - Healthcare
    - Finance or Banking
    - Manufacturing
    - Retail or Hospitality
    - Government or Public sector
    - Nonprofit
    - Other

36. **How many years of work or study experience do you have in your field?**
    - Less than 1 year
    - 1 to 3 years
    - 4 to 6 years
    - 7 to 10 years
    - 11 or more years

37. **Do you identify as a person with a disability (for example, vision, mobility, neurodivergence)?**
    - Yes
    - No
    - Prefer not to answer

---

### Section 6: Open Feedback (Optional)

38. **Do you have any other feedback about your experiences with AI tools?**

[Open text response field]

---

### Survey Completion

Thank you for completing this survey. Your responses will contribute to research on AI adoption in academic and professional settings.

If you have questions about this study, please contact the research team.

---

*Note: Items 15-16 (Voluntariness), 19-20 (Explainability), 21-22 (Perceived Ethical Risk), and 23-24 (AI Anxiety) were administered but subsequently removed from the final validated instrument due to insufficient reliability (α < .70) as documented in Chapter 4.*

\newpage

## Appendix H: Data Availability and Reproducibility

This appendix provides instructions for accessing the research data, analysis code, and thesis materials from the public GitHub repository.

### H.1 Repository Access

**GitHub Repository**: [https://github.com/fabioc-aloha/AIRS_Data_Analysis](https://github.com/fabioc-aloha/AIRS_Data_Analysis)

The complete research materials are publicly available under dual licensing:

- **Code**: MIT License (open source, free to use and modify)
- **Documentation**: CC BY 4.0 (attribution required)

To access the repository:

1. Visit the URL above in any web browser
2. Click "Code" -> "Download ZIP" for a complete download, or
3. Clone using Git: `git clone https://github.com/fabioc-aloha/AIRS_Data_Analysis.git`

### H.2 Repository Structure

The repository contains the following key directories:

| Directory | Contents |
|-----------|----------|
| thesis/ | Complete dissertation chapters, tables, figures, and bibliography |
| airs_experiment/ | Jupyter notebooks for the 10-phase analysis pipeline |
| data/ | Cleaned survey data and variable documentation |
| docs/ | Data dictionary and methodology documentation |

### H.3 Data Files

**Primary Data File**: data/AIRS_clean.csv

This file contains the anonymized survey responses (N=523) with the following characteristics:

- All personally identifiable information has been removed
- Variables are labeled according to the Data Dictionary (`docs/DATA_DICTIONARY.md`)
- Missing values are coded consistently throughout

**Supporting Data Files**:

| File | Description |
|------|-------------|
| airs_28item_complete.json | Full 28-item instrument with metadata |
| AIRS-AI-Readiness-Scale-labels.csv | Variable labels and response options |

*Note: All data files are located in the data/ directory. Source: Compiled by Author*

### H.4 Analysis Notebooks

The analysis was conducted using Jupyter notebooks executed sequentially. Each notebook is self-contained with documentation.

**Notebook Execution Order**:

| Notebook | Purpose | Key Outputs |
|----------|---------|-------------|
| 00_Create_Split_Samples | Create development/holdout split | Sample files |
| 01_EFA_Experiment | Exploratory Factor Analysis | Factor structure |
| 02_CFA_Experiment | Confirmatory Factor Analysis | Model fit indices |
| 03_Measurement_Invariance | Cross-group validation | Invariance tests |
| 04_Structural_Model | Hypothesis testing (SEM) | Path coefficients |
| 05_Mediation_Analysis | Indirect effects | Bootstrap results |
| 06_Moderation_Analysis | Experience/population effects | Interaction terms |
| 07_Tool_Usage_Patterns | Behavioral validation | Usage correlations |
| 08_Qualitative_Feedback | Open-ended analysis | Theme frequencies |
| 09_Comprehensive_Review | Cluster analysis | User typology |
| 10_Final_Synthesis | Integration | Summary statistics |

*Note: All notebooks have `.ipynb` extension. Source: Compiled by Author*

### H.5 Quick Start Guide

**Prerequisites**:

- Python 3.9 or higher
- Jupyter Notebook or JupyterLab
- Required packages listed in `requirements.txt`

**Installation**:

```bash
# Clone the repository
git clone https://github.com/fabioc-aloha/AIRS_Data_Analysis.git
cd AIRS_Data_Analysis

# Create virtual environment (recommended)
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt
```

**Running the Analysis**:

```bash
# Navigate to experiment folder
cd airs_experiment

# Launch Jupyter
jupyter notebook
```

Open notebooks in numerical order (00 -> 01 -> 02 -> ... -> 10) to reproduce the complete analysis pipeline.

### H.6 Key Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| pandas | ≥1.5.0 | Data manipulation |
| numpy | ≥1.23.0 | Numerical computing |
| scipy | ≥1.9.0 | Statistical functions |
| factor_analyzer | ≥0.4.0 | EFA/CFA implementation |
| semopy | ≥2.3.0 | Structural Equation Modeling |
| pingouin | ≥0.5.0 | Statistical testing |
| matplotlib | ≥3.6.0 | Visualization |
| seaborn | ≥0.12.0 | Statistical graphics |

*Source: Compiled by Author*

### H.7 Thesis PDF Generation

The dissertation PDF can be regenerated from source files:

```bash
cd thesis
.\build-thesis.ps1  # Windows PowerShell
```

Requirements: Pandoc, XeLaTeX (via MiKTeX or TeX Live), Mermaid CLI (optional for diagrams)

### H.8 Citation

When using this data or code in academic work, please cite:

```bibtex
@phdthesis{correa2025airs,
  author = {Correa, Fabio},
  title = {Artificial Intelligence Readiness Scale: Extending UTAUT2
           for Enterprise AI Adoption},
  school = {Touro University Worldwide},
  year = {2025},
  type = {Doctoral dissertation},
  url = {https://github.com/fabioc-aloha/AIRS_Data_Analysis}
}
```

### H.9 Data Retention Policy

In accordance with federal regulations (45 CFR 46) and institutional policy:

| Aspect | Policy |
|--------|--------|
| Retention Period | Minimum 3 years from study completion |
| Retention End Date | January 2028 |
| Data Format | De-identified, anonymized CSV |
| Storage Location | Encrypted institutional storage + GitHub (public) |
| Post-Retention | Data may be retained indefinitely for research purposes |

**Privacy Protections**:

- No personally identifiable information (PII) was collected
- No IP addresses, names, or email addresses retained
- Responses cannot be linked to individual participants
- All demographic variables are categorical (no birthdates, specific locations)

**Public Repository Note**: The GitHub repository contains only de-identified data that poses no privacy risk. The public availability supports research transparency and reproducibility while maintaining participant anonymity.

### H.10 Contact and Support

For questions about the data, methodology, or reproducing the analysis:

- **Repository Issues**: Use GitHub Issues for technical questions
- **Research Inquiries**: Contact the author through the repository

All materials are provided as-is for research and educational purposes.

\newpage

## Appendix I: Research Questions and Hypotheses Summary

**Note**: The content from this appendix has been incorporated into the main body of the dissertation. See Chapter 4 (§4.2 Research Questions and Hypotheses Overview, §4.6 Findings by Research Question, §4.7 Summary of Findings) and Chapter 5 (§5.4 Implications for Theory, §5.6 Unexpected Findings) for the integrated presentation of research questions, hypotheses, and their outcomes.

The following summary is retained for quick reference.

### I.1 Research Questions Summary

#### Primary Research Question

**RQ: How can UTAUT2 be extended with AI-specific constructs to better predict behavioral intention to adopt AI tools in professional and academic contexts?**

| Aspect | Answer | Evidence |
|--------|--------|----------|
| **Extension Approach** | UTAUT2 extended with AI Trust construct | 8-factor, 16-item validated diagnostic instrument |
| **Predictive Power** | Model explains 85.2% variance in BI | R² = .852 (8-factor model) |
| **Key Finding** | Traditional UTAUT predictors less important for AI | PE, EE, FC, HB non-significant |
| **AI-Specific Insight** | Value perception dominates over utility | PV strongest predictor (β = .505) |

#### Secondary Research Questions

| RQ# | Question | Answer | Supporting Evidence |
|-----|----------|--------|---------------------|
| **RQ1** | What is the factor structure of an AI-specific adoption readiness instrument? | 8-factor structure with 16 items | CFI = .975, TLI = .960, RMSEA = .065; all α > .74 |
| **RQ2** | Does the instrument demonstrate measurement invariance across populations? | Configural invariance achieved; metric invariance partial | ΔCFI = .003, ΔRMSEA = .004; mean Δλ = .082 |
| **RQ3** | Which factors most strongly predict behavioral intention? | Price Value (β = .505), Hedonic Motivation (β = .217), Social Influence (β = .136) | All p < .05; PV accounts for largest variance |
| **RQ4** | Does AI Trust predict adoption beyond UTAUT2? | Marginal effect, not statistically significant | β = .106, p = .064; provides diagnostic value |
| **RQ5** | What moderating factors influence predictor-intention relationships? | Experience moderates HM->BI; Population moderates HM->BI | HM×Exp p = .009; Academic vs Professional Δβ = .750 |

### I.2 Core UTAUT2 Hypotheses (H1a–H1g)

| Hypothesis | Path | Prediction | β | p | 95% CI | Result |
|------------|------|------------|---|---|--------|--------|
| **H1a** | PE -> BI | Positive | -.028 | .791 | [-.234, .178] | **[X] Not Supported** |
| **H1b** | EE -> BI | Positive | -.008 | .875 | [-.108, .092] | **[X] Not Supported** |
| **H1c** | SI -> BI | Positive | **.136** | **.024** | [.018, .254] | **[OK] Supported** |
| **H1d** | FC -> BI | Positive | .059 | .338 | [-.062, .180] | **[X] Not Supported** |
| **H1e** | HM -> BI | Positive | **.217** | **.014** | [.044, .390] | **[OK] Supported** |
| **H1f** | PV -> BI | Positive | **.505** | **<.001** | [.352, .658] | **[OK] Supported (Strongest)** |
| **H1g** | HB -> BI | Positive | .023 | .631 | [-.071, .117] | **[X] Not Supported** |

**Summary**: 3 of 7 UTAUT2 hypotheses supported. Price Value emerged as dominant predictor, departing from traditional UTAUT findings where Performance Expectancy typically dominates.

### I.3 AI Extension Hypothesis (H2)

| Hypothesis | Path | Prediction | β | p | 95% CI | Result |
|------------|------|------------|---|---|--------|--------|
| **H2** | TR -> BI | Positive | .106 | .064 | [-.006, .218] | **[X] Marginal (Not Significant)** |

**Interpretation**: AI Trust approached but did not reach conventional significance (p = .064). However, the 8-factor model including AI Trust was retained as the recommended diagnostic instrument because:

1. Trust provides essential diagnostic capability for organizational assessment
2. Organizations can identify trust deficits and design targeted interventions
3. The marginal effect suggests theoretical relevance warranting further investigation with larger samples

### I.4 Moderation Hypotheses (H3–H4)

#### H3: Experience Moderation

| Interaction | Path Moderated | Interaction β | p | Result |
|-------------|----------------|---------------|---|--------|
| PE × Experience | PE -> BI | 0.112 | .055 | [!] Marginal |
| **HM × Experience** | **HM -> BI** | **0.136** | **.009** | **[OK] Significant** |
| EE × Experience | EE -> BI | 0.122 | .161 | [X] Not Significant |
| TR × Experience | TR -> BI | 0.081 | .145 | [X] Not Significant |

**H3 Result: [!] Partially Supported** – Experience significantly moderates the HM -> BI path (p = .009). Professionals with 4+ years of experience weight hedonic motivation more heavily in AI adoption decisions.

#### H4: Population Moderation

| Path | Academic β | Professional β | Δβ | p | Result |
|------|------------|----------------|-----|---|--------|
| PE -> BI | -0.184 | 0.084 | 0.268 | .312 | No moderation |
| EE -> BI | 0.073 | -0.055 | -0.128 | .567 | No moderation |
| SI -> BI | 0.007 | 0.239 | 0.232 | .284 | No moderation |
| FC -> BI | -0.016 | 0.141 | 0.156 | .423 | No moderation |
| **HM -> BI** | **0.449** | **-0.301** | **-0.750** | **.041** | **[OK] Significant** |
| PV -> BI | 0.638 | 0.808 | 0.170 | .489 | No moderation |
| HB -> BI | 0.075 | -0.064 | -0.140 | .512 | No moderation |
| TR -> BI | -0.011 | 0.153 | 0.164 | .398 | No moderation |

**H4 Result: [!] Partially Supported** – Population significantly moderates HM -> BI (p = .041). Hedonic Motivation is substantially stronger for Academics (β = 0.449) than Professionals (β = -0.301), indicating that enjoyment of AI tools is more important for student adoption than professional adoption.

### I.5 Behavioral Validation Hypotheses (H5–H6)

| Hypothesis | Test | Statistic | p | Effect Size | Result |
|------------|------|-----------|---|-------------|--------|
| **H5** | BI × Tool Usage | ρ = .69 | <.001 | Large | **[OK] Supported** |
| **H6** | Role Usage Differences | F(2,520) = 22.15 | <.001 | η² = .078 | **[OK] Supported** |

**H5 Detail**: Behavioral Intention strongly correlates with actual AI tool usage:

| Tool | ρ with BI | p | Interpretation |
|------|-----------|---|----------------|
| Total Usage Index | .69 | <.001 | Strong positive |
| ChatGPT | .57 | <.001 | Strong positive |
| Microsoft Copilot | .54 | <.001 | Moderate positive |
| Google Gemini | .52 | <.001 | Moderate positive |

**H6 Detail**: Significant role differences in tool usage (Leaders > Professionals > Academics):

| Measure | F | p | Post-hoc Pattern |
|---------|---|---|------------------|
| Tool Breadth | 18.42 | <.001 | L > P > A |
| Usage Frequency | 22.15 | <.001 | L > P > A |
| Usage Intensity | 15.87 | <.001 | L > P > A |

### I.6 Comprehensive Hypothesis Outcome Summary

| Category | Hypotheses | Supported | Partial | Not Supported |
|----------|------------|-----------|---------|---------------|
| **UTAUT2 Core (H1a-g)** | 7 | 3 (43%) | 0 | 4 (57%) |
| **AI Extension (H2)** | 1 | 0 | 1 (marginal) | 0 |
| **Moderation (H3-H4)** | 2 | 0 | 2 (100%) | 0 |
| **Behavioral (H5-H6)** | 2 | 2 (100%) | 0 | 0 |
| **TOTAL** | **12** | **5 (42%)** | **3 (25%)** | **4 (33%)** |

### I.7 Constructs Not Testable

Four initially proposed AI-specific constructs demonstrated inadequate reliability during psychometric validation and could not be formally tested:

| Construct | Cronbach's α | Status | Recommendation |
|-----------|--------------|--------|----------------|
| Voluntariness (VO) | .406 | Excluded | Revise operationalization |
| Explainability (EX) | .582 | Excluded | Develop AI-specific items |
| Ethical Risk (ER) | .546 | Excluded | Context-specific measurement |
| AI Anxiety (AX) | .301 | Excluded | Validated anxiety scale adaptation |

These constructs remain theoretically important for AI adoption and warrant revised measurement approaches in future research.

### I.8 Key Theoretical Implications

1. **Price Value Dominance**: The finding that PV (β = .505) rather than PE drives AI adoption represents a significant theoretical departure from traditional UTAUT research, suggesting AI tools are evaluated through a value lens ("Is it worth it?") rather than a utility lens ("Will it help me?").

2. **Non-Significance of Traditional Predictors**: PE, EE, FC, and HB were not significant, suggesting AI may represent a distinct technology category requiring tailored theoretical frameworks.

3. **Experience-Dependent Mechanisms**: The experience moderation of HM suggests that adoption mechanisms differ by user characteristics in ways not previously documented in technology acceptance research.

4. **Population-Specific Pathways**: Differential HM effects across populations indicate that adoption interventions may need to be tailored to specific user groups.
