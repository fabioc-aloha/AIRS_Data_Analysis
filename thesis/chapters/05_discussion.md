# Chapter 5: Discussion and Conclusions

## 5.1 Introduction

This chapter discusses the implications of the AIRS validation study findings, addresses limitations, and provides recommendations for future research and practice.

## 5.2 Summary of Key Findings

### 5.2.1 AIRS Instrument Validation

The study successfully validated an 8-factor, 16-item AI Readiness Scale extending UTAUT2 with AI Trust.

### 5.2.2 Supported Relationships

Three of seven hypothesized UTAUT2 paths were significant:

- **Price Value** (β = .505, p < .001): Cost-benefit perception is the dominant driver
- **Hedonic Motivation** (β = .217, p = .014): Enjoyment significantly predicts adoption
- **Social Influence** (β = .136, p = .024): Peer influence matters for AI adoption

### 5.2.3 AI Trust Extension

AI Trust approached but did not reach significance (β = .106, p = .064), providing tentative support for the theoretical extension. Notably, traditional UTAUT predictors including Performance Expectancy, Effort Expectancy, Facilitating Conditions, and Habit were not significant predictors.

## 5.3 Discussion of Findings

### 5.3.1 Price Value as Dominant Predictor

**Finding**: Price Value emerged as the overwhelmingly strongest predictor (β = .505, p < .001), substantially exceeding all other constructs.

**Interpretation**: This finding represents a significant departure from traditional UTAUT research where Performance Expectancy typically dominates. In the AI context, users appear primarily motivated by **perceived value relative to cost** rather than raw productivity benefits (PE, ns), ease of use (EE, ns), organizational support (FC, ns), or habit (HB, ns). This suggests that AI adoption interventions should prioritize demonstrating clear return on investment and cost-effectiveness rather than focusing solely on capability demonstrations.

**Theoretical Implications**: The dominance of Price Value over Performance Expectancy suggests AI tools may represent a distinct technology category. Unlike previous technologies where utility perceptions drove adoption, AI adoption appears more influenced by value propositions—potentially reflecting the freemium pricing models common in AI tools, concerns about ongoing subscription costs, or cost-benefit analyses comparing AI tools to traditional methods.

### 5.3.2 Non-Significant UTAUT2 Paths

**Finding**: PE, EE, FC, and HB were not significant predictors.

**Interpretation**: The non-significance of Performance Expectancy (β = -.028, p = .791) is particularly noteworthy, as PE typically dominates technology acceptance research. This suggests that in the AI context, perceived usefulness may be a baseline expectation rather than a differentiating factor. Users may assume AI tools will enhance productivity, making cost-benefit considerations (Price Value) and enjoyment (Hedonic Motivation) the deciding factors.

Similarly, the non-significance of Effort Expectancy (β = -.008, p = .875) and Facilitating Conditions (β = .059, p = .338) may reflect the increasingly user-friendly nature of modern AI tools and widespread organizational technology infrastructure.

### 5.3.3 AI Trust Marginality

**Finding**: TR approached but did not reach significance (β = .106, p = .064).

**Interpretation**: The marginal significance of AI Trust suggests it may become a more important predictor as AI technologies mature and trust concerns become more salient. The current sample may have insufficient power to detect the effect, or trust considerations may be less central for the relatively straightforward AI tools currently in use. Future research should examine whether AI Trust becomes more predictive for high-stakes AI applications (e.g., AI-assisted decision-making, autonomous systems).

### 5.3.4 Experience as Moderator

**Finding**: Professional experience strengthens HM → BI (β = .136, p = .007).

**Interpretation**: The significant moderation effect suggests that experienced professionals place greater weight on enjoyment when evaluating AI tools. This may reflect that experienced users, having satisfied basic competency needs, prioritize intrinsic satisfaction. Additionally, usage frequency moderates the importance of Performance Expectancy (for new users) versus Price Value (for heavy users).

### 5.3.5 User Typology Segments

**Finding**: Four distinct user segments identified.

**Implications for Practice**:

- AI Enthusiasts (16%): Leverage as champions
- Cautious Adopters (30%): Address concerns while maintaining engagement
- Moderate Users (37%): Benefit-focused messaging
- Anxious Avoiders (17%): Targeted anxiety-reduction interventions

### 5.3.6 Disability and Accessibility

**Finding**: Disability associated with higher AI anxiety (d = .36).

**Implications**:
[To be written - inclusive AI design]

## 5.4 Theoretical Contributions

1. **UTAUT2 Extension**: Validated AI Trust as potential extension
2. **Context-Specific Model**: Identified AI-specific adoption drivers
3. **Career Development Integration**: Experience as novel moderator
4. **User Typology Framework**: Practical segmentation approach

## 5.5 Practical Implications

### 5.5.1 For Organizations

[To be written]

### 5.5.2 For AI Tool Designers

[To be written]

### 5.5.3 For Trainers and Educators

[To be written]

### 5.5.4 For Policy Makers

[To be written]

## 5.6 Limitations

### 5.6.1 Methodological Limitations

1. **Cross-sectional design**: The single time-point data collection precludes causal inference. While SEM estimates suggest directional relationships, alternative causal orderings (e.g., behavior → intention) cannot be ruled out.

2. **Self-reported intention**: Behavioral Intention may not perfectly predict actual behavior. However, the strong BI-Usage correlation (ρ = .70) provides behavioral validation.

3. **Convenience sampling**: The United States sample limits generalizability to other countries, cultures, and organizational contexts.

### 5.6.2 Measurement Limitations

1. **Dropped constructs**: Four proposed AI-specific constructs (Voluntariness, Explainability, Ethical Risk, original Anxiety items) demonstrated inadequate reliability (α = .30–.58) and were excluded. This finding reveals that **two-item scales proved insufficient for these multi-dimensional constructs**:
   - **Voluntariness** (α = .41): Choice vs. freedom dimensions
   - **Explainability** (α = .58): Understanding vs. preference dimensions
   - **Ethical Risk** (α = .55): Job displacement vs. privacy concern dimensions
   - **Original Anxiety** (α = .30): Avoidance vs. approach motivation dimensions

   **Implication**: These constructs remain theoretically important for AI adoption but require more comprehensive operationalization. Future scale development should include 3-4 items per dimension, potentially yielding multi-factor sub-scales (e.g., "Ethical Risk" with separate job-threat and privacy-concern subscales).

   **Note**: This represents an empirical finding, not a design failure. The proposal committed to testing these constructs; the data revealed measurement limitations. Transparent reporting of psychometric issues aligns with best practices in scale development.

2. **Marginal AI Trust**: Trust approached but did not reach significance (p = .064). This may reflect inadequate statistical power (β = .106 requires n > 600 for 80% power at α = .05) or genuine marginality of trust in AI adoption decisions.

3. **Western sample**: Cultural generalizability is unknown. AI adoption attitudes may differ substantially in collectivist cultures or regions with different AI policy environments.

## 5.7 Future Research Directions

### 5.7.1 Immediate Priorities

1. **Replicate with larger sample**: Achieve n > 600 to provide adequate power (80%) for detecting the Trust effect (β ≈ .10) at α = .05.

2. **Redesign dropped construct scales**: The four excluded constructs (Voluntariness, Explainability, Ethical Risk, Anxiety sub-dimensions) require comprehensive item development:
   - Develop 3-4 items per dimension (e.g., 4 items for job-threat ethical risk + 4 items for privacy ethical risk)
   - Use cognitive interviewing to ensure items capture intended constructs
   - Pilot test reliability before main data collection
   - Consider formative vs. reflective measurement models for inherently multi-faceted constructs

3. **Test untested mediation hypotheses**: The original proposal hypothesized mediation paths through Explainability, Ethical Risk, and Anxiety (H5a-c). These paths could not be tested because EX and ER were dropped. Future research with improved measures should examine:
   - H5a: TR → EX → BI (Trust operating through Explainability)
   - H5b: AX ↔ ER → BI (Anxiety-Risk interaction effects)
   - H5c: FC → EX → BI (Organizational support enabling explainability)

4. **Longitudinal intention-behavior study**: Track actual AI adoption behavior over 6-12 months following intention measurement to validate the BI → Behavior pathway.

### 5.7.2 Extended Research Agenda

1. Cross-cultural validation
2. Industry-specific applications
3. Intervention studies based on user typology
4. Accessibility-focused AI anxiety research

## 5.8 Conclusions

[To be written - synthesize contributions and call to action]
