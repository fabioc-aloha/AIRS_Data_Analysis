# Chapter 5: Discussion and Conclusions

## 5.1 Introduction

This chapter discusses the implications of the AIRS validation study findings, addresses limitations, and provides recommendations for future research and practice.

## 5.2 Summary of Key Findings

### 5.2.1 AIRS Instrument Validation

The study successfully validated an 8-factor, 16-item AI Readiness Scale extending UTAUT2 with AI Trust.

### 5.2.2 Supported Relationships

Four of seven hypothesized paths were significant:

- **Performance Expectancy** (β = .505, p < .001): Perceived usefulness is the dominant driver
- **Hedonic Motivation** (β = .217, p < .001): Enjoyment strongly predicts adoption
- **AI Anxiety** (β = -.152, p = .002): Apprehension significantly inhibits adoption
- **Social Influence** (β = .136, p = .013): Peer influence matters for AI adoption

### 5.2.3 AI Trust Extension

AI Trust approached but did not reach significance (β = .106, p = .064), providing tentative support for the theoretical extension. The significant Anxiety path (β = -.152) demonstrates that AI-specific affective factors do predict adoption beyond core UTAUT2 constructs.

## 5.3 Discussion of Findings

### 5.3.1 Performance Expectancy as Dominant Predictor

**Finding**: PE emerged as the overwhelmingly strongest predictor (β = .505, p < .001), substantially exceeding all other constructs.

**Interpretation**: This finding aligns with UTAUT theory but highlights a critical insight for AI adoption: **perceived usefulness trumps all other considerations**. In the AI context, users are primarily motivated by tangible productivity and quality improvements rather than ease of use (EE, ns), organizational support (FC, ns), or even trust (TR, marginal). This suggests that AI adoption interventions should prioritize demonstrating concrete value propositions over training or infrastructure investments.

**Theoretical Implications**: The dominance of PE supports Venkatesh et al.'s (2003) original positioning of Performance Expectancy as the primary adoption driver. However, the magnitude (β = .505) exceeds typical UTAUT findings, suggesting AI tools may represent a particularly utility-focused technology category where hedonic and social considerations, while significant, remain secondary.

### 5.3.2 Non-Significant UTAUT2 Paths

**Finding**: PE, EE, FC, and HB were not significant predictors.

**Interpretation**:
[To be written - discuss AI tool landscape where ease of use is assumed]

### 5.3.3 AI Trust Marginality

**Finding**: TR approached but did not reach significance (p = .064).

**Interpretation**:
[To be written - discuss power considerations, trust as emerging construct]

### 5.3.4 Experience as Novel Moderator

**Finding**: Professional experience strengthens PE→BI and HM→BI.

**Interpretation**:
[To be written - career development literature integration]

### 5.3.5 User Typology Segments

**Finding**: Four distinct user segments identified.

**Implications for Practice**:

- AI Enthusiasts (16%): Leverage as champions
- Cautious Adopters (30%): Address concerns while maintaining engagement
- Moderate Users (37%): Benefit-focused messaging
- Anxious Avoiders (17%): Targeted anxiety-reduction interventions

### 5.3.6 Disability and Accessibility

**Finding**: Disability associated with higher AI anxiety (d = .36).

**Implications**:
[To be written - inclusive AI design]

## 5.4 Theoretical Contributions

1. **UTAUT2 Extension**: Validated AI Trust as potential extension
2. **Context-Specific Model**: Identified AI-specific adoption drivers
3. **Career Development Integration**: Experience as novel moderator
4. **User Typology Framework**: Practical segmentation approach

## 5.5 Practical Implications

### 5.5.1 For Organizations

[To be written]

### 5.5.2 For AI Tool Designers

[To be written]

### 5.5.3 For Trainers and Educators

[To be written]

### 5.5.4 For Policy Makers

[To be written]

## 5.6 Limitations

### 5.6.1 Methodological Limitations

1. **Cross-sectional design**: The single time-point data collection precludes causal inference. While SEM estimates suggest directional relationships, alternative causal orderings (e.g., behavior → intention) cannot be ruled out.

2. **Self-reported intention**: Behavioral Intention may not perfectly predict actual behavior. However, the strong BI-Usage correlation (ρ = .70) provides behavioral validation.

3. **Convenience sampling**: The UK higher education sample limits generalizability to other sectors, cultures, and educational contexts.

### 5.6.2 Measurement Limitations

1. **Dropped constructs**: Four proposed AI-specific constructs (Voluntariness, Explainability, Ethical Risk, original Anxiety items) demonstrated inadequate reliability (α = .30–.58) and were excluded. This finding reveals that **two-item scales proved insufficient for these multi-dimensional constructs**:
   - **Voluntariness** (α = .41): Choice vs. freedom dimensions
   - **Explainability** (α = .58): Understanding vs. preference dimensions
   - **Ethical Risk** (α = .55): Job displacement vs. privacy concern dimensions
   - **Original Anxiety** (α = .30): Avoidance vs. approach motivation dimensions

   **Implication**: These constructs remain theoretically important for AI adoption but require more comprehensive operationalization. Future scale development should include 3-4 items per dimension, potentially yielding multi-factor sub-scales (e.g., "Ethical Risk" with separate job-threat and privacy-concern subscales).

   **Note**: This represents an empirical finding, not a design failure. The proposal committed to testing these constructs; the data revealed measurement limitations. Transparent reporting of psychometric issues aligns with best practices in scale development.

2. **Marginal AI Trust**: Trust approached but did not reach significance (p = .064). This may reflect inadequate statistical power (β = .106 requires n > 600 for 80% power at α = .05) or genuine marginality of trust in AI adoption decisions.

3. **Western sample**: Cultural generalizability is unknown. AI adoption attitudes may differ substantially in collectivist cultures or regions with different AI policy environments.

## 5.7 Future Research Directions

### 5.7.1 Immediate Priorities

1. **Replicate with larger sample**: Achieve n > 600 to provide adequate power (80%) for detecting the Trust effect (β ≈ .10) at α = .05.

2. **Redesign dropped construct scales**: The four excluded constructs (Voluntariness, Explainability, Ethical Risk, Anxiety sub-dimensions) require comprehensive item development:
   - Develop 3-4 items per dimension (e.g., 4 items for job-threat ethical risk + 4 items for privacy ethical risk)
   - Use cognitive interviewing to ensure items capture intended constructs
   - Pilot test reliability before main data collection
   - Consider formative vs. reflective measurement models for inherently multi-faceted constructs

3. **Test untested mediation hypotheses**: The original proposal hypothesized mediation paths through Explainability, Ethical Risk, and Anxiety (H5a-c). These paths could not be tested because EX and ER were dropped. Future research with improved measures should examine:
   - H5a: TR → EX → BI (Trust operating through Explainability)
   - H5b: AX ↔ ER → BI (Anxiety-Risk interaction effects)
   - H5c: FC → EX → BI (Organizational support enabling explainability)

4. **Longitudinal intention-behavior study**: Track actual AI adoption behavior over 6-12 months following intention measurement to validate the BI → Behavior pathway.

### 5.7.2 Extended Research Agenda

1. Cross-cultural validation
2. Industry-specific applications
3. Intervention studies based on user typology
4. Accessibility-focused AI anxiety research

## 5.8 Conclusions

[To be written - synthesize contributions and call to action]

---

<!-- Chapter 5 Draft Status: Outline Complete -->
