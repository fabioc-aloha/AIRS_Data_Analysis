---
title: "Artificial Intelligence Readiness Scale: Extending UTAUT2 for Enterprise AI Adoption"
author: "Fabio Correa"
institution: "Touro University Worldwide"
program: "DBA712 - Doctoral Research Project"
chair: "Dr. Karina Kasztelnik"
committee1: "Dr. Jerome Jones"
committee2: "Dr. Donna Day"
date: "December 2025"
running-header: "AI READINESS SCALE"
---

\begin{center}

\vspace*{1in}

{\LARGE \textbf{Artificial Intelligence Readiness Scale:}}

{\LARGE \textbf{Extending UTAUT2 for Enterprise AI Adoption}}

\vspace{1.5in}

A Dissertation

Presented to the Faculty of

Touro University Worldwide

\vspace{0.5in}

In Partial Fulfillment

of the Requirements for the Degree

Doctor of Business Administration

\vspace{1in}

by

Fabio Correa

December 2025

\end{center}

\newpage

## Dissertation Approval

This dissertation, written by Fabio Correa under the guidance of the Dissertation Committee and approved by all its members, has been accepted in partial fulfillment of the requirements for the degree of Doctor of Business Administration.

\vspace{0.5in}

**Dissertation Committee:**

\vspace{0.3in}

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Dr. Karina Kasztelnik, Committee Chair \hfill Date

\vspace{0.3in}

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Dr. Jerome Jones, Committee Member \hfill Date

\vspace{0.3in}

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Dr. Donna Day, Committee Member \hfill Date

\newpage

## Copyright Notice

© 2025 Fabio Correa

All Rights Reserved

\newpage

## Abstract

This dissertation develops and validates the AI Readiness Scale (AIRS), an instrument designed to measure artificial intelligence adoption readiness in professional and academic contexts. Extending the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) with AI-specific constructs, this study examines factors influencing behavioral intention to adopt AI tools among students and employed professionals.

Using a sample of 523 United States participants, exploratory and confirmatory factor analyses validated an 8-factor, 16-item model demonstrating excellent fit (CFI = .975, TLI = .960, RMSEA = .065). The structural model revealed Price Value (β = .505, p < .001), Hedonic Motivation (β = .217, p = .014), and Social Influence (β = .136, p = .024) as significant predictors of behavioral intention, while AI Trust approached but did not reach significance (β = .106, p = .064). The model explained 85.7% of variance in behavioral intention.

Four theoretically-proposed constructs (Voluntariness, Explainability, Ethical Risk, AI Anxiety) were excluded due to inadequate reliability (α = .30–.58), revealing measurement challenges with two-item scales for multi-dimensional AI constructs. Notably, traditional UTAUT predictors including Performance Expectancy, Effort Expectancy, Facilitating Conditions, and Habit did not significantly predict AI adoption intention, suggesting AI tools may represent a distinct technology category where cost-benefit perceptions and enjoyment outweigh conventional utility considerations.

Measurement invariance testing across student (n = 216) and professional (n = 307) populations demonstrated configural invariance, supporting the instrument's applicability across workforce contexts. Cluster analysis identified four distinct user segments—AI Enthusiasts (16%), Cautious Adopters (30%), Moderate Users (37%), and Anxious Avoiders (17%)—providing a framework for understanding adoption heterogeneity.

The study contributes a psychometrically validated instrument for AI adoption research and establishes a foundation for future organizational applications. Findings suggest that demonstrating value relative to cost (Price Value) and fostering positive engagement experiences (Hedonic Motivation) may represent promising directions for future intervention research in AI adoption contexts.

**Keywords:** artificial intelligence, technology adoption, UTAUT2, scale development, psychometric validation, structural equation modeling, measurement invariance, AI readiness

\newpage

## Acknowledgments

I extend my deepest gratitude to the individuals who made this dissertation possible.

To my dissertation chair, Dr. Karina Kasztelnik, thank you for your guidance, patience, and scholarly wisdom throughout this journey. Your expertise in research methodology and commitment to academic excellence shaped both this work and my development as a researcher.

To my committee members, Dr. Jerome Jones and Dr. Donna Day, thank you for your thoughtful feedback, challenging questions, and unwavering support. Your diverse perspectives strengthened this research in countless ways.

To my family, thank you for your understanding during the countless hours devoted to this project. Your encouragement sustained me through the challenges of doctoral study.

To my professional colleagues and the participants who generously shared their experiences with AI tools, thank you for making this research possible. Your insights illuminate the path forward for organizations navigating the AI transformation.

Finally, I acknowledge the broader academic community whose foundational work—particularly Venkatesh and colleagues' development of UTAUT—provided the theoretical architecture upon which this research builds. Scholarship advances through cumulative contribution, and I am honored to add to this conversation.

\newpage

## Table of Contents

**Front Matter**

- Abstract
- Acknowledgments
- Table of Contents
- List of Tables
- List of Figures

**Chapter 1: Introduction** \dotfill 1

- 1.1 Background and Context
- 1.2 Statement of the Problem
- 1.3 Purpose of the Study
- 1.4 Research Questions and Hypotheses
- 1.5 Theoretical and Practical Significance
- 1.6 Scope and Delimitations
- 1.7 Definition of Key Terms
- 1.8 Summary and Dissertation Structure

**Chapter 2: Literature Review** \dotfill 15

- 2.1 Introduction
- 2.2 Technology Acceptance Models: Foundations and Evolution
- 2.3 The AI Adoption-Value Gap: Industry Context
- 2.4 Why AI Stresses Traditional Acceptance Models
- 2.5 Trust in AI Systems
- 2.6 AI Anxiety
- 2.7 Literature Synthesis and Research Gaps
- 2.8 Theoretical Framework and Hypotheses
- 2.9 Chapter Summary

**Chapter 3: Research Methodology** \dotfill 45

- 3.1 Introduction
- 3.2 Research Design and Paradigm
- 3.3 Quantitative Methodology
- 3.4 Ten-Phase Analysis Pipeline
- 3.5 Ethical Considerations
- 3.6 Summary

**Chapter 4: Findings** \dotfill 75

- 4.1 Introduction
- 4.2 Description of the Sample
- 4.3 Data Screening and Preparation
- 4.4 Quantitative Findings
- 4.5 Findings by Research Question
- 4.6 Summary

**Chapter 5: Analysis and Discussion** \dotfill 110

- 5.1 Introduction
- 5.2 Review of Key Findings
- 5.3 Discussion of Key Findings
- 5.4 Theoretical Implications
- 5.5 Implications for Practice
- 5.6 Limitations
- 5.7 Summary

**Chapter 6: Conclusions, Implications, and Recommendations** \dotfill 135

- 6.1 Summary of the Study
- 6.2 Key Findings
- 6.3 Contributions to Knowledge
- 6.4 Practical and Managerial Implications
- 6.5 Recommendations for Future Research
- 6.6 Limitations and Boundaries
- 6.7 Future Research Roadmap
- 6.8 Closing Remarks

**References** \dotfill 155

**Appendices** \dotfill 175

- Appendix A: AI Readiness Scale (AIRS) Final 16-Item Instrument
- Appendix B: Survey Materials
- Appendix C: Supplementary Statistical Tables
- Appendix D: Supplementary Figures
- Appendix Z: AIRS Research Roadmap and Future Applications

\newpage

## List of Tables

| Table | Title | Page |
|-------|-------|------|
| 3.1 | Sample Composition by Role Type | 48 |
| 3.2 | Survey Instrument Overview | 52 |
| 3.3 | Model Fit Index Thresholds | 65 |
| 4.1 | Exploratory Factor Analysis Model Comparison | 78 |
| 4.2 | Construct Exclusion Analysis | 80 |
| 4.3 | Final Factor Structure: Reliability and Validity | 82 |
| 4.4 | Confirmatory Factor Analysis Model Fit | 85 |
| 4.5 | Composite Reliability and Validity Indices | 88 |
| 4.6 | Measurement Invariance Testing | 92 |
| 4.7 | Structural Model Path Coefficients | 95 |
| 4.8 | Moderation Analysis Results | 98 |
| 4.9 | User Typology Segment Profiles | 102 |

\newpage

## List of Figures

| Figure | Title | Page |
|--------|-------|------|
| 2.1 | Evolution of Technology Acceptance Models | 22 |
| 2.2 | AIRS Conceptual Model: Extended UTAUT2 for AI Adoption | 38 |
| 2.3 | Research Hypotheses Summary | 42 |
| 3.1 | Split-Sample Cross-Validation Strategy | 55 |
| 3.2 | Structural Model: Eight Predictors of Behavioral Intention | 62 |
| 3.3 | Ten-Phase Analysis Pipeline | 68 |
| 4.1 | Scree Plot with Parallel Analysis | 79 |
| 4.2 | CFA Factor Loadings | 86 |
| 4.3 | Factor Correlation Matrix | 87 |
| 4.4 | Reliability Comparison Across Constructs | 89 |
| 4.5 | Measurement Invariance: Loading Comparison | 93 |
| 4.6 | Hypothesis Test Summary | 96 |
| 4.7 | Structural Equation Model Paths | 97 |
| 4.8 | Experience Moderation Effect | 99 |
| 5.1 | User Typology Framework | 118 |
| D.1 | Sample Preparation Overview | 178 |
| D.2 | AI Tool Usage Distribution | 179 |
| D.3 | Disability Status and AI Anxiety | 180 |

\newpage
