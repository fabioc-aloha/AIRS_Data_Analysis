
---
## Page 1
---

1 
 
Please cite this article as: 
Venkatesh, V. “Adoption and Use of AI Tools: A Research Agenda Grounded in UTAUT,” 
Annals of Operations Research, forthcoming. https://doi.org/10.1007/s10479-020-03918-9 
 
 
ADOPTION AND USE OF AI TOOLS:  
A RESEARCH AGENDA GROUNDED IN UTAUT 
 
 
Viswanath Venkatesh 
Pamplin College of Business 
Virginia Tech, Blacksburg 
VA 24061, USA 
vvenkatesh@vvenkatesh.us  
 
 
 


---
## Page 2
---

2 
 
ADOPTION AND USE OF AI TOOLS:  
 
A RESEARCH AGENDA GROUNDED IN UTAUT 
 
Abstract  
This paper is motivated by the widespread availability of AI tools, whose adoption and 
consequent benefits are still a question mark. As a first step, some critical issues that relate to AI 
tools in general, humans in the context of AI tools, and AI tools in the context of operations 
management are identified. A discussion of how these issues could hinder employee adoption 
and use of AI tools is presented. Building on this discussion, the unified theory of acceptance and 
use of technology (UTAUT) is used as a theoretical basis to propose individual characteristics, 
technology characteristics, environmental characteristics and interventions as viable research 
directions that could not only contribute to the adoption literature, particularly as it relates to AI 
tools, but also, if pursued, such research could help organizations positively influence the 
adoption of AI tools. 
Keywords: AI tools, UTAUT, employee adoption, technology use 
 
 


---
## Page 3
---

3 
 
1. Introduction 
Artificial intelligence (AI) saw its genesis in the mid-1950s. Despite its initial promise, it 
stuttered to what seemed like an end for a variety of reasons such as technology limitations, 
including data processing capability, handling different types of data, and approximating human 
thinking. The tremendous growth of technology has been a critical contributing factor to the 
resurgence of AI tools that remedy the limitations of the past. The growth of AI tools and its 
promise of benefits for organizations are unprecedented. Organizations are scrambling to invest 
in, deploy and leverage AI tools in various areas of organizational functioning to harvest its 
benefits, create competitive advantage, and enhance performance. 
 
The definition of AI tools and what they entail itself is continuing to evolve, especially 
with the integration with many new and modern technologies, such as Internet of Things, and 
data, such as big data (Y. Wang et al. 2019). There is a growing body of research on various 
aspects of AI tools, especially focused on design of AI tools ranging from requirements 
elicitation (Z. Wang et al. 2019) to technical aspects (Romanova et al. 2019) in a variety of 
settings such as supply chain (Priore et al. 2019), biomedicine (Kocheturov et al. 2019), and 
smart healthcare in clinical settings (Pan et al. 2019). Performance of such AI-based tools, 
especially in comparison to previous approaches and algorithms, is of interest (Razzaghi et al. 
2019), with a particular focus on avoiding biases that can creep into models, especially when 
learning comes from data that is riddled with bias (Lambrecht and Tucker 2019).  
Not unlike numerous technologies before AI that came with extraordinary promise, the 
ground reality tends to be far different. A major hurdle to garnering benefits is adoption and use 
of any technology. AI tools are and will continue to be no different. At the organizational level, 
amongst the problems hindering adoption are several usual suspects—such as the need for 


---
## Page 4
---

4 
 
infrastructure, the need for appropriate training, the lack of a business case, and inadequate skills 
to name but a few. Several articles have been written in the trade press that outline these 
problems.1 Although there may be unique elements that hinder the organizational adoption of AI 
tools, I argue that some of the problems are typical of any technology implementation. 
 
Turning to employee adoption of AI tools, which is a necessary step to organizational 
adoption and garnering of benefits, unlike in the case of organizational adoption, there are a 
number of unique aspects of AI tools that could play a critical role, especially in hindering 
employee adoption. Employee adoption of technology is a mature area of research, with many 
established theories that successfully predict the adoption and use of a broad range of 
technologies (see Venkatesh et al. 2016). The unified theory of acceptance and use of technology 
(UTAUT; Venkatesh et al. 2003) is among the most widely used theories that has successfully 
replicated numerous times and, in fact, used to study a variety of technologies and even contexts 
beyond employee adoption. Critically, contextual conditions and attributes unique to specific 
technologies are known to play a role in the ultimate adoption and use of those technologies (for 
examples, see Brown et al. 2010; Hong et al. 2014). Contextual issues that can influence 
employee adoption of AI are thus the focus of this work. AI tools, at least currently, as noted 
earlier, span a wide spectrum to provide decision making support and even decision making in a 
variety of contexts. The particular shift with AI tools is not only powered by the availability of 
enormous amount of data, but also by a shift from decision support to actual decision making. 
With AI tools, the human decision maker—i.e., employee—could thus be relegated to playing a 
secondary role or have no role to play. On the positive side, AI tools may indeed be able to 
process a lot of data, even in real-time, to arrive at inferences that can be the basis of good 
 
1 Two illustrative sources of organizational challenges are: https://petuum.com/2019/04/02/seven-challenges-of-
adopting-artificial-intelligence-solutions/ and https://neoteric.eu/blog/12-challenges-of-ai-adoption/ 


---
## Page 5
---

5 
 
decisions, thus freeing up employees for more strategic and/or abstract thinking. On the flip side, 
for instance, the widely publicized AI tool used by Amazon that led to biases against women job 
applicants—a tool that was used in screening applications (see Schuetz and Venkatesh 2020). 
Undoubtedly, this is but one example of an AI tool replacing a human being in making a decision 
of substantial significance. Taking the human intervention away from the decision-making 
process means organizations rely on AI tools to make decisions, the consequences of which may 
not be felt until later in the business process. Thus, a middle ground would seem that AI tools are 
used by employees in much the same way as decision support tools were in the past, albeit with a 
focus on more sophisticated problems and to support more complex decisions. This would give 
the employee the leeway to leverage the AI tools and its power to support decision making, as he 
or she should see fit. It is the adoption of AI tools in such a middle ground that is the focus of 
this paper.  
 
Moving beyond the general topic of AI tools, it is important to consider how the AI tool 
adoption will be unique in the case of tools built to support operations management (OM). One 
clear distinguishing feature of OM, compared to other business disciplines except perhaps 
information systems (IS), is that it necessarily spans across a large chain of business functioning 
by connecting an organization to upstream activities tied to vendors all the way to downstream 
activities tied to distribution and even retail. By relating to the entire supply chain and logistics, 
OM is a broad discipline and tools that seek to support OM may need to factor this. Such OM 
problems have been long supported by various approaches powered by mathematical models and 
algorithms, and they are progressively seeing the use if AI, especially machine learning, 
approaches in the quest for solutions. 
 
Against this backdrop, this paper has the specific objectives: 


---
## Page 6
---

6 
 
(1) identify general issues related to AI tools and unique issues related to AI tools in the context 
of OM that could potentially hinder employee adoption and use of such tools; and  
(2) using UTAUT as the underlying theoretical basis, present a research agenda to study the 
adoption and use of AI tools in OM, with implications for the broader adoption and use of AI 
tools by employees in organizations.  
2. AI Tools and Operations Management: What’s General and What’s Unique? 
As we consider AI tools for OM, it is important to recognize and identify the several 
issues that AI tools present that may hinder their adoption by employees. These issues are 
organized into three areas: (1) general issues with AI tools; (2) general challenges with 
employees; and (3) unique issues with AI tools for OM.  
2.1 General Issues with AI Tools 
(1) 
Model is blackboxed: With AI tools, often, the underlying model itself is blackboxed and 
the user has little or no visibility into the underlying algorithm or process that renders the 
decision. Users are unlikely to always embrace this, especially if there is accountability 
on the part of the user for the consequences. 
(2) 
Model errors: Almost by definition, a model is bound to make mistakes, given that it is, 
after all, a representation of reality. Such mistakes are particularly more likely in dynamic 
environments and/or environments where there is greater uncertainly or lack of data, as 
may sometimes be the case when extra-organization entities are involved, which is often 
the case in supply-chain and logistics matters. With errors come a lack of trust in the 
model decisions or recommendations. With mistakes building up over time, there could 
be a potential negative impact on use over time.  


---
## Page 7
---

7 
 
(3) 
Model learning takes time: Related to but somewhat distinct from the issue of model 
errors is the fact, AI models will learn over time that will likely and hopefully result in 
the performance improving over time. Such learning and early mistakes will be 
particularly more pronounced when, as noted in the previous point, the environment is 
dynamic in contexts like supply-chain and logistics where more partners, limited data 
and/or data of questionable quality may be involved.  
(4) 
Model bias: Models do tend to have biases, some of which may be emergent and 
unknown initially (see Schuetz and Venkatesh 2020) such as in the case of the Amazon 
job applicant screening tool. The bigger the biases that develop, especially those with 
significant adverse consequences, the greater the resistance that is likely to build.  
2.2 General Challenges with Employees  
(5) 
Human biases and greater trust in human judgment: Employees, each with their unique 
background and experiences in general and experiences in the specific organization, 
business unit and/or job, will have numerous biases. Some of these biases would be the 
result of heuristics that they have developed over time. Although these biases could be as 
severe or worse than what AI tools may have/develop and such biases could lead to 
bigger or more frequent mistakes than what AI tools may make, employees may simply 
have greater trust in their own judgment or judgment of their coworkers.  
(6) 
Algorithm aversion: An interesting and evolving issue seems to be a particular 
characteristic that manifests as an aversion to what the core of AI tools are—i.e., 
algorithms. This issue is broader than the earlier set of issues identified earlier related to 
models in that this particular issue has nothing to do with whether the model is right or 


---
## Page 8
---

8 
 
wrong, rather it is simply a matter of a preference for no algorithm—i.e., no AI tools—
altogether. 
2.3 Unique Issues with AI tools for OM  
(7) 
More stakeholders: Compared to AI tools built to serve specific business units or jobs 
within specific business units, AI tools and concomitant algorithms/models for OM will 
necessarily need to take more stakeholders data/information into account because of the 
very nature of the supply chain and logistics activities. This will build greater uncertainty 
and may lead to, as articulated earlier, errors and biases. Beyond that, due to such 
challenges, employees using AI tools to support OM activities may be reluctant to adopt 
and use them. 
(8) 
Incomplete and/or missing data: Models will often be based on incomplete or missing 
data, and this is likely to be exacerbated with more stakeholders being involved and 
especially more extra-organizational stakeholders involved, which, as noted earlier, is 
likely to be the case in an OM context. 
(9) 
Unknown or incorrect assumptions: Going beyond the availability of data is that models, 
given that they are a representation of reality, are based on numerous assumptions. For 
models that are narrower in scope, such as the ones that are supporting specific jobs or 
specific jobs within specific business units with little or no interfaces with other business 
units or extra-organization entities, such assumptions may be accurate. However, in an 
OM context, just like missing or incomplete data, assumptions made may be 
unknown/unspecified or incorrect—such assumptions can in turn be a direct contributor 
to some of the issues, such as model errors, articulated earlier.  


---
## Page 9
---

9 
 
(10) 
Changing landscape: Due to the number of stakeholders involved and the complex and 
long chain involved, the landscape of parameters, not just assumptions, that influence 
activities may be changing in ways that are not readily apparent and thus cannot be used 
to inform the model, especially in a dynamic manner. Much like faulty assumptions or 
missing data, such a situation is also likely to contribute to problems, such as model 
errors, like the ones articulated earlier. 
In sum, there are several issues with AI tools, some general, some specific to employees, 
and some unique to AI tools in an OM context that will play a role in potentially hindering 
employee adoption.  
3. Research Agenda 
 
Against the backdrop of the issues discussed earlier, in this section, a research agenda 
using UTAUT as the underlying theoretical basis is proposed. Note that UTAUT has been used 
to study the full spectrum of technology adoption from initial adoption to post-adoptive use (e.g., 
Venkatesh et al. 2011). The key ideas of UTAUT from Venkatesh et al. (2003) are presented 
here. UTAUT has four predictors of intention to use and technology use: performance 
expectancy, effort expectancy, social influence, and facilitating conditions. These constructs are 
defined as follows: performance expectancy is defined as the degree to which an individual 
believes that using a system will enhance their job performance; effort expectancy is defined as 
the degree of ease associated with the use of the system; social influence refers to an individual’s 
perception that important others believe that he or she should use the new system; and 
facilitating conditions refers to individual’s belief that an organizational and technical 
infrastructure exists to support use of the system. Up to four variables moderate various 
relationships: gender, age, experience, and voluntariness of use (for a discussion of moderators, 


---
## Page 10
---

10 
 
see Morris and Venkatesh 2000; Morris et al. 2005; Venkatesh and Morris 2000; Venkatesh et al. 
2004). Fig. 1 presents UTAUT and the future research directions suggested. Table 1 maps the 
issues related to AI tools with the proposed future research directions including illustrative 
research questions. 
Fig. 1 UTAUT and Proposed Future Research Directions 
 
I have, in the past, proposed research agendas for the topic of individual-level adoption 
and use of technology both in general (Venkatesh et al. 2007; Venkatesh and Bala 2008; 
Venkatesh et al. 2016; Zhang and Venkatesh 2018) and in specific contexts including those 
related to operations management (e.g., Venkatesh 2006, 2013). These serve as the backdrop to 
propose research that can be conducted to better understand and foster employee adoption and 
use of AI tools, with a particular eye toward how to increase such adoption and use, especially in 
the OM context. As with most research agendas, the suggestions here are not meant to be 
exhaustive but meant to provide illustrations and conceptual ideas that can spur further 
investigations. 
Table 1. Research Agenda 
AI Tool Issues 
UTAUT-related 
Research Directions 
Illustrations 


---
## Page 11
---

11 
 
1. Model is blackboxed 
2. Model errors 
3. Model learning takes 
time 
4. Model bias 
 
All these issues related to 
the model create 
situations of uncertainty 
that users have to 
embrace and/or tolerate.  
• Individual 
characteristics  
• Technology 
characteristics 
• Environmental 
characteristics 
• Interventions 
 
• Role of personality in influencing 
UTAUT predictors. Some individual 
characteristics could be moderators of 
the impact of model opacity on 
UTAUT predictors and the impact of 
UTAUT predictors on outcomes. 
• Design characteristics (such as 
transparency) can enhance perceptions 
about UTAUT predictors (such as 
performance expectancy). Similarly, 
some design characteristics could 
serve as moderators of the impact of 
the relationship of the perceptions of 
the model to UTAUT predictors and 
UTAUT predictors to outcomes. 
• Some situations lead to higher levels 
of model opacity and consequent 
negative impacts on UTAUT 
predictors and/or moderators, as noted 
above. 
• Interventions are always crucial to 
foster adoption and use—and when 
faced with new models of decision 
making and related impacts on job 
characteristics, interventions will be 
especially critical. Interventions can be 
designed such that they vary 
depending on various other 
characteristics. For instance, the 
interventions for the more risk-averse 
may be different.  
5. Human biases and 
greater trust in human 
judgment 
6. Algorithm aversion 
 
These relate to issues 
employees can have that 
hinder their willingness 
to adopt AI tools, 
especially the more 
opaque the tools are.  
• Individual 
characteristics 
• Technology 
characteristics 
• Environmental 
characteristics  
• Interventions 
The ideas here are similar in spirit to what 
was is outlined above in that various 
aspects of individuals, the design of the 
tool, and the environment will play a role. 
In addition, interventions can be designed 
to enhance adoption and use.  
7. More stakeholders 
8. Incomplete and/or 
missing data 
• Individual 
characteristics 
• Technology 
characteristics 
Building on the spirit of what has already 
been noted above, OM contexts create 
greater levels of uncertainty and 
incomplete information. The impacts of 


---
## Page 12
---

12 
 
9. Unknown or 
incorrect assumptions 
10. Changing landscape 
• Environmental 
characteristics  
• Interventions 
these issues can be especially significant 
in terms of when, where, how, and who 
will adopt and use AI tools. For instance, 
the more the stakeholders who are 
involved and in a dynamic environment, 
with a great of missing data, the more 
likely there could be barriers to adoption, 
and careful investigation and planning of 
interventions will be critical. 
General 
• Outcomes 
Critical employee outcomes, such as job 
characteristics, job satisfaction, job stress 
and job performance, may be affected by 
the use of AI tools. Accumulating benefits 
at the employee level is critical to get 
higher-level (e.g., business unit, 
organizational) benefits.  
 
 
As noted in Venkatesh et al. (2016) and associated works (Venkatesh 2014; Venkatesh et 
al. 2014), UTAUT has served as a powerful general theoretical model and its embedded 
constructs have been predictive in a variety of contexts and among a variety of technologies— 
agile systems (Hong et al. 2011), digital libraries (Hong et al. 2001; Thong et al. 2002), e-
government (Chan et al. 2010; Venkatesh et al. 2011; Venkatesh et al. 2012; Venkatesh et al. 
2016), e-tax filing (Hu et al. 2009), mobile data services (Hong et al. 2008; Xu et al. 2017), and 
personal ICT (Thong et al. 2011). Building on the prior general research agendas, there are the 
following four key research opportunities here: (1) antecedents/determinants of UTAUT 
constructs including interventions; (2) moderators of UTAUT relationships; (3) new predictors; 
and (4) consequences.  
3.1. Antecedents/Determinants and UTAUT 
 
One of the most fruitful and important avenues leveraging UTAUT as a theoretical basis 
is to examine antecedents/determinants that are tailored to the particular technology. A general 
framework adapted from Thong (1999), Venkatesh et al. (2007), Venkatesh and Bala (2008), and 
Venkatesh et al. (2016) include individual characteristics, such as personality, technology 


---
## Page 13
---

13 
 
characteristics, such as quality, environmental characteristics (including as perceived by the 
employee), such as culture of innovation, and interventions, such as training. I elaborate on these 
next. 
 
Individual characteristics are critical in most technology adoption and use contexts. In 
this particular case, given the likelihood of errors, uncertainty, and opaqueness, personality 
characteristics related to these attributes of the technology may be particularly relevant. 
Individuals who are likely to be more risk-seeking, tolerant of uncertainty, and with a desire to 
learn are more likely to adopt AI tools. Beyond this, traditional technology-related traits, such as 
computer self-efficacy and computer playfulness (see Venkatesh 2000; Venkatesh and Davis 
1996), could also play a role. General personality traits could also be relevant. These traits can 
influence the various predictors in UTAUT, especially performance expectancy, effort 
expectancy and facilitating conditions. Together, these individual characteristics can play a role 
in how employees deal with issues with the AI tools and/or general challenges faced by 
employees Overall, researchers should investigate potential traits that could foster or hinder the 
adoption of AI tools. Using this knowledge, organizations can then identify those who may be 
able to create a positive environment around the technology.  
 
Technology characteristics can be examined either as perceptions of employees or 
objective characteristics depending on the nature of the investigation. The particular 
characteristics of AI tools connected to the various potential challenges, which were described 
earlier, could play a role. For instance, perceptions of model errors by employees or perceptions 
of the availability or complete information from other entities in the supply chain could have an 
impact on UTAUT predictors, especially performance expectancy. If multiple tools were to be 
compared, objective characteristics of the different competing options on the various parameters, 


---
## Page 14
---

14 
 
related to the errors, could be examined to see which of them has a strong/substantial effect. 
Further, design characteristics of AI tools, especially as it relates to the model, such as 
transparency, could influence UTAUT predictors. 
 
Environmental characteristics including the organizational climate that promotes 
innovation, learning and other aspects that will allow the tools and associated challenges to work 
themselves out over a period of time will likely lead employees to adopt and use such tools. Like 
with technology characteristics, depending on the nature of the studies, i.e., one organization 
[business unit] being studied or several organizations [business units] being studied, these 
investigations can also be conducted as perceptions of employees or defined characteristics of 
specific organizations [business units]. A number of specific attributes pertaining to the 
environment in which AI tools are used can have an impact on UTAUT predictors. These include 
the range and number of stakeholders, the lack of data or incomplete or missing data, 
uncertainty, biases, and extent to which the environment itself is dynamic. All of these 
environmental characteristics can vary independently or in tandem to create a variety of 
situations that can play a key role in determining UTAUT predictors. 
 
Interventions, ranging from generic training to various types of training to innovative 
approaches using gamification (see Venkatesh 1999), could be used to study the impact on 
adoption and use. Venkatesh and Bala (2008) provide an elaborate framework for studying 
interventions and their impacts on technology adoption. In particular, when there is likely to be 
significant uncertainly surrounding the workings of the system, appropriate project management 
practices may be critical to achieving not only the desired project outcomes, but also the desired 
employee outcomes (Morris and Venkatesh 2010; Rai et al. 2009; Sykes and Venkatesh 2017; 
Sykes et al. 2014). Although good project management practices to include significant roles for 


---
## Page 15
---

15 
 
the users is generally important, it could be expected that they will even more important given 
the potential problems and uncertainty surrounding supply-chain management systems. 
 
3.2. Moderators 
 
The four categories of constructs, discussed in section 3.1, could potentially play a 
moderating role as well. To illustrate, it is possible that individual characteristics can moderate 
the effect of one or more of the UTAUT predictors (e.g., performance expectancy) on intention 
or use. Similarly, it is possible for environmental variables to play a moderating role. For 
instance, it is possible that high tolerance for uncertainty could result in a situation where low 
performance expectancy, say due to high model errors, may not have as detrimental an effect. 
Another example is where a favorable climate of innovation may result in a stronger effect of 
social influence on intention. Beyond this, these relationships could vary across cultures (Hoehle 
et al. 2015; Maruping et al. 2019; Thongpananl et al. 2018; Venkatesh et al. 2010, 2016) and 
time (Venkatesh et al. 2006). Further, a variety of these effects could be non-linear (Brown et al. 
2008, 2012, 2014; Venkatesh and Goyal 2010).  
3.3. New Predictors  
Going beyond direct effects on UTAUT predictors discussed in section 3.1 and the 
moderating effects discussed in section 3.2, these variables can potentially have direct effects on 
intention and use or even downstream outcomes/consequences. It should be noted that beyond 
the sets of constructs, described in section 3.1, that could influence the various UTAUT 
predictors or directly influence outcomes, such as intention, use and/or other outcomes, there 
could be other predictors with direct and/or interaction effects on outcomes. For instance, it is 
possible to envision that environmental variables will have an effect on intention, use and/or 
outcomes of using AI tools. The context can often create particular variables that could drive 


---
## Page 16
---

16 
 
intention and/or use. An important example of adding predictors to UTAUT can be readily seen 
in the evolution of UTAUT to UTAUT 2 (Venkatesh et al. 2012). UTAUT 2 was created by 
tailoring UTAUT to the context of consumers using technologies for personal use and 
specifically adding three predictors (e.g., habit). Additionally, modifications were made to 
UTAUT in UTAUT 2 by dropping voluntariness of use as a moderator that in turn suggests that, 
the discussion earlier, could include addition and/or deletion of main effects (predictors) and/or 
moderators.  
3.4. Outcomes/Consequences 
 
The various outcomes/consequences that are typically studied in the technology adoption 
literature, such as intention, behavioral expectation and use, should be studied (Maruping et al. 
2017; Venkatesh et al. 2008). In addition, the impacts of AI tools on job characteristics (Bala and 
Venkatesh 2013; Morris and Venkatesh 2010) merit attention. Various employee outcomes, 
ranging from job performance and job satisfaction to job stress should be studied (Sykes 2015; 
Sykes and Venkatesh 2017). 
4. Conclusion 
 
This paper presented a research agenda to study the employee adoption and use of AI 
tools. UTAUT, which is one of the most widely used theories to explain individual-level 
adoption and use, is used as a theoretical basis for the proposed agenda. Based on ten issues with 
AI tools (e.g., model bias), including issues specific to AI tools in operations management (e.g., 
incomplete information from extra-organizational stakeholders), individual characteristics (e.g., 
tolerance for uncertainty), technology characteristics (e.g., model quality), environmental 
characteristics (e.g., innovation climate), and interventions (e.g., gamified training) are proposed 


---
## Page 17
---

17 
 
as possible determinants of UTAUT constructs, moderators of UTAUT relationships, and 
possible additional direct predictors of employee adoption and use.  
References 
 
Bala, H., & Venkatesh, V. (2013). Changes in Employees' Job Characteristics During an 
Enterprise System Implementation: A Latent Growth Modeling Perspective. MIS Quarterly, 
37(4), 1113-1140. 
Brown, S.A., Dennis, A.R., & Venkatesh, V. (2010). Predicting Collaboration Technology Use: 
Integrating Technology Adoption and Collaboration Research. Journal of Management 
Information Systems, 27(2), 9-54.  
Brown, S.A., Venkatesh, V., & Goyal, S. (2014). Expectation Confirmation in Information 
Systems Research: A Test of Six Competing Models. MIS Quarterly, 38(3), 729-756. 
Brown, S.A., Venkatesh, V., & Goyal, S. (2012). Expectation Confirmation in Technology Use. 
Information Systems Research, 23(2), 474-487. 
Brown, S.A., Venkatesh, V., Kuruzovich, J.N., & Massey, A.P. (2008). Expectation 
Confirmation: An Examination of Three Competing Models. Organizational Behavior and 
Human Decision Processes, 105(1), 52-66.   
Chan, F.K.Y., Thong, J.Y.L., Venkatesh, V., Brown, S.A., Hu, P.J-H., & Tam, K.Y. (2010). 
Modeling Citizen Satisfaction with Mandatory Adoption of an E-Government Technology. 
Journal of the Association for Information Systems, 11(10), 519-549. 
Hoehle, H., Zhang, X., & Venkatesh, V. (2015). An Espoused Cultural Perspective to 
Understand Continued Intention to Use Mobile Applications: A Four-country Study of Mobile 
Social Media Application Usability. European Journal of Information Systems, 24(3), 337-359.  
Hong, W., Chan, F.K.Y., Thong, J.Y.L., Chasalow, L., & Dhillon, G. (2014). A framework and 
guidelines for context-specific theorizing in information systems research. Information Systems 
Research, 25(1), 111-136. 
Hong, S.J., Thong, J.Y.L., Moon, J.Y., & Tam, K.Y. (2008). Understanding the behavior of 
mobile data services consumers. Information Systems Frontiers, 10(4), 431-445. 
Hong, W., Thong, J.Y.L., Chasalow, L., & Dhillon, G. (2011). User acceptance of agile 
information systems: A model and empirical test. Journal of Management Information Systems, 
28(1), 235-272. 
Hong, W., Thong, J.Y.L., Wong, W.M., & Tam, K.Y. (2001). Determinants of user acceptance 
of digital libraries: An empirical examination of individual differences and system 
characteristics. Journal of Management Information Systems, 18(3), 97-124. 


---
## Page 18
---

18 
 
Hu, P.J.H., Brown, S.A., Thong, J.Y.L., Chan, F.K.Y., & Tam, K.Y. (2009). Determinants of 
service quality and continuance intention of online services: The case of eTax. Journal of the 
American Society for Information Science and Technology, 60(2), 292-306. 
Kocheturov, A., Pardalos, P.M., & Karakitsiou, A. (2019). Massive datasets and machine 
learning for computational biomedicine: trends and challenges. Annals of Operations Research, 
276, 5-34. 
Lambrecht, A., & Tucker, C. (2019). Algorithmic Bias? An Empirical Study of Apparent 
Gender-Based Discrimination in the Display of STEM Career Ads. Management Science, 65(7), 
2966-2981. 
Maruping, L.M., Bala, H., Venkatesh, V., & Brown, S.A. (2017). Going Beyond Intention: 
Integrating Behavioral Expectation into the Unified Theory of Acceptance and Use of 
Technology. Journal of the American Society for Information Science and Technology, 68(3), 
623-637.  
Maruping, L.M., Venkatesh, V., Thong, J.Y.L., & Zhang, X. (2019). A Risk Mitigation 
Framework for Information Technology Projects: A Cultural Contingency Perspective. Journal 
of Management Information Systems, 36(1), 120-157. 
Morris, M.G., & Venkatesh, V. (2010). Job Characteristics and Job Satisfaction: Understanding 
the Role of Enterprise Resource Planning System Implementation. MIS Quarterly, 34(1), 143-
161.  
Morris, M.G., Venkatesh, V., & Ackerman, P.L. (2005). Gender and Age Differences in 
Employee Decisions about New Technology: An Extension to the Theory of Planned Behavior,” 
IEEE Transactions on Engineering Management, 52(1), 69-84. 
Pan, J., Ding, S., Wu, D., Yang, S., & Yang. J. (2019). Exploring behavioural intentions toward 
smart healthcare services among medical practitioners: a technology transfer perspective. 
International Journal of Production Research, 57(18), 5801-5820. 
Priore, P., Ponte, B., Rosillo, R., & de la Fuente, D. (2019). Applying machine learning to the 
dynamic selection of replenishment policies in fast-changing supply chain environments. 
International Journal of Production Research, 57(11), 3663-3677. 
Rai, A., Maruping, L.M., & Venkatesh, V. (2009). Offshore Information System Project Success: 
The Role of Social Embeddedness and Cultural Characteristics. MIS Quarterly, 33(3), 617-641. 
Razzaghi, T., Safro, I., Ewing, J., Sadrfaridpour, E., & Scott, J.D. (2019). Predictive models for 
bariatric surgery risks with imbalanced medical datasets. Annals of Operations Research, 280, 1-
18. 
Romanova, T., Stoyan, Y., Pankratov, A., Litvinchev, I., Avramov, K., Chernobryvko, M., et al. 
(2019). Optimal layout of ellipses and its application for additive manufacturing. International 
Journal of Production Research, DOI: 10.1080/00207543.2019.1697836. 


---
## Page 19
---

19 
 
Schuetz, S.W., & Venkatesh, V. (2020). Research Perspectives: The Rise of Human Machines: 
How Cognitive Computing Systems Challenge Assumptions of User-System Interaction. Journal 
of the Association for Information Systems, 21(2).  
Sykes, T.A., Venkatesh, V., & Johnson, J.L. (2014). Enterprise System Implementation and 
Employee Job Performance: Understanding the Role of Advice Networks. MIS Quarterly, 38(1), 
51-72. 
Sykes, T.A., & Venkatesh, V. (2017). Explaining Post-Implementation Employee System Use 
and Job Performance: Impacts of the Content and Source of Social Network Ties. MIS Quarterly, 
41(3), 917-936.  
Thong, J.Y.L. (1999). An integrated model of information systems adoption in small businesses.  
Journal of Management Information Systems, 15(4), 187-214. 
Thong, J.Y.L., Hong, W., & Tam, K.Y. (2002). Understanding user acceptance of digital 
libraries: What are the roles of interface characteristics, organizational context, and individual 
differences?. International Journal of Human-Computer Studies, 57(3), 215-242. 
Thong, J.Y.L., Venkatesh, V., Xu, X., Hong, S-J., & Tam, K.Y. (2011). Consumer Acceptance 
of Personal Information and Communication Technology Services. IEEE Transactions on 
Engineering Management, 58(4), 613-625.  
Thongpapanl, N., Ashraf, A.R., Lapa, L., & Venkatesh, V. (2018). Unveiling the Differential 
Effects of Consumers’ Regulatory Fit on Trust, Perceived Value, and M-commerce Usage 
among Developed and Developing Countries. Journal of International Marketing, 26(3), 22-44.  
Venkatesh, V. (2013). IT, Supply Chain, and Services: Looking Ahead. Journal of Operations 
Management, 31(6), 281-284. 
Venkatesh, V. (2014). IT, Supply Chain, and Services: Looking Ahead. In C. Cooper, D. Straub 
and R. Welke (Eds.), The Wiley Encyclopedia of Management (pp. 295-303), Vol. 7, Chichester, 
West Sussex, UK: Wiley.  
Venkatesh, V. (2000). Determinants of Perceived Ease of Use: Integrating Control, Intrinsic 
Motivation, and Emotion into the Technology Acceptance Model. Information Systems 
Research, 11(4), 342-365.  
Venkatesh, V. (2006). Where to go from Here? Thoughts on Future Directions for Research on 
Individual-level Technology Adoption with a focus on Decision Making. Decision Sciences, 
37(4), 497-518.  
Venkatesh, V. (1999). Creation of Favorable User Perceptions: Exploring the Role of Intrinsic 
Motivation. MIS Quarterly, 23(2), 239-260. 
Venkatesh, V., & Bala, H. (2008). Technology Acceptance Model 3 and a Research Agenda on 
Interventions. Decision Sciences, 39(2), 273-315.  


---
## Page 20
---

20 
 
Venkatesh, V., Bala, H., & Sambamurthy, V. (2016). Implementation of an Information and 
Communication Technology in a Developing Country: A Multimethod Longitudinal Study in a 
Bank in India. Information Systems Research, 27(3), 558-579.  
Venkatesh, V., Brown, S.A., Maruping, L.M., & Bala, H. (2008). Predicting Different 
Conceptualizations of System Use: The Competing Roles of Behavioral Intention, Facilitating 
Conditions, and Behavioral Expectation. MIS Quarterly, 32(3), 483-502. 
Venkatesh, V., Chan, F.K.Y., & Thong, J.Y.L. (2012). Designing E-government Services: Key 
Service Attributes and Citizens’ Preference Structures. Journal of Operations Management, 
30(1-2), 116-133.  
Venkatesh, V., & Davis, F.D. (1996). A Model of the Antecedents of Perceived Ease of Use: 
Development and Test. Decision Sciences, 27(3), 451-481.  
Venkatesh, V., & Davis, F.D. (2000). A Theoretical Extension of the Technology Acceptance 
Model: Four Longitudinal Field Studies. Management Science, 46(2), 186-204.  
Venkatesh, V., Davis, F.D., & Morris, M.G. (2007). Dead or Alive? The Development, 
Trajectory and Future of Technology Adoption Research. Journal of the Association for 
Information Systems, 8(4), 267-286. 
Venkatesh, V., & Goyal, S. (2010). Expectation Disconfirmation and Technology Adoption: 
Polynomial Modeling and Response Surface Analysis. MIS Quarterly, 34(2), 281-303. 
Venkatesh, V., Maruping, L.M., & Brown, S.A. (2006). Role of Time in Self-prediction of 
Behavior. Organizational Behavior and Human Decision Processes, 100(2), 160-176.   
Venkatesh, V., Morris, M.G., & Davis, F.D. (2014). Individual-Level Technology Adoption 
Research: An Assessment of The Strengths, Weaknesses, Threats and Opportunities for Further 
Research Contributions. In H. Topi (Ed.), CRC Computing Handbook Set (pp. 38-1-38-25). Boca 
Raton, FL: CRC Press, 3rd edition,. 
Venkatesh, V., Morris, M.G., Davis, F.D., & Davis, G.B. (2003). User Acceptance of 
Information Technology: Toward a Unified View. MIS Quarterly, 27(3), 425-478.  
Venkatesh, V., Morris, M.G., Sykes, T.A., & Ackerman, P.L. (2004). Individual Reactions to 
New Technologies in the Workplace: The Role of Gender as a Psychological Construct. Journal 
of Applied Social Psychology, 34(3), 445-467. 
Venkatesh, V., Thong, J.Y.L., Chan, F.K.Y., & Hu, P.J. (2016). Managing Citizens’ Uncertainty 
in E-government Services: The Mediating and Moderating Roles of Transparency and Trust. 
Information Systems Research, 27(1), 87-111. 
Venkatesh, V., Thong, J.Y.L., Chan, F.K.Y., Hu, P.J-H., & Brown, S.A. (2011). Extending the 
Two-stage Information Systems Continuance Model: Incorporating UTAUT Predictors and the 
Role of Context. Information Systems Journal, 21(6), 527-555. 


---
## Page 21
---

21 
 
Venkatesh, V., Thong, J.Y.L., & Xu, X., (2016). Unified Theory of Acceptance and Use of 
Technology: A Synthesis and the Road Ahead. Journal of the Association for Information 
Systems, 17(5), 328-376. 
Venkatesh, V., Thong, J.Y.L., & Xu, X. (2012). Consumer Acceptance and Use of Information 
Technology: Extending the Unified Theory of Acceptance and Use of Technology. MIS 
Quarterly, 36(1), 157-178.  
Venkatesh, V., & Zhang, X. (2010). Unified Theory of Acceptance and Use of Technology: U.S. 
Vs. China. Journal of Global Information Technology Management, 13(1) 5-27. 
Wang, Y., Lin, Y., Zhong, R.Y., & Xu, X. (2019). IoT-enabled cloud-based additive 
manufacturing platform to support rapid product development. International Journal of 
Production Research, 57(12), 3975-3991. 
Wang, Z., Chen, C.H., Zheng, P., Li, X., & Khoo, L.P. (2019). A graph-based context-aware 
requirement elicitation approach in smart product-service systems. International Journal of 
Production Research, 57(20), 1-17. 
Xu, X., Thong, J.Y.L., & Tam, K.Y. (2017). Winning back technology disadopters: Testing a 
technology re-adoption model in the context of mobile internet services. Journal of Management 
Information Systems, 34(1), 102-140. 
Zhang, X., & Venkatesh, V. (2018). From Design Principles to Impacts: A Theoretical 
Framework and Research Agenda. AIS Transactions on Human-Computer Interaction, 10(2), 
105-128.  
